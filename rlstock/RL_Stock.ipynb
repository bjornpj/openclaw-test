{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch as T\n",
    "#from dueling_dqn_torchB1 import C51DuelDQNAgentPER\n",
    "from model import C51DuelDQNAgentPER\n",
    "#from dueling_dqn_torchB1copy import C51DuelDQNAgentPER\n",
    "#from dqn_agent1 import DQNAgent\n",
    "#from utils import plot_learning_curve, make_env\n",
    "from gym import wrappers\n",
    "\n",
    "from RLStock_Utils import DataEnv, StockTradingEnvBB\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import deque\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#T.cuda.memory_allocated()\n",
    "T.cuda.empty_cache()\n",
    "T.cuda.memory_allocated()\n",
    "##############################\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    T.manual_seed(seed)\n",
    "    T.cuda.manual_seed(seed)\n",
    "    T.cuda.manual_seed_all(seed)\n",
    "    T.backends.cudnn.deterministic = True\n",
    "    T.backends.cudnn.benchmark = True\n",
    "#    T.set_float32_matmul_precision('high')  # (PyTorch 2.0+) - improves matmul ops\n",
    "    \n",
    "seed_everything(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.seed(2021)\n",
    "random.seed(2021)\n",
    "T.manual_seed(2021)\n",
    "T.cuda.manual_seed(2021)\n",
    "T.backends.cudnn.deterministic = True\n",
    "T.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of days back in time\n",
    "ndays = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple ISO 8601 timestamped logger\n",
    "def log(s):\n",
    "  print('[' + str(datetime.now().strftime('%Y-%m-%d %H:%M:%S')) + '] ' + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(sys.prefix, 'data')\n",
    "dataenv = DataEnv(save_tuple_buffer=False, path=data_path, fname=\"last_10_years\", ndays=ndays)\n",
    "#dataenv = DataEnv(save_tuple_buffer=False, path=data_path, fname=\"last_10_years\", ndays=ndays)\n",
    "#dataenv = DataEnv(save_tuple_buffer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading C:\\Users\\bjorn\\miniconda3\\envs\\rlstock\\data\\tuplebuffer_train_sma_last_10_years_25d.pickle\n",
      "loading C:\\Users\\bjorn\\miniconda3\\envs\\rlstock\\data\\tuplebuffer_test_sma_last_10_years_25d.pickle\n",
      "loading C:\\Users\\bjorn\\miniconda3\\envs\\rlstock\\data\\date_ranges_sma_last_10_years_25d.pickle\n"
     ]
    }
   ],
   "source": [
    "#dataenv.process()\n",
    "#dataenv.process_save(fname=\"t0one_sma_last_10_years\")\n",
    "dataenv.process_load(fname=\"sma_last_10_years\")\n",
    "#dataenv.process_load(fname=\"t0one_sma_last_10_years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(573,\n",
       " ['1COV.DE',\n",
       "  'AAL',\n",
       "  'AAPL',\n",
       "  'AAP',\n",
       "  'ABBV',\n",
       "  'ABT',\n",
       "  'ACGL',\n",
       "  'ACN',\n",
       "  'ADBE',\n",
       "  'ADI',\n",
       "  'ADM',\n",
       "  'ADP',\n",
       "  'ADS.DE',\n",
       "  'ADSK',\n",
       "  'ADT',\n",
       "  'AEE',\n",
       "  'AEP',\n",
       "  'AES',\n",
       "  'AFL',\n",
       "  'AIG',\n",
       "  'AIR.PA',\n",
       "  'AIZ',\n",
       "  'AJG',\n",
       "  'AKAM',\n",
       "  'ALB',\n",
       "  'ALGN',\n",
       "  'ALK',\n",
       "  'ALLE',\n",
       "  'ALL',\n",
       "  'ALV.DE',\n",
       "  'AMAT',\n",
       "  'AMCR',\n",
       "  'AMD',\n",
       "  'AME',\n",
       "  'AMGN',\n",
       "  'AMG',\n",
       "  'AMP',\n",
       "  'AMT',\n",
       "  'AMZN',\n",
       "  'ANET',\n",
       "  'ANSS',\n",
       "  'AON',\n",
       "  'AOS',\n",
       "  'APD',\n",
       "  'APH',\n",
       "  'APTV',\n",
       "  'ARE',\n",
       "  'ASML',\n",
       "  'ATO',\n",
       "  'AVB',\n",
       "  'AVGO',\n",
       "  'AVY',\n",
       "  'AWK',\n",
       "  'AXON',\n",
       "  'AXP',\n",
       "  'AYI',\n",
       "  'AZN',\n",
       "  'AZO',\n",
       "  'A',\n",
       "  'BAC',\n",
       "  'BALL',\n",
       "  'BAS.DE',\n",
       "  'BAX',\n",
       "  'BAYN.DE',\n",
       "  'BA',\n",
       "  'BBY',\n",
       "  'BDX',\n",
       "  'BEI.DE',\n",
       "  'BEN',\n",
       "  'BG',\n",
       "  'BHF',\n",
       "  'BIIB',\n",
       "  'BIO',\n",
       "  'BKNG',\n",
       "  'BKR',\n",
       "  'BK',\n",
       "  'BLDR',\n",
       "  'BLK',\n",
       "  'BMS',\n",
       "  'BMW.DE',\n",
       "  'BMY',\n",
       "  'BNR.DE',\n",
       "  'BRO',\n",
       "  'BR',\n",
       "  'BSX',\n",
       "  'BWA',\n",
       "  'BXP',\n",
       "  'BX',\n",
       "  'CAG',\n",
       "  'CAH',\n",
       "  'CARR',\n",
       "  'CAT',\n",
       "  'CBK.DE',\n",
       "  'CBOE',\n",
       "  'CBRE',\n",
       "  'CB',\n",
       "  'CCEP',\n",
       "  'CCI',\n",
       "  'CCL',\n",
       "  'CDNS',\n",
       "  'CDW',\n",
       "  'CE',\n",
       "  'CFG',\n",
       "  'CF',\n",
       "  'CHD',\n",
       "  'CHRW',\n",
       "  'CHTR',\n",
       "  'CINF',\n",
       "  'CI',\n",
       "  'CLF',\n",
       "  'CLX',\n",
       "  'CL',\n",
       "  'CMCSA',\n",
       "  'CME',\n",
       "  'CMG',\n",
       "  'CMI',\n",
       "  'CMS',\n",
       "  'CNC',\n",
       "  'CNP',\n",
       "  'COF',\n",
       "  'CON.DE',\n",
       "  'COO',\n",
       "  'COP',\n",
       "  'COR',\n",
       "  'COST',\n",
       "  'COTY',\n",
       "  'CPAY',\n",
       "  'CPB',\n",
       "  'CPRT',\n",
       "  'CPT',\n",
       "  'CRL',\n",
       "  'CRM',\n",
       "  'CRWD',\n",
       "  'CSCO',\n",
       "  'CSGP',\n",
       "  'CSX',\n",
       "  'CTAS',\n",
       "  'CTLT',\n",
       "  'CTRA',\n",
       "  'CTSH',\n",
       "  'CTVA',\n",
       "  'CVS',\n",
       "  'CVX',\n",
       "  'C',\n",
       "  'DAL',\n",
       "  'DAY',\n",
       "  'DB1.DE',\n",
       "  'DBK.DE',\n",
       "  'DDOG',\n",
       "  'DD',\n",
       "  'DECK',\n",
       "  'DELL',\n",
       "  'DE',\n",
       "  'DFS',\n",
       "  'DGX',\n",
       "  'DG',\n",
       "  'DHI',\n",
       "  'DHL.DE',\n",
       "  'DHR',\n",
       "  'DIS',\n",
       "  'DLR',\n",
       "  'DLTR',\n",
       "  'DOC',\n",
       "  'DOV',\n",
       "  'DOW',\n",
       "  'DPZ',\n",
       "  'DRI',\n",
       "  'DTE.DE',\n",
       "  'DTE',\n",
       "  'DUK',\n",
       "  'DVA',\n",
       "  'DVN',\n",
       "  'DXCM',\n",
       "  'DXC',\n",
       "  'D',\n",
       "  'EA',\n",
       "  'EBAY',\n",
       "  'ECL',\n",
       "  'ED',\n",
       "  'EFX',\n",
       "  'EG',\n",
       "  'EIX',\n",
       "  'ELV',\n",
       "  'EL',\n",
       "  'EMN',\n",
       "  'EMR',\n",
       "  'ENPH',\n",
       "  'ENR.DE',\n",
       "  'EOAN.DE',\n",
       "  'EOG',\n",
       "  'EPAM',\n",
       "  'EQIX',\n",
       "  'EQR',\n",
       "  'EQT',\n",
       "  'ERIE',\n",
       "  'ESS',\n",
       "  'ES',\n",
       "  'ETN',\n",
       "  'ETR',\n",
       "  'ETSY',\n",
       "  'EVRG',\n",
       "  'EW',\n",
       "  'EXC',\n",
       "  'EXPD',\n",
       "  'EXPE',\n",
       "  'EXR',\n",
       "  'FANG',\n",
       "  'FAST',\n",
       "  'FCX',\n",
       "  'FDS',\n",
       "  'FDX',\n",
       "  'FE',\n",
       "  'FFIV',\n",
       "  'FICO',\n",
       "  'FIS',\n",
       "  'FITB',\n",
       "  'FI',\n",
       "  'FL',\n",
       "  'FMC',\n",
       "  'FOSL',\n",
       "  'FOXA',\n",
       "  'FOX',\n",
       "  'FRE.DE',\n",
       "  'FRT',\n",
       "  'FSLR',\n",
       "  'FTI',\n",
       "  'FTNT',\n",
       "  'FTV',\n",
       "  'F',\n",
       "  'GAS',\n",
       "  'GDDY',\n",
       "  'GD',\n",
       "  'GEN',\n",
       "  'GE',\n",
       "  'GILD',\n",
       "  'GIS',\n",
       "  'GLW',\n",
       "  'GL',\n",
       "  'GME',\n",
       "  'GM',\n",
       "  'GNRC',\n",
       "  'GOOGL',\n",
       "  'GOOG',\n",
       "  'GPC',\n",
       "  'GPN',\n",
       "  'GRMN',\n",
       "  'GS',\n",
       "  'GWW',\n",
       "  'HAL',\n",
       "  'HAS',\n",
       "  'HBAN',\n",
       "  'HBI',\n",
       "  'HCA',\n",
       "  'HD',\n",
       "  'HEI.DE',\n",
       "  'HEN3.DE',\n",
       "  'HES',\n",
       "  'HIG',\n",
       "  'HII',\n",
       "  'HLT',\n",
       "  'HNR1.DE',\n",
       "  'HOLX',\n",
       "  'HON',\n",
       "  'HPE',\n",
       "  'HPQ',\n",
       "  'HP',\n",
       "  'HRL',\n",
       "  'HSIC',\n",
       "  'HST',\n",
       "  'HSY',\n",
       "  'HUBB',\n",
       "  'HUM',\n",
       "  'HWM',\n",
       "  'IBM',\n",
       "  'ICE',\n",
       "  'IDXX',\n",
       "  'IEX',\n",
       "  'IFF',\n",
       "  'IFX.DE',\n",
       "  'ILMN',\n",
       "  'INCY',\n",
       "  'INTC',\n",
       "  'INTU',\n",
       "  'INVH',\n",
       "  'IPGP',\n",
       "  'IPG',\n",
       "  'IP',\n",
       "  'IQV',\n",
       "  'IRM',\n",
       "  'IR',\n",
       "  'ISRG',\n",
       "  'ITW',\n",
       "  'IT',\n",
       "  'IVZ',\n",
       "  'JBHT',\n",
       "  'JBL',\n",
       "  'JCI',\n",
       "  'JKHY',\n",
       "  'JNJ',\n",
       "  'JNPR',\n",
       "  'JPM',\n",
       "  'J',\n",
       "  'KEYS',\n",
       "  'KEY',\n",
       "  'KHC',\n",
       "  'KIM',\n",
       "  'KKR',\n",
       "  'KLAC',\n",
       "  'KMB',\n",
       "  'KMI',\n",
       "  'KMX',\n",
       "  'KO',\n",
       "  'KR',\n",
       "  'K',\n",
       "  'LDOS',\n",
       "  'LEN',\n",
       "  'LHX',\n",
       "  'LH',\n",
       "  'LIN',\n",
       "  'LKQ',\n",
       "  'LLY',\n",
       "  'LMT',\n",
       "  'LNT',\n",
       "  'LOW',\n",
       "  'LRCX',\n",
       "  'LULU',\n",
       "  'LUV',\n",
       "  'LVS',\n",
       "  'LW',\n",
       "  'LYB',\n",
       "  'LYV',\n",
       "  'L',\n",
       "  'MAA',\n",
       "  'MAC',\n",
       "  'MAR',\n",
       "  'MAS',\n",
       "  'MA',\n",
       "  'MBG.DE',\n",
       "  'MCD',\n",
       "  'MCHP',\n",
       "  'MCK',\n",
       "  'MCO',\n",
       "  'MDB',\n",
       "  'MDLZ',\n",
       "  'MDT',\n",
       "  'MELI',\n",
       "  'META',\n",
       "  'MET',\n",
       "  'MGM',\n",
       "  'MHK',\n",
       "  'MKC',\n",
       "  'MKTX',\n",
       "  'MLM',\n",
       "  'MMC',\n",
       "  'MMM',\n",
       "  'MNST',\n",
       "  'MOH',\n",
       "  'MOS',\n",
       "  'MO',\n",
       "  'MPC',\n",
       "  'MPWR',\n",
       "  'MRK.DE',\n",
       "  'MRK',\n",
       "  'MRNA',\n",
       "  'MRVL',\n",
       "  'MSCI',\n",
       "  'MSFT',\n",
       "  'MSI',\n",
       "  'MS',\n",
       "  'MTB',\n",
       "  'MTCH',\n",
       "  'MTD',\n",
       "  'MTX.DE',\n",
       "  'MUV2.DE',\n",
       "  'MU',\n",
       "  'NAVI',\n",
       "  'NDAQ',\n",
       "  'NDSN',\n",
       "  'NEE',\n",
       "  'NEM',\n",
       "  'NFLX',\n",
       "  'NI',\n",
       "  'NKE',\n",
       "  'NKTR',\n",
       "  'NOC',\n",
       "  'NOW',\n",
       "  'NRG',\n",
       "  'NSC',\n",
       "  'NTAP',\n",
       "  'NTRS',\n",
       "  'NUE',\n",
       "  'NVDA',\n",
       "  'NVR',\n",
       "  'NWSA',\n",
       "  'NWS',\n",
       "  'NXPI',\n",
       "  'ODFL',\n",
       "  'OI',\n",
       "  'OMC',\n",
       "  'ON',\n",
       "  'ORCL',\n",
       "  'ORLY',\n",
       "  'OTIS',\n",
       "  'O',\n",
       "  'PAH3.DE',\n",
       "  'PANW',\n",
       "  'PARA',\n",
       "  'PAYC',\n",
       "  'PAYX',\n",
       "  'PCAR',\n",
       "  'PCG',\n",
       "  'PDD',\n",
       "  'PEG',\n",
       "  'PENN',\n",
       "  'PEP',\n",
       "  'PFE',\n",
       "  'PFG',\n",
       "  'PGR',\n",
       "  'PG',\n",
       "  'PHM',\n",
       "  'PH',\n",
       "  'PKG',\n",
       "  'PLD',\n",
       "  'PLTR',\n",
       "  'PM',\n",
       "  'PNC',\n",
       "  'PNR',\n",
       "  'PNW',\n",
       "  'PODD',\n",
       "  'POOL',\n",
       "  'PPG',\n",
       "  'PPL',\n",
       "  'PRGO',\n",
       "  'PRU',\n",
       "  'PSA',\n",
       "  'PSX',\n",
       "  'PTC',\n",
       "  'PVH',\n",
       "  'PWR',\n",
       "  'PYPL',\n",
       "  'QCOM',\n",
       "  'QIA.DE',\n",
       "  'QRVO',\n",
       "  'RCL',\n",
       "  'REGN',\n",
       "  'REG',\n",
       "  'RF',\n",
       "  'RHM.DE',\n",
       "  'RIG',\n",
       "  'RJF',\n",
       "  'RL',\n",
       "  'RMD',\n",
       "  'ROK',\n",
       "  'ROL',\n",
       "  'ROP',\n",
       "  'ROST',\n",
       "  'RRC',\n",
       "  'RSG',\n",
       "  'RTX',\n",
       "  'RVTY',\n",
       "  'RWE.DE',\n",
       "  'SAP.DE',\n",
       "  'SBAC',\n",
       "  'SBUX',\n",
       "  'SCHW',\n",
       "  'SEDG',\n",
       "  'SHL.DE',\n",
       "  'SHW',\n",
       "  'SIE.DE',\n",
       "  'SIG',\n",
       "  'SJM',\n",
       "  'SLB',\n",
       "  'SLG',\n",
       "  'SMCI',\n",
       "  'SNA',\n",
       "  'SNPS',\n",
       "  'SO',\n",
       "  'SPGI',\n",
       "  'SPG',\n",
       "  'SRE',\n",
       "  'SRT3.DE',\n",
       "  'STE',\n",
       "  'STLD',\n",
       "  'STT',\n",
       "  'STX',\n",
       "  'STZ',\n",
       "  'SWKS',\n",
       "  'SWK',\n",
       "  'SY1.DE',\n",
       "  'SYF',\n",
       "  'SYK',\n",
       "  'SYY',\n",
       "  'TAP',\n",
       "  'TDC',\n",
       "  'TDG',\n",
       "  'TDY',\n",
       "  'TEAM',\n",
       "  'TECH',\n",
       "  'TEL',\n",
       "  'TER',\n",
       "  'TFC',\n",
       "  'TFX',\n",
       "  'TGT',\n",
       "  'TJX',\n",
       "  'TMO',\n",
       "  'TMUS',\n",
       "  'TPL',\n",
       "  'TPR',\n",
       "  'TRIP',\n",
       "  'TRMB',\n",
       "  'TROW',\n",
       "  'TRV',\n",
       "  'TSCO',\n",
       "  'TSLA',\n",
       "  'TSN',\n",
       "  'TTD',\n",
       "  'TTWO',\n",
       "  'TT',\n",
       "  'TXN',\n",
       "  'TXT',\n",
       "  'TYL',\n",
       "  'T',\n",
       "  'UAL',\n",
       "  'UA',\n",
       "  'UBER',\n",
       "  'UDR',\n",
       "  'UHS',\n",
       "  'ULTA',\n",
       "  'UNH',\n",
       "  'UNP',\n",
       "  'UPS',\n",
       "  'URI',\n",
       "  'USB',\n",
       "  'VICI',\n",
       "  'VLO',\n",
       "  'VMC',\n",
       "  'VNA.DE',\n",
       "  'VNT',\n",
       "  'VOW3.DE',\n",
       "  'VRSK',\n",
       "  'VRSN',\n",
       "  'VRTX',\n",
       "  'VST',\n",
       "  'VTRS',\n",
       "  'VTR',\n",
       "  'VZ',\n",
       "  'V',\n",
       "  'WAB',\n",
       "  'WAT',\n",
       "  'WBA',\n",
       "  'WBD',\n",
       "  'WDAY',\n",
       "  'WDC',\n",
       "  'WEC',\n",
       "  'WELL',\n",
       "  'WFC',\n",
       "  'WMB',\n",
       "  'WMT',\n",
       "  'WM',\n",
       "  'WRB',\n",
       "  'WST',\n",
       "  'WTW',\n",
       "  'WYNN',\n",
       "  'WY',\n",
       "  'XEL',\n",
       "  'XOM',\n",
       "  'XYL',\n",
       "  'YUM',\n",
       "  'ZAL.DE',\n",
       "  'ZBH',\n",
       "  'ZBRA',\n",
       "  'ZS',\n",
       "  'ZTS'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#env.date_ranges.popitem() # removes last entry to dictionary\n",
    "dataenv.ticks = dataenv.date_ranges.keys()\n",
    "###################################################################################################################\n",
    "exclude_list = ['OXY', 'CZR', 'OKE', 'KDP', 'NCLH', 'TRGP', 'APA', 'SBL', 'COV', 'CPWR', 'CVG'] # ticks with negative BLL and KLL values\n",
    "# Filter out the excluded tickers from self.ticks\n",
    "dataenv.ticks = [tick for tick in dataenv.ticks if tick not in exclude_list]\n",
    "###################################################################################################################\n",
    "len(list(dataenv.ticks)), dataenv.ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StockTradingEnvBB(dataenv, 0, ndays=ndays)\n",
    "#Z25env = StockTradingEnvBB(dataenv.tbuf_train, dataenv.tbuf_test, dataenv.ticks)\n",
    "#env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = -np.inf\n",
    "load_checkpoint = False\n",
    "n_games = 5000\n",
    "\n",
    "# Number of environments to run sequentially\n",
    "n_envs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...allocating a PrioritizedReplayBuffer\n"
     ]
    }
   ],
   "source": [
    "agent = C51DuelDQNAgentPER(gamma=0.99, epsilon=0.002*n_envs, lr=4*6.25e-5,\n",
    "#agent = C51DuelDQNAgentPER(gamma=0.994, epsilon=0.002*n_envs, lr=4*6.25e-5,\n",
    "#agent = C51DuelDQNAgentPER(gamma=0.997, epsilon=0.002*n_envs, lr=4*6.25e-5,\n",
    "#agent = C51DuelDQNAgentPER(gamma=0.99, epsilon=0.002*n_envs, lr=1*6.25e-5,\n",
    "#805 agent = C51DuelDQNAgentPER(gamma=0.99, epsilon=0.002*n_envs, lr=4*6.25e-5,\n",
    "#agent = C51DuelDQNAgentPER(gamma=0.99, epsilon=0.002*n_envs, lr=1e-3,\n",
    "                input_dims=((1,73,5)),\n",
    "                b_step=0,\n",
    "                n_step=4,#8,#5,#3,#3,\n",
    "                n_actions=7, mem_size=2 ** 20, eps_min=0.0,\n",
    "                batch_size=256, replace=1000, nenvs=n_envs, eps_dec=5e-5,\n",
    "                ndays = ndays,\n",
    "#                batch_size=64, replace=1000, nenvs=n_envs, eps_dec=5e-5,\n",
    "                chkpt_dir='models/')\n",
    "\n",
    "if load_checkpoint:\n",
    "    print('loading models')\n",
    "    agent.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientC51DuelingDeepQNetworkCV2J23(\n",
      "  (groupz_pos): CustomNorm1d()\n",
      "  (group1): GlobalGroupNorm()\n",
      "  (group2): CustomNorm2d()\n",
      "  (group3): GlobalGroupNorm()\n",
      "  (group4): CustomNorm2d()\n",
      "  (group_state): Conv2d(9, 9, kernel_size=(1, 1), stride=(1, 1), groups=9)\n",
      "  (conv_mainA): Sequential(\n",
      "    (0): Conv2d(19, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (1): CustomNorm2d()\n",
      "    (2): ReLU()\n",
      "    (3): ResNetBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (bn1): CustomNorm2d()\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (bn2): CustomNorm2d()\n",
      "    )\n",
      "    (4): SE2DIdentity(\n",
      "      (fc1): Linear(in_features=32, out_features=5, bias=True)\n",
      "      (fc2): Linear(in_features=5, out_features=32, bias=True)\n",
      "    )\n",
      "    (5): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), groups=32)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (7): CustomNorm2d()\n",
      "    (8): ReLU()\n",
      "    (9): ResNetBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (bn1): CustomNorm2d()\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (bn2): CustomNorm2d()\n",
      "    )\n",
      "    (10): SE2DIdentity(\n",
      "      (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
      "      (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
      "    )\n",
      "    (11): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 1), groups=64)\n",
      "    (12): Conv2d(64, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "    (13): CustomNorm2d()\n",
      "    (14): ReLU()\n",
      "    (15): ResNetBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (bn1): CustomNorm2d()\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (bn2): CustomNorm2d()\n",
      "    )\n",
      "    (16): SE2DIdentity(\n",
      "      (fc1): Linear(in_features=128, out_features=4, bias=True)\n",
      "      (fc2): Linear(in_features=4, out_features=128, bias=True)\n",
      "    )\n",
      "    (17): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 1), groups=128)\n",
      "  )\n",
      "  (temporal_encoder): DilatedTemporalEncoder(\n",
      "    (block1): DilatedResidualConv2d(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
      "      (norm2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (block2): DilatedResidualConv2d(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 1))\n",
      "      (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(2, 0), dilation=(2, 1))\n",
      "      (norm2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (block3): DilatedResidualConv2d(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 1))\n",
      "      (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(4, 0), dilation=(4, 1))\n",
      "      (norm2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "    (block4): DilatedResidualConv2d(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 1))\n",
      "      (norm1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 1), stride=(1, 1), padding=(8, 0), dilation=(8, 1))\n",
      "      (norm2): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "      (act): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (temp_gate): TemporalGate(\n",
      "    (dw): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,), groups=128)\n",
      "    (pw): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    (act): Sigmoid()\n",
      "  )\n",
      "  (static_mlp): StaticMLP(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=9, out_features=128, bias=True)\n",
      "      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.0, inplace=False)\n",
      "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (6): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (static_film): BoundedFiLM(\n",
      "    (ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (gamma): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (beta): Linear(in_features=128, out_features=256, bias=True)\n",
      "  )\n",
      "  (fuse_gate): GateFusion(\n",
      "    (t_ln): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (s_ln): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (t_proj): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (s_proj): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (gate): Sequential(\n",
      "      (0): Linear(in_features=384, out_features=512, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (advantage_stream): Sequential(\n",
      "    (0): NoisyLinear3()\n",
      "    (1): ReLU()\n",
      "    (2): NoisyLinear3()\n",
      "  )\n",
      "  (value_stream): Sequential(\n",
      "    (0): NoisyLinear3()\n",
      "    (1): ReLU()\n",
      "    (2): NoisyLinear3()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(agent.q_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 19 11:17:27 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.83                 Driver Version: 581.83         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   38C    P3             12W /   70W |    4081MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           73460      C   ...onda3\\envs\\rlstock\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Elo:\n",
    "    def __init__(self,k,g=1,homefield = 100):\n",
    "        self.ratingDict = {}\n",
    "        self.k = k\n",
    "        self.g = g\n",
    "        self.homefield = homefield\n",
    "\n",
    "    def addPlayer(self,name,rating = 1500):\n",
    "        self.ratingDict[name] = rating\n",
    "\n",
    "    def gameOver(self, winner, loser, winnerHome):\n",
    "        if winnerHome:\n",
    "            result = self.expectResult(self.ratingDict[winner] + self.homefield, self.ratingDict[loser])\n",
    "        else:\n",
    "            result = self.expectResult(self.ratingDict[winner], self.ratingDict[loser]+self.homefield)\n",
    "\n",
    "        self.ratingDict[winner] = self.ratingDict[winner] + (self.k*self.g)*(1 - result)  \n",
    "        self.ratingDict[loser] \t= self.ratingDict[loser] + (self.k*self.g)*(0 - (1 -result))\n",
    "\n",
    "    def expectResult(self, p1, p2):\n",
    "        exp = (p2-p1)/400.0\n",
    "        return 1/((10.0**(exp))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eloMarket, eloHuman, eloAI = [], [], []\n",
    "eloscore = Elo(k=20)\n",
    "eloscore.addPlayer(\"Market\", rating = 100)\n",
    "eloscore.addPlayer(\"Human\", rating = 100)\n",
    "eloscore.addPlayer(\"AI\", rating = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score_eval = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Financial Times color scheme\n",
    "ft_colors = {\n",
    "    'ft_pink': '#FFF1E5',\n",
    "    'ft_black': '#000000',\n",
    "    'ft_blue': '#0D559F',\n",
    "    'ft_lightblue': '#85C1E9',\n",
    "    'ft_green': '#28A745',\n",
    "    'ft_yellow': '#FFC000',\n",
    "    'ft_red': '#DC3545'\n",
    "}\n",
    "\n",
    "def test_new(tick, step, nstep=200, bal=10000, metrics=True):\n",
    "    price, real_price, adi, pdi, ndi, rsi = [], [], [], [], [], []\n",
    "    hist, bma, bul, bll = [], [], [], []\n",
    "    \n",
    "    agent.q_eval.eval()\n",
    "    agent.q_next.eval()\n",
    "\n",
    "    tbuf = env.tbuf_test\n",
    "    env.btraining = False\n",
    "    env.set_step(step=step, balance=bal, shares_held=[0, 0], shares_held_value=[0, 0], tick=tick)\n",
    "\n",
    "    # initial observation (first action is implicitly HOLD)\n",
    "    observation = env.pred_step(training=False)  # self.current_step = step\n",
    "    hist.append(' ')  # index 0\n",
    "\n",
    "    # ---- init context for new regime stats path ----\n",
    "    d_med  = getattr(agent.q_eval, \"d_med_raw\", None)\n",
    "    d_slow = getattr(agent.q_eval, \"d_slow_raw\", None)\n",
    "#    print(f'd_med={d_med}, d_slow={d_slow}')\n",
    "\n",
    "#999    d_med = getattr(agent, \"d_med_raw\", None)\n",
    "#999    d_slow = getattr(agent, \"d_slow_raw\", None)\n",
    "\n",
    "    med_ctx = np.zeros(d_med, dtype=np.float32) if d_med is not None else None\n",
    "    slow_ctx = np.zeros(d_slow, dtype=np.float32) if d_slow is not None else None\n",
    "\n",
    "    for i in range(nstep):\n",
    "        agent.q_eval.eval()\n",
    "        agent.q_next.eval()\n",
    "\n",
    "        # ---- pick action, optionally using regime context ----\n",
    "        if med_ctx is not None or slow_ctx is not None:\n",
    "            # agent.pred_action should accept med_ctx / slow_ctx in new code\n",
    "#            print(f'med_ctx={med_ctx},slow_ctx={slow_ctx}')\n",
    "            action = agent.pred_action(\n",
    "                observation,\n",
    "                med_ctx=med_ctx,\n",
    "                slow_ctx=slow_ctx,\n",
    "            )\n",
    "        else:\n",
    "            # backward compatible if pred_action ignores context\n",
    "            action = agent.pred_action(observation)\n",
    " \n",
    "\n",
    "        # ---- step env ----\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        # update context for *next* decision if available\n",
    "        if \"medium_stats\" in info:\n",
    "            arr = info[\"medium_stats\"]\n",
    "            if d_med is not None:\n",
    "                med_ctx = np.asarray(arr, dtype=np.float32).reshape(-1)\n",
    "                if med_ctx.shape[0] > d_med:\n",
    "                    med_ctx = med_ctx[:d_med]\n",
    "                elif med_ctx.shape[0] < d_med:\n",
    "                    tmp = np.zeros(d_med, dtype=np.float32)\n",
    "                    tmp[:med_ctx.shape[0]] = med_ctx\n",
    "                    med_ctx = tmp\n",
    "        if \"slow_stats\" in info:\n",
    "            arr = info[\"slow_stats\"]\n",
    "            if d_slow is not None:\n",
    "                slow_ctx = np.asarray(arr, dtype=np.float32).reshape(-1)\n",
    "                if slow_ctx.shape[0] > d_slow:\n",
    "                    slow_ctx = slow_ctx[:d_slow]\n",
    "                elif slow_ctx.shape[0] < d_slow:\n",
    "                    tmp = np.zeros(d_slow, dtype=np.float32)\n",
    "                    tmp[:slow_ctx.shape[0]] = slow_ctx\n",
    "                    slow_ctx = tmp\n",
    "\n",
    "        # fetch TA / price data\n",
    "        [(curcls, nxtcls, curbma, curbul, curbll, zbma, zbul, zbll,\n",
    "          zkma, zkul, zkll, zcls, zrsi, zadi, zpdi, zndi,\n",
    "          zhgh, zlow, zopn, zem12, zem26)] = tbuf.get_indices((tick, step + i))\n",
    "        \n",
    "        real_price.append(curcls)\n",
    "        adi.append(zadi[-1] * 100)\n",
    "        pdi.append(zpdi[-1] * 100)\n",
    "        ndi.append(zndi[-1] * 100)\n",
    "        rsi.append(zrsi[-1] * 100)\n",
    "\n",
    "        bma.append(curbma)\n",
    "        bul.append(curbul)\n",
    "        bll.append(curbll)\n",
    "        \n",
    "        # build action history (skip last index because we don't have a plotted price there)\n",
    "        if i < nstep - 1:\n",
    "            if action == 0:\n",
    "                hist.append(' ')\n",
    "            elif action == 1:\n",
    "                hist.append('a')   # buy small\n",
    "            elif action == 2:\n",
    "                hist.append('b')   # buy medium\n",
    "            elif action == 3:\n",
    "                hist.append('c')   # buy large\n",
    "            elif action == 4:\n",
    "                hist.append('s')   # sell small\n",
    "            elif action == 5:\n",
    "                hist.append('t')   # sell medium\n",
    "            elif action == 6:\n",
    "                hist.append('u')   # sell large\n",
    "            else:\n",
    "                hist.append('?')\n",
    "\n",
    "        if done:\n",
    "            # you *can* break early if you want, but then adjust plotting length accordingly\n",
    "            pass\n",
    "\n",
    "    # ---- scoring vs market ----\n",
    "    xcprice = env.cprice[-1] / env.cprice[1]\n",
    "    if np.sum(env.total_shares_bought1) > 0:\n",
    "        xnet_worth = (env.balance + env.shares_held[0] * env.cprice[-1]) / 10000\n",
    "    else:\n",
    "        xnet_worth = env.net_worth / 10000\n",
    "\n",
    "    if xcprice > xnet_worth:\n",
    "        if xcprice > 1:\n",
    "            eloscore.gameOver('Human', 'AI', 0)\n",
    "        else:\n",
    "            eloscore.gameOver('Market', 'AI', 0)\n",
    "    else:\n",
    "        if xnet_worth > 1:\n",
    "            eloscore.gameOver('AI', 'Human', 0)\n",
    "        else:\n",
    "            eloscore.gameOver('Market', 'Human', 0)\n",
    "\n",
    "    if metrics:\n",
    "        eloMarket.append(eloscore.ratingDict['Market'])\n",
    "        eloHuman.append(eloscore.ratingDict['Human'])\n",
    "        eloAI.append(eloscore.ratingDict['AI'])\n",
    "        title = f'{tick} price vs model  {xcprice:,.2f} / {xnet_worth:,.2f} {step:03d} {n_steps:08d} eloAI={eloAI[-1]:.1f}'\n",
    "        print(f'{tick} Human:{eloHuman[-1]:.1f} AI:{eloAI[-1]:.1f}')\n",
    "    else:\n",
    "        title = f'{tick} price vs model  {xcprice:,.2f} / {xnet_worth:,.2f} {step:03d} {n_steps:08d}'\n",
    "        \n",
    "    pricex = np.array(real_price[:])\n",
    "    adix = np.array(adi[:])\n",
    "    pdix = np.array(pdi[:])\n",
    "    ndix = np.array(ndi[:])\n",
    "    rsix = np.array(rsi[:])\n",
    "    \n",
    "    bmax = np.array(bma[:])\n",
    "    bulx = np.array(bul[:])\n",
    "    bllx = np.array(bll[:])\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 4), dpi=100)\n",
    "    plt.rcParams['figure.figsize'] = [14, 4]\n",
    "    plt.title(title, loc='center', color='b')\n",
    "    plt.grid(color='#C5C9C7')\n",
    "    plt.plot(pricex, color='darkblue', linewidth=0.7)\n",
    "    plt.plot(bmax, alpha=0.7, linewidth=0.5)\n",
    "    plt.plot(bulx, alpha=0.7, linewidth=0.5)\n",
    "    plt.plot(bllx, alpha=0.7, linewidth=0.5)\n",
    "    plt.fill_between(np.linspace(0, nstep-1, nstep), bulx, bllx, color='grey', alpha=0.1)\n",
    "\n",
    "    # ---- draw action markers ----\n",
    "    for i in range(len(hist)):\n",
    "        ch = hist[i]\n",
    "        if ch in ('a', 'b', 'c', 'd'):\n",
    "            color = 'b'   # buys -> blue\n",
    "        elif ch in ('s', 't', 'u', 'v'):\n",
    "            color = 'm'   # sells -> magenta\n",
    "        elif ch == ' ':\n",
    "            color = 'g'   # hold -> green\n",
    "        else:\n",
    "            color = 'k'   # unknown / debug\n",
    "        if i < len(pricex):  # guard in case of early done\n",
    "            plt.text(i, pricex[i], ch, ha='center', color=color)\n",
    "\n",
    "    # secondary axis for RSI / ADI\n",
    "    ax2 = plt.twinx()\n",
    "    ax2.plot(rsix, color='#C0C0C0', alpha=0.7, linewidth=0.5)\n",
    "    ax2.plot(adix, color='#C0C0C0', alpha=0.7, linewidth=0.5)\n",
    "    \n",
    "    path = './img/'\n",
    "    fig.savefig(f'{path}img_{n_steps:08d}_{tick}.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    env.btraining = True\n",
    "\n",
    "    return xnet_worth / xcprice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Financial Times color scheme\n",
    "ft_colors = {\n",
    "    'ft_pink': '#FFF1E5',\n",
    "    'ft_black': '#000000',\n",
    "    'ft_blue': '#0D559F',\n",
    "    'ft_lightblue': '#85C1E9',\n",
    "    'ft_green': '#28A745',\n",
    "    'ft_yellow': '#FFC000',\n",
    "    'ft_red': '#DC3545'\n",
    "}\n",
    "\n",
    "def test(tick, step, nstep=200, bal=10000, metrics=True):\n",
    "    price, real_price, adi, pdi, ndi, rsi, hist, close_macd, close_signal, bma, bul, bll, ema12, ema26 = [], [], [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    \n",
    "    agent.q_eval.eval()\n",
    "    agent.q_next.eval()\n",
    "\n",
    "    tbuf = env.tbuf_test\n",
    "    env.btraining = False\n",
    "    env.set_step(step=step, balance=bal, shares_held=[0, 0], shares_held_value=[0, 0], tick=tick)\n",
    "\n",
    "#    action, volume = agent.pred_action(observation, training=False)\n",
    "    observation = env.pred_step(training=False)  # self.current_step = step\n",
    "\n",
    "    # first action is implicitly \"hold\"\n",
    "    hist.append(' ')  # index 0\n",
    "\n",
    "    for i in range(nstep):\n",
    "        agent.q_eval.eval()\n",
    "        agent.q_next.eval()\n",
    "\n",
    "        # given current observation, predict action in next step\n",
    "#        action, volume = agent.pred_action(observation, training=False)\n",
    "        action = agent.pred_action(observation, training=False)\n",
    "\n",
    "        # take action with reward, step+, next observation\n",
    "#        observation, reward, done, info = env.step((action, volume))\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        # fetch TA / price data\n",
    "        [(curcls, nxtcls, curbma, curbul, curbll, zbma, zbul, zbll,\n",
    "          zkma, zkul, zkll, zcls, zrsi, zadi, zpdi, zndi,\n",
    "          zhgh, zlow, zopn, zem12, zem26)] = tbuf.get_indices((tick, step + i))\n",
    "        \n",
    "        real_price.append(curcls)\n",
    "        adi.append(zadi[-1] * 100)\n",
    "        pdi.append(zpdi[-1] * 100)\n",
    "        ndi.append(zndi[-1] * 100)\n",
    "        rsi.append(zrsi[-1] * 100)\n",
    "\n",
    "        bma.append(curbma)\n",
    "        bul.append(curbul)\n",
    "        bll.append(curbll)\n",
    "        \n",
    "        # build action history (skip last index because we don't have a plotted price there)\n",
    "        if i < nstep - 1:\n",
    "            # 7-action mapping:\n",
    "            # 0 = hold\n",
    "            # 1 = buy small\n",
    "            # 2 = buy medium\n",
    "            # 3 = buy large\n",
    "            # 4 = sell small\n",
    "            # 5 = sell medium\n",
    "            # 6 = sell large\n",
    "            if action == 0:\n",
    "                hist.append(' ')\n",
    "            elif action == 1:\n",
    "                hist.append('b')   # buy small\n",
    "            elif action == 2:\n",
    "                hist.append('c')   # buy medium\n",
    "            elif action == 3:\n",
    "                hist.append('d')   # buy large\n",
    "            elif action == 4:\n",
    "                hist.append('s')   # sell small\n",
    "            elif action == 5:\n",
    "                hist.append('t')   # sell medium\n",
    "            elif action == 6:\n",
    "                hist.append('u')   # sell large\n",
    "            else:\n",
    "                # fallback â€“ shouldn't happen\n",
    "                hist.append('?')\n",
    "\n",
    "    # ---- scoring vs market ----\n",
    "    xcprice = env.cprice[-1] / env.cprice[1]\n",
    "    if np.sum(env.total_shares_bought1) > 0:\n",
    "        xnet_worth = (env.balance + env.shares_held[0] * env.cprice[-1]) / 10000\n",
    "    else:\n",
    "        xnet_worth = env.net_worth / 10000\n",
    "\n",
    "    if xcprice > xnet_worth:\n",
    "        if xcprice > 1:\n",
    "            eloscore.gameOver('Human', 'AI', 0)\n",
    "        else:\n",
    "            eloscore.gameOver('Market', 'AI', 0)\n",
    "    else:\n",
    "        if xnet_worth > 1:\n",
    "            eloscore.gameOver('AI', 'Human', 0)\n",
    "        else:\n",
    "            eloscore.gameOver('Market', 'Human', 0)\n",
    "\n",
    "    if metrics:\n",
    "        eloMarket.append(eloscore.ratingDict['Market'])\n",
    "        eloHuman.append(eloscore.ratingDict['Human'])\n",
    "        eloAI.append(eloscore.ratingDict['AI'])\n",
    "        title = f'{tick} price vs model  {xcprice:,.2f} / {xnet_worth:,.2f} {step:03d} {n_steps:08d} eloAI={eloAI[-1]:.1f}'\n",
    "        print(f'{tick} Human:{eloHuman[-1]:.1f} AI:{eloAI[-1]:.1f}')\n",
    "    else:\n",
    "        title = f'{tick} price vs model  {xcprice:,.2f} / {xnet_worth:,.2f} {step:03d} {n_steps:08d}'\n",
    "        \n",
    "    pricex = np.array(real_price[:])\n",
    "    adix = np.array(adi[:])\n",
    "    pdix = np.array(pdi[:])\n",
    "    ndix = np.array(ndi[:])\n",
    "    rsix = np.array(rsi[:])\n",
    "    \n",
    "    bmax = np.array(bma[:])\n",
    "    bulx = np.array(bul[:])\n",
    "    bllx = np.array(bll[:])\n",
    "    \n",
    "    fig = plt.figure(figsize=(14, 4), dpi=100)\n",
    "    plt.rcParams['figure.figsize'] = [14, 4]\n",
    "    plt.title(title, loc='center', color='b')\n",
    "    plt.grid(color='#C5C9C7')\n",
    "    plt.plot(pricex, color='darkblue', linewidth=0.7)\n",
    "    plt.plot(bmax, alpha=0.7, linewidth=0.5)\n",
    "    plt.plot(bulx, alpha=0.7, linewidth=0.5)\n",
    "    plt.plot(bllx, alpha=0.7, linewidth=0.5)\n",
    "    plt.fill_between(np.linspace(0, nstep-1, nstep), bulx, bllx, color='grey', alpha=0.1)\n",
    "\n",
    "    # ---- draw action markers ----\n",
    "    for i in range(len(hist)):\n",
    "        ch = hist[i]\n",
    "        if ch in ('a', 'b', 'c', 'd'):\n",
    "            color = 'b'   # buys -> blue\n",
    "        elif ch in ('s', 't', 'u', 'v'):\n",
    "            color = 'm'   # sells -> magenta\n",
    "        elif ch == ' ':\n",
    "            color = 'g'   # hold -> green (or you can skip drawing)\n",
    "        else:\n",
    "            color = 'k'   # unknown / debug\n",
    "        plt.text(i, pricex[i], ch, ha='center', color=color)\n",
    "\n",
    "    # secondary axis for RSI / ADI\n",
    "    ax2 = plt.twinx()\n",
    "    ax2.plot(rsix, color='#C0C0C0', alpha=0.7, linewidth=0.5)\n",
    "    ax2.plot(adix, color='#C0C0C0', alpha=0.7, linewidth=0.5)\n",
    "    \n",
    "    path = './img/'\n",
    "    fig.savefig(f'{path}img_{n_steps:08d}_{tick}.png')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    env.btraining = True\n",
    "\n",
    "    return xnet_worth / xcprice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nw = test('T', 123, nstep=200, metrics=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test' + '_' + 'agent_env_name' + '_lr' + '0.0001' + '_' + str(n_games) + 'games'\n",
    "figure_file = 'plots/' + fname + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 0\n",
    "ascores, scores, s_scores, eps_history, steps_array = deque(maxlen=10000), deque(maxlen=10), deque(maxlen=10000), deque(maxlen=10000), deque(maxlen=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_games = 10 * 30 * 3300#3 * 28000#60000#15000#1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "since_last, rewardc = [], []\n",
    "best_since_last = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 80001#80001#65#1001#65#10001#80001#25001#80001#64+32#64#80001#64#20001 # Max number of steps before learning starts; Per Rainbow, 80k with PER works\n",
    "bootstrap = False#False # Set to True when saving initial randomized buffer after max_steps; Only used once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bootstrap:\n",
    "    agent.memory = pickle.load(open('./pickle/buf_160.pkl', 'rb'))  # load from \"buf.pkl\"\n",
    "    agent.memory_n = pickle.load(open('./pickle/buf_n_160.pkl', 'rb'))  # load from \"buf_n.pkl\"\n",
    "    n_steps = max_steps\n",
    "    agent.epsilon = 1 - (n_steps / 250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "interrupted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### Vecntor based Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "#from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVecEnvNoFlatten_new(DummyVecEnv):\n",
    "    \"\"\"\n",
    "    Slightly modified version of stable_baselines3's DummyVecEnv.\n",
    "    - Observations are not flattened.\n",
    "    - Supports actions as either:\n",
    "        * int          -> env.step(action)\n",
    "        * (action, v)  -> env.step(action, volume_fraction=v)\n",
    "    \"\"\"\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        \"\"\"Queue the action for later execution.\"\"\"\n",
    "        self.actions = actions\n",
    "\n",
    "    def step_wait(self):\n",
    "        obs_list = [None] * self.num_envs\n",
    "        for env_idx in range(self.num_envs):\n",
    "\n",
    "            act = self.actions[env_idx]\n",
    "\n",
    "            # support (action, volume_fraction) pairs\n",
    "            if isinstance(act, (tuple, list, np.ndarray)) and len(act) == 2:\n",
    "                a, vol = act\n",
    "                obs_, self.buf_rews[env_idx], self.buf_dones[env_idx], truncated, self.buf_infos[env_idx] = \\\n",
    "                    self.envs[env_idx].step(int(a), volume_fraction=float(vol))\n",
    "            else:\n",
    "                # old behavior: plain discrete action\n",
    "                obs_, self.buf_rews[env_idx], self.buf_dones[env_idx], truncated, self.buf_infos[env_idx] = \\\n",
    "                    self.envs[env_idx].step(act)\n",
    "\n",
    "            obs_list[env_idx] = obs_\n",
    "\n",
    "        return obs_list, self.buf_rews.copy(), self.buf_dones.copy(), self.buf_infos\n",
    "\n",
    "    def reset(self):\n",
    "        obs_list = [None] * self.num_envs\n",
    "        for env_idx in range(self.num_envs):\n",
    "            obs_list[env_idx] = self.envs[env_idx].reset()[0]\n",
    "        return obs_list\n",
    "\n",
    "    def reset_at(self, env_idx):\n",
    "        obs, _ = self.envs[env_idx].reset()\n",
    "        return obs\n",
    "\n",
    "    def train(self):\n",
    "        for env_idx in range(self.num_envs):\n",
    "            self.envs[env_idx].btraining = True\n",
    "\n",
    "    def test(self):\n",
    "        for env_idx in range(self.num_envs):\n",
    "            self.envs[env_idx].btraining = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVecEnvNoFlatten(DummyVecEnv):\n",
    "    \"\"\"\n",
    "    Slightly modified version of stable_baselines3's DummyVecEnv. The main difference is that observations are not\n",
    "    flattened before they are returned. This is done to make it work with our lazy frame-stacking class further below.\n",
    "    \"\"\"\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        \"\"\"Queue the action for later execution.\"\"\"\n",
    "        self.actions = actions\n",
    "        \n",
    "    def step_wait(self):\n",
    "        obs_list = [None] * self.num_envs\n",
    "        for env_idx in range(self.num_envs):\n",
    "            \n",
    "            obs_, self.buf_rews[env_idx], self.buf_dones[env_idx], truncated, self.buf_infos[env_idx] = \\\n",
    "                self.envs[env_idx].step(self.actions[env_idx])\n",
    "            obs_list[env_idx] = obs_\n",
    "            \n",
    "        return obs_list, self.buf_rews.copy(), self.buf_dones.copy(), self.buf_infos\n",
    "\n",
    "    def reset(self):\n",
    "        obs_list = [None] * self.num_envs\n",
    "        for env_idx in range(self.num_envs):\n",
    "            obs_list[env_idx] = self.envs[env_idx].reset()[0]\n",
    "        return obs_list\n",
    "\n",
    "    def reset_at(self, env_idx):\n",
    "        obs, _ = self.envs[env_idx].reset()\n",
    "        return obs\n",
    "\n",
    "    def train(self):\n",
    "        for env_idx in range(self.num_envs):\n",
    "            self.envs[env_idx].btraining = True\n",
    "\n",
    "    def test(self):\n",
    "        for env_idx in range(self.num_envs):\n",
    "            self.envs[env_idx].btraining = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVecEnvNoFlatten_orig(DummyVecEnv):\n",
    "    \"\"\"\n",
    "    Slightly modified version of stable_baselines3's DummyVecEnv. The main difference is that observations are not\n",
    "    flattened before they are returned. This is done to make it work with our lazy frame-stacking class further below.\n",
    "    \"\"\"\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        \"\"\"Queue the action for later execution.\"\"\"\n",
    "        self.actions = actions\n",
    "        \n",
    "    def step_wait(self):\n",
    "        obs_list = []\n",
    "        for env_idx in range(self.num_envs):\n",
    "            \n",
    "            obs_, self.buf_rews[env_idx], self.buf_dones[env_idx], truncated, self.buf_infos[env_idx] = \\\n",
    "                self.envs[env_idx].step(self.actions[env_idx])\n",
    "            \n",
    "            obs_list.append(obs_)\n",
    "            \n",
    "        return obs_list, np.copy(self.buf_rews), np.copy(self.buf_dones), deepcopy(self.buf_infos)\n",
    "\n",
    "    def reset(self):\n",
    "        obs_list = []\n",
    "        for env_idx in range(self.num_envs):\n",
    "            obs, _ = self.envs[env_idx].reset()\n",
    "            obs_list.append(obs)\n",
    "        return obs_list\n",
    "\n",
    "    def reset_at(self, env_idx):\n",
    "        obs, _ = self.envs[env_idx].reset()\n",
    "        return obs\n",
    "\n",
    "    def train(self):\n",
    "        for env_idx in range(self.num_envs):\n",
    "            self.envs[env_idx].btraining = True\n",
    "\n",
    "    def test(self):\n",
    "        for env_idx in range(self.num_envs):\n",
    "            self.envs[env_idx].btraining = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjorn\\miniconda3\\envs\\rlstock\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Function to create environments\n",
    "def make_env(dataenv, rank):\n",
    "    def _init():\n",
    "        env = StockTradingEnvBB(dataenv, rank, ndays=ndays)  # Replace this with your environment\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "# Number of environments to run sequentially\n",
    "#n_envs = 64\n",
    "\n",
    "# Creating the vectorized environments using DummyVecEnv\n",
    "envs = DummyVecEnvNoFlatten([make_env(dataenv, i) for i in range(n_envs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = deque(maxlen=1000)\n",
    "best_score = -10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.0000000e+00]\n",
      "  [ 4.9822646e-01]\n",
      "  [ 4.9856105e-01]\n",
      "  [ 4.9949145e-01]\n",
      "  [ 5.0102049e-01]\n",
      "  [ 5.0226259e-01]\n",
      "  [ 5.0318342e-01]\n",
      "  [ 5.0403947e-01]\n",
      "  [ 5.0475055e-01]\n",
      "  [ 5.0603795e-01]\n",
      "  [ 5.0706512e-01]\n",
      "  [ 5.0818801e-01]\n",
      "  [ 5.0920516e-01]\n",
      "  [ 5.0930190e-01]\n",
      "  [ 5.0919896e-01]\n",
      "  [ 5.0849068e-01]\n",
      "  [ 5.0679439e-01]\n",
      "  [ 5.0364339e-01]\n",
      "  [ 4.9875745e-01]\n",
      "  [ 4.9439627e-01]\n",
      "  [ 4.9002844e-01]\n",
      "  [ 4.8617253e-01]\n",
      "  [ 4.8076516e-01]\n",
      "  [ 4.7527105e-01]\n",
      "  [ 4.6901387e-01]\n",
      "  [ 4.6210036e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 5.0860673e-01]\n",
      "  [ 5.1559120e-01]\n",
      "  [ 5.1838493e-01]\n",
      "  [ 5.2068317e-01]\n",
      "  [ 5.1613194e-01]\n",
      "  [ 5.0856155e-01]\n",
      "  [ 5.0865173e-01]\n",
      "  [ 5.0932759e-01]\n",
      "  [ 5.0108141e-01]\n",
      "  [ 5.0594807e-01]\n",
      "  [ 5.0630850e-01]\n",
      "  [ 5.0851649e-01]\n",
      "  [ 5.0243318e-01]\n",
      "  [ 4.9855793e-01]\n",
      "  [ 4.9869311e-01]\n",
      "  [ 4.9184391e-01]\n",
      "  [ 4.7426996e-01]\n",
      "  [ 4.5228010e-01]\n",
      "  [ 4.5507383e-01]\n",
      "  [ 4.4741341e-01]\n",
      "  [ 4.5466831e-01]\n",
      "  [ 4.3362471e-01]\n",
      "  [ 4.2416176e-01]\n",
      "  [ 4.1834891e-01]\n",
      "  [ 4.0951693e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 5.1227462e-01]\n",
      "  [ 5.1396048e-01]\n",
      "  [ 5.1773256e-01]\n",
      "  [ 5.2227336e-01]\n",
      "  [ 5.2482957e-01]\n",
      "  [ 5.2565128e-01]\n",
      "  [ 5.2636188e-01]\n",
      "  [ 5.2706730e-01]\n",
      "  [ 5.2503210e-01]\n",
      "  [ 5.2429241e-01]\n",
      "  [ 5.2282625e-01]\n",
      "  [ 5.2165043e-01]\n",
      "  [ 5.2151173e-01]\n",
      "  [ 5.2174097e-01]\n",
      "  [ 5.2215564e-01]\n",
      "  [ 5.2228624e-01]\n",
      "  [ 5.2518749e-01]\n",
      "  [ 5.3099811e-01]\n",
      "  [ 5.3211004e-01]\n",
      "  [ 5.3383929e-01]\n",
      "  [ 5.3219491e-01]\n",
      "  [ 5.3211576e-01]\n",
      "  [ 5.3283501e-01]\n",
      "  [ 5.3077024e-01]\n",
      "  [ 5.2718979e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 4.8417830e-01]\n",
      "  [ 4.8316213e-01]\n",
      "  [ 4.8125038e-01]\n",
      "  [ 4.7976756e-01]\n",
      "  [ 4.7969559e-01]\n",
      "  [ 4.8071510e-01]\n",
      "  [ 4.8171699e-01]\n",
      "  [ 4.8243430e-01]\n",
      "  [ 4.8704427e-01]\n",
      "  [ 4.8983780e-01]\n",
      "  [ 4.9355027e-01]\n",
      "  [ 4.9676037e-01]\n",
      "  [ 4.9709162e-01]\n",
      "  [ 4.9665692e-01]\n",
      "  [ 4.9482572e-01]\n",
      "  [ 4.9130297e-01]\n",
      "  [ 4.8209971e-01]\n",
      "  [ 4.6651679e-01]\n",
      "  [ 4.5668203e-01]\n",
      "  [ 4.4621763e-01]\n",
      "  [ 4.4015014e-01]\n",
      "  [ 4.2941502e-01]\n",
      "  [ 4.1770709e-01]\n",
      "  [ 4.0725747e-01]\n",
      "  [ 3.9701039e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 4.9613455e-01]\n",
      "  [ 4.9823743e-01]\n",
      "  [ 5.0035036e-01]\n",
      "  [ 5.0453132e-01]\n",
      "  [ 5.0726002e-01]\n",
      "  [ 5.0925761e-01]\n",
      "  [ 5.1085478e-01]\n",
      "  [ 5.1177084e-01]\n",
      "  [ 5.1189095e-01]\n",
      "  [ 5.1159590e-01]\n",
      "  [ 5.1056451e-01]\n",
      "  [ 5.0946778e-01]\n",
      "  [ 5.0744021e-01]\n",
      "  [ 5.0548744e-01]\n",
      "  [ 5.0439072e-01]\n",
      "  [ 5.0252330e-01]\n",
      "  [ 4.9862826e-01]\n",
      "  [ 4.9320567e-01]\n",
      "  [ 4.8755282e-01]\n",
      "  [ 4.8100919e-01]\n",
      "  [ 4.7502607e-01]\n",
      "  [ 4.6738043e-01]\n",
      "  [ 4.5911425e-01]\n",
      "  [ 4.5018700e-01]\n",
      "  [ 4.4104001e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 5.1205254e-01]\n",
      "  [ 5.1115984e-01]\n",
      "  [ 5.1025087e-01]\n",
      "  [ 5.0934339e-01]\n",
      "  [ 5.0843966e-01]\n",
      "  [ 5.0739205e-01]\n",
      "  [ 5.0645167e-01]\n",
      "  [ 5.0573432e-01]\n",
      "  [ 5.0520432e-01]\n",
      "  [ 5.0462377e-01]\n",
      "  [ 5.0416625e-01]\n",
      "  [ 5.0427967e-01]\n",
      "  [ 5.0411618e-01]\n",
      "  [ 5.0374204e-01]\n",
      "  [ 5.0338739e-01]\n",
      "  [ 5.0285214e-01]\n",
      "  [ 5.0182313e-01]\n",
      "  [ 5.0049144e-01]\n",
      "  [ 4.9932653e-01]\n",
      "  [ 4.9823123e-01]\n",
      "  [ 4.9731421e-01]\n",
      "  [ 4.9582711e-01]\n",
      "  [ 4.9428427e-01]\n",
      "  [ 4.9261081e-01]\n",
      "  [ 4.9069050e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 5.3244698e-01]\n",
      "  [ 5.7592601e-01]\n",
      "  [ 5.9226000e-01]\n",
      "  [ 6.0571301e-01]\n",
      "  [ 5.6589198e-01]\n",
      "  [ 5.0627100e-01]\n",
      "  [ 5.0693798e-01]\n",
      "  [ 5.1225102e-01]\n",
      "  [ 4.4871399e-01]\n",
      "  [ 4.8899800e-01]\n",
      "  [ 4.9195901e-01]\n",
      "  [ 5.1066399e-01]\n",
      "  [ 4.6037099e-01]\n",
      "  [ 4.3123499e-01]\n",
      "  [ 4.3258399e-01]\n",
      "  [ 3.8301399e-01]\n",
      "  [ 2.9090300e-01]\n",
      "  [ 2.1970400e-01]\n",
      "  [ 2.4498700e-01]\n",
      "  [ 2.2359399e-01]\n",
      "  [ 2.8708801e-01]\n",
      "  [ 2.2867200e-01]\n",
      "  [ 2.0816000e-01]\n",
      "  [ 1.9650000e-01]\n",
      "  [ 1.8000200e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 1.6760901e-01]\n",
      "  [ 2.1191800e-01]\n",
      "  [ 2.7285200e-01]\n",
      "  [ 2.4761599e-01]\n",
      "  [ 2.3327100e-01]\n",
      "  [ 2.1685401e-01]\n",
      "  [ 1.9964400e-01]\n",
      "  [ 2.3442100e-01]\n",
      "  [ 2.1641600e-01]\n",
      "  [ 2.0953500e-01]\n",
      "  [ 2.0660999e-01]\n",
      "  [ 2.0738900e-01]\n",
      "  [ 2.2084400e-01]\n",
      "  [ 2.0391700e-01]\n",
      "  [ 1.9468801e-01]\n",
      "  [ 1.8444100e-01]\n",
      "  [ 1.6182099e-01]\n",
      "  [ 1.3294800e-01]\n",
      "  [ 1.2417600e-01]\n",
      "  [ 1.1521500e-01]\n",
      "  [ 1.0858400e-01]\n",
      "  [ 9.3501002e-02]\n",
      "  [ 8.5506000e-02]\n",
      "  [ 8.1405997e-02]\n",
      "  [ 7.4592002e-02]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 1.9660500e-01]\n",
      "  [ 1.8222700e-01]\n",
      "  [ 1.6475999e-01]\n",
      "  [ 2.0394400e-01]\n",
      "  [ 1.9213000e-01]\n",
      "  [ 2.0639800e-01]\n",
      "  [ 2.3284200e-01]\n",
      "  [ 2.1368399e-01]\n",
      "  [ 2.7142701e-01]\n",
      "  [ 2.5678000e-01]\n",
      "  [ 2.4416600e-01]\n",
      "  [ 2.3529799e-01]\n",
      "  [ 2.1228100e-01]\n",
      "  [ 2.5695801e-01]\n",
      "  [ 2.4532899e-01]\n",
      "  [ 2.4823800e-01]\n",
      "  [ 3.3708200e-01]\n",
      "  [ 4.5050499e-01]\n",
      "  [ 4.2078099e-01]\n",
      "  [ 4.3138200e-01]\n",
      "  [ 4.0655601e-01]\n",
      "  [ 4.4098499e-01]\n",
      "  [ 4.5508400e-01]\n",
      "  [ 4.4898701e-01]\n",
      "  [ 4.6152601e-01]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 3.0696401e-01]\n",
      "  [ 2.9041800e-01]\n",
      "  [ 2.8731701e-01]\n",
      "  [ 2.7370301e-01]\n",
      "  [ 2.6106101e-01]\n",
      "  [ 2.4417800e-01]\n",
      "  [ 2.3221999e-01]\n",
      "  [ 2.1893799e-01]\n",
      "  [ 2.1135400e-01]\n",
      "  [ 2.0349400e-01]\n",
      "  [ 1.9491000e-01]\n",
      "  [ 1.8549100e-01]\n",
      "  [ 1.7365400e-01]\n",
      "  [ 1.6947000e-01]\n",
      "  [ 1.6558599e-01]\n",
      "  [ 1.6429000e-01]\n",
      "  [ 1.7764799e-01]\n",
      "  [ 2.0383500e-01]\n",
      "  [ 2.2815201e-01]\n",
      "  [ 2.5317201e-01]\n",
      "  [ 2.7640501e-01]\n",
      "  [ 3.0309901e-01]\n",
      "  [ 3.3028200e-01]\n",
      "  [ 3.5619301e-01]\n",
      "  [ 3.8230300e-01]]\n",
      "\n",
      " [[ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]]\n",
      "\n",
      " [[ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]]\n",
      "\n",
      " [[ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]\n",
      "  [ 9.9999999e-09]]\n",
      "\n",
      " [[-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]\n",
      "  [-8.0785722e-01]]\n",
      "\n",
      " [[ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]\n",
      "  [ 9.7818631e-01]]\n",
      "\n",
      " [[ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]]\n",
      "\n",
      " [[ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]\n",
      "  [ 0.0000000e+00]]\n",
      "\n",
      " [[ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]\n",
      "  [ 1.0000000e+00]]]\n",
      "[2026-01-19 11:17:34] ## n_step 0 score 0.000 best score -10.000\n",
      "[2026-01-19 11:17:51] ## n_step 16000 score -6.330 best score 1.017\n",
      "[2026-01-19 11:18:07] ## n_step 32000 score -6.627 best score 1.017\n",
      "[2026-01-19 11:18:24] ## n_step 48000 score -8.144 best score 1.017\n",
      "[2026-01-19 11:18:42] ## n_step 64000 score -7.933 best score 1.017\n",
      "[2026-01-19 11:18:59] ## n_step 80000 score -5.240 best score 1.017\n",
      "[2026-01-19 11:20:17] ## n_step 96000 score -9.543 best score 1.017 loss 0.00524\n",
      "[2026-01-19 11:21:33] ## n_step 112000 score -4.332 best score 1.017 loss 0.00480\n",
      "[2026-01-19 11:22:47] ## n_step 128000 score -5.780 best score 1.017 loss 0.00514\n",
      "step= 2000 a= 1.1330856084823608 b= 0.39672765135765076 std= 0.8825458884239197 freeze= True\n",
      "[2026-01-19 11:24:00] ## n_step 144000 score -5.074 best score 1.017 loss 0.00406\n",
      "[2026-01-19 11:25:14] ## n_step 160000 score -3.880 best score 1.017 loss 0.00488\n",
      "[2026-01-19 11:26:26] ## n_step 176000 score -8.141 best score 1.017 loss 0.00426\n",
      "[2026-01-19 11:27:39] ## n_step 192000 score -5.868 best score 1.017 loss 0.00344\n",
      "step= 4000 a= 0.6953405737876892 b= 0.3911910653114319 std= 1.4381442070007324 freeze= True\n",
      "[2026-01-19 11:28:54] ## n_step 208000 score -9.328 best score 1.017 loss 0.00311\n",
      "[2026-01-19 11:30:07] ## n_step 224000 score -6.806 best score 1.017 loss 0.00335\n",
      "[2026-01-19 11:31:20] ## n_step 240000 score -7.415 best score 1.017 loss 0.00329\n",
      "[2026-01-19 11:32:33] ## n_step 256000 score -5.116 best score 1.017 loss 0.00212\n",
      "step= 6000 a= 0.5019880533218384 b= 0.4141302704811096 std= 1.992079257965088 freeze= True\n",
      "[2026-01-19 11:33:48] ## n_step 272000 score -6.493 best score 1.017 loss 0.00270\n",
      "[2026-01-19 11:35:00] ## n_step 288000 score -5.117 best score 1.017 loss 0.00215\n",
      "[2026-01-19 11:36:12] ## n_step 304000 score -5.904 best score 1.017 loss 0.00239\n",
      "[2026-01-19 11:37:25] ## n_step 320000 score -5.168 best score 1.017 loss 0.00237\n",
      "step= 8000 a= 0.40931591391563416 b= 0.49100932478904724 std= 2.443100690841675 freeze= True\n",
      "[2026-01-19 11:38:39] ## n_step 336000 score -6.151 best score 1.017 loss 0.00222\n",
      "[2026-01-19 11:39:52] ## n_step 352000 score -7.204 best score 1.017 loss 0.00258\n",
      "[2026-01-19 11:41:04] ## n_step 368000 score -4.010 best score 1.017 loss 0.00132\n",
      "[2026-01-19 11:42:16] ## n_step 384000 score -7.741 best score 1.017 loss 0.00211\n",
      "step= 10000 a= 0.3488598167896271 b= 0.5524128079414368 std= 2.866480827331543 freeze= True\n",
      "[2026-01-19 11:43:30] ## n_step 400000 score -7.864 best score 1.017 loss 0.00176\n",
      "[2026-01-19 11:44:44] ## n_step 416000 score -7.947 best score 1.017 loss 0.00190\n",
      "[2026-01-19 11:45:57] ## n_step 432000 score -3.621 best score 1.017 loss 0.00222\n",
      "[2026-01-19 11:47:10] ## n_step 448000 score -9.073 best score 1.017 loss 0.00189\n",
      "step= 12000 a= 0.312887579202652 b= 0.6697989106178284 std= 3.1960361003875732 freeze= True\n",
      "[2026-01-19 11:48:24] ## n_step 464000 score -8.035 best score 1.017 loss 0.00153\n",
      "[2026-01-19 11:49:39] ## n_step 480000 score -4.730 best score 1.017 loss 0.00199\n",
      "[2026-01-19 11:50:53] ## n_step 496000 score -5.356 best score 1.017 loss 0.00202\n",
      "[2026-01-19 11:52:06] ## n_step 512000 score -1.316 best score 1.017 loss 0.00191\n",
      "step= 14000 a= 0.28500038385391235 b= 0.7098265290260315 std= 3.5087671279907227 freeze= True\n",
      "[2026-01-19 11:53:24] ## n_step 528000 score -8.431 best score 1.017 loss 0.00121\n",
      "[2026-01-19 11:54:39] ## n_step 544000 score -9.129 best score 1.017 loss 0.00163\n",
      "[2026-01-19 11:55:53] ## n_step 560000 score -9.632 best score 1.017 loss 0.00136\n",
      "[2026-01-19 11:57:06] ## n_step 576000 score -9.790 best score 1.017 loss 0.00165\n",
      "step= 16000 a= 0.2738229036331177 b= 0.7844706773757935 std= 3.6519954204559326 freeze= True\n",
      "[2026-01-19 11:58:19] ## n_step 592000 score -7.841 best score 1.017 loss 0.00130\n",
      "[2026-01-19 11:59:34] ## n_step 608000 score -4.445 best score 1.017 loss 0.00124\n",
      "[2026-01-19 12:00:46] ## n_step 624000 score -5.196 best score 1.017 loss 0.00153\n",
      "[2026-01-19 12:01:59] ## n_step 640000 score -5.740 best score 1.017 loss 0.00118\n",
      "step= 18000 a= 0.26970550417900085 b= 0.8065212965011597 std= 3.7077479362487793 freeze= True\n",
      "[2026-01-19 12:03:13] ## n_step 656000 score -4.303 best score 1.017 loss 0.00149\n",
      "[2026-01-19 12:04:27] ## n_step 672000 score -7.274 best score 1.017 loss 0.00143\n",
      "[2026-01-19 12:05:41] ## n_step 688000 score -9.152 best score 1.017 loss 0.00132\n",
      "[2026-01-19 12:06:54] ## n_step 704000 score -7.857 best score 1.017 loss 0.00135\n",
      "step= 20000 a= 0.26725655794143677 b= 0.8321389555931091 std= 3.74172306060791 freeze= True\n",
      "[2026-01-19 12:08:08] ## n_step 720000 score -9.158 best score 1.017 loss 0.00100\n",
      "[2026-01-19 12:09:22] ## n_step 736000 score -7.921 best score 1.017 loss 0.00180\n",
      "[2026-01-19 12:10:35] ## n_step 752000 score -6.701 best score 1.017 loss 0.00142\n",
      "[2026-01-19 12:11:48] ## n_step 768000 score -7.603 best score 1.017 loss 0.00111\n",
      "step= 22000 a= 0.26157087087631226 b= 0.8362118601799011 std= 3.8230557441711426 freeze= True\n",
      "[2026-01-19 12:13:01] ## n_step 784000 score -6.441 best score 1.017 loss 0.00102\n",
      "[2026-01-19 12:14:15] ## n_step 800000 score -4.722 best score 1.017 loss 0.00128\n",
      "[2026-01-19 12:15:28] ## n_step 816000 score -6.556 best score 1.017 loss 0.00125\n",
      "[2026-01-19 12:16:42] ## n_step 832000 score -10.328 best score 1.017 loss 0.00145\n",
      "step= 24000 a= 0.2542560398578644 b= 0.8335635662078857 std= 3.9330432415008545 freeze= True\n",
      "[2026-01-19 12:17:55] ## n_step 848000 score -9.596 best score 1.017 loss 0.00110\n",
      "[2026-01-19 12:19:09] ## n_step 864000 score -9.710 best score 1.017 loss 0.00119\n",
      "[2026-01-19 12:20:23] ## n_step 880000 score -10.018 best score 1.017 loss 0.00135\n",
      "[2026-01-19 12:21:36] ## n_step 896000 score -7.691 best score 1.017 loss 0.00100\n",
      "step= 26000 a= 0.2546314597129822 b= 0.872997522354126 std= 3.9272444248199463 freeze= True\n",
      "[2026-01-19 12:22:49] ## n_step 912000 score -9.427 best score 1.017 loss 0.00166\n",
      "[2026-01-19 12:24:02] ## n_step 928000 score -5.829 best score 1.017 loss 0.00125\n",
      "[2026-01-19 12:25:16] ## n_step 944000 score -8.366 best score 1.017 loss 0.00098\n",
      "[2026-01-19 12:26:28] ## n_step 960000 score -12.218 best score 1.017 loss 0.00099\n",
      "step= 28000 a= 0.2603955566883087 b= 0.915245771408081 std= 3.840311288833618 freeze= True\n",
      "[2026-01-19 12:27:42] ## n_step 976000 score -13.252 best score 1.017 loss 0.00124\n",
      "[2026-01-19 12:28:55] ## n_step 992000 score -7.290 best score 1.017 loss 0.00145\n",
      "[2026-01-19 12:29:32] ## evaluating\n",
      "HNR1.DE Human:112.8 AI:87.2\n",
      "PM Human:124.9 AI:75.1\n",
      "HAL Human:124.9 AI:63.0\n",
      "BAYN.DE Human:111.8 AI:63.0\n",
      "NUE Human:123.2 AI:51.5\n",
      "CHD Human:134.0 AI:40.7\n",
      "SEDG Human:144.2 AI:30.5\n",
      "FTV Human:130.9 AI:30.5\n",
      "DLTR Human:130.9 AI:20.7\n",
      "CINF Human:140.6 AI:11.0\n",
      "score_eval=0.948 best_score_eval=0.948\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 573 Bought: 573\n",
      "Balance: 9,965.55 Net worth: 9,965.55 Max worth: 10,028.63 total_sales: 9,581.46\n",
      "Avg price bought: 1.00 Avg price_sold: 16.72\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-19 12:31:04] ## n_step 1008000 score -11.904 best score 1.017 loss 0.00110\n",
      "[2026-01-19 12:32:16] ## n_step 1024000 score -9.149 best score 1.017 loss 0.00086\n",
      "step= 30000 a= 0.26234909892082214 b= 0.9377143383026123 std= 3.8117151260375977 freeze= True\n",
      "[2026-01-19 12:33:29] ## n_step 1040000 score -9.994 best score 1.017 loss 0.00139\n",
      "[2026-01-19 12:34:43] ## n_step 1056000 score -6.644 best score 1.017 loss 0.00107\n",
      "[2026-01-19 12:35:56] ## n_step 1072000 score -9.672 best score 1.017 loss 0.00133\n",
      "[2026-01-19 12:37:10] ## n_step 1088000 score -10.298 best score 1.017 loss 0.00139\n",
      "step= 32000 a= 0.27091851830482483 b= 0.9777652621269226 std= 3.6911466121673584 freeze= True\n",
      "[2026-01-19 12:38:24] ## n_step 1104000 score -11.426 best score 1.017 loss 0.00111\n",
      "[2026-01-19 12:39:37] ## n_step 1120000 score -11.995 best score 1.017 loss 0.00111\n",
      "[2026-01-19 12:40:51] ## n_step 1136000 score -8.985 best score 1.017 loss 0.00095\n",
      "[2026-01-19 12:42:05] ## n_step 1152000 score -6.209 best score 1.017 loss 0.00108\n",
      "step= 34000 a= 0.28347617387771606 b= 1.0271854400634766 std= 3.5276334285736084 freeze= True\n",
      "[2026-01-19 12:43:18] ## n_step 1168000 score -8.575 best score 1.017 loss 0.00107\n",
      "[2026-01-19 12:44:32] ## n_step 1184000 score -10.482 best score 1.017 loss 0.00085\n",
      "[2026-01-19 12:45:45] ## n_step 1200000 score -9.136 best score 1.017 loss 0.00091\n",
      "[2026-01-19 12:46:58] ## n_step 1216000 score -8.396 best score 1.017 loss 0.00121\n",
      "step= 36000 a= 0.29410311579704285 b= 1.0773262977600098 std= 3.400167942047119 freeze= True\n",
      "[2026-01-19 12:48:12] ## n_step 1232000 score -9.430 best score 1.017 loss 0.00118\n",
      "[2026-01-19 12:49:25] ## n_step 1248000 score -9.038 best score 1.017 loss 0.00118\n",
      "[2026-01-19 12:50:40] ## n_step 1264000 score -6.300 best score 1.017 loss 0.00117\n",
      "[2026-01-19 12:51:53] ## n_step 1280000 score -12.691 best score 1.017 loss 0.00095\n",
      "step= 38000 a= 0.30047842860221863 b= 1.089386224746704 std= 3.3280258178710938 freeze= True\n",
      "[2026-01-19 12:53:05] ## n_step 1296000 score -5.364 best score 1.017 loss 0.00104\n",
      "[2026-01-19 12:54:18] ## n_step 1312000 score -11.221 best score 1.017 loss 0.00095\n",
      "[2026-01-19 12:55:31] ## n_step 1328000 score -7.765 best score 1.017 loss 0.00092\n",
      "[2026-01-19 12:56:44] ## n_step 1344000 score -7.757 best score 1.017 loss 0.00114\n",
      "step= 40000 a= 0.3059263527393341 b= 1.098449468612671 std= 3.2687606811523438 freeze= True\n",
      "[2026-01-19 12:57:58] ## n_step 1360000 score -12.063 best score 1.017 loss 0.00092\n",
      "[2026-01-19 12:59:11] ## n_step 1376000 score -7.893 best score 1.017 loss 0.00101\n",
      "[2026-01-19 13:00:24] ## n_step 1392000 score -11.927 best score 1.017 loss 0.00101\n",
      "[2026-01-19 13:01:37] ## n_step 1408000 score -5.895 best score 1.017 loss 0.00100\n",
      "step= 42000 a= 0.3120073080062866 b= 1.1083799600601196 std= 3.2050530910491943 freeze= True\n",
      "[2026-01-19 13:02:51] ## n_step 1424000 score -9.243 best score 1.017 loss 0.00087\n",
      "[2026-01-19 13:04:04] ## n_step 1440000 score -11.172 best score 1.017 loss 0.00098\n",
      "[2026-01-19 13:05:17] ## n_step 1456000 score -4.595 best score 1.017 loss 0.00070\n",
      "[2026-01-19 13:06:29] ## n_step 1472000 score -9.098 best score 1.017 loss 0.00103\n",
      "step= 44000 a= 0.3122555613517761 b= 1.0860618352890015 std= 3.202504873275757 freeze= True\n",
      "[2026-01-19 13:07:42] ## n_step 1488000 score -7.507 best score 1.017 loss 0.00115\n",
      "[2026-01-19 13:08:56] ## n_step 1504000 score -7.900 best score 1.017 loss 0.00109\n",
      "[2026-01-19 13:10:09] ## n_step 1520000 score -7.468 best score 1.017 loss 0.00107\n",
      "[2026-01-19 13:11:22] ## n_step 1536000 score -6.868 best score 1.017 loss 0.00095\n",
      "step= 46000 a= 0.310364305973053 b= 1.04923677444458 std= 3.222020149230957 freeze= True\n",
      "[2026-01-19 13:12:35] ## n_step 1552000 score -4.310 best score 1.017 loss 0.00108\n",
      "[2026-01-19 13:13:48] ## n_step 1568000 score -5.208 best score 1.017 loss 0.00100\n",
      "[2026-01-19 13:15:02] ## n_step 1584000 score -10.109 best score 1.017 loss 0.00097\n",
      "[2026-01-19 13:16:16] ## n_step 1600000 score -7.586 best score 1.017 loss 0.00112\n",
      "step= 48000 a= 0.31116408109664917 b= 1.0086601972579956 std= 3.213738441467285 freeze= True\n",
      "[2026-01-19 13:17:29] ## n_step 1616000 score -9.917 best score 1.017 loss 0.00091\n",
      "[2026-01-19 13:18:42] ## n_step 1632000 score -7.816 best score 1.017 loss 0.00103\n",
      "[2026-01-19 13:19:55] ## n_step 1648000 score -5.100 best score 1.017 loss 0.00083\n",
      "[2026-01-19 13:21:08] ## n_step 1664000 score -8.317 best score 1.017 loss 0.00095\n",
      "step= 50000 a= 0.31366273760795593 b= 0.9757930040359497 std= 3.1881377696990967 freeze= True\n",
      "[2026-01-19 13:22:21] ## n_step 1680000 score -6.763 best score 1.017 loss 0.00091\n",
      "[2026-01-19 13:23:35] ## n_step 1696000 score -8.445 best score 1.017 loss 0.00092\n",
      "[2026-01-19 13:24:48] ## n_step 1712000 score -6.858 best score 1.017 loss 0.00106\n",
      "[2026-01-19 13:26:01] ## n_step 1728000 score -8.503 best score 1.017 loss 0.00070\n",
      "step= 52000 a= 0.3159753978252411 b= 0.9544569849967957 std= 3.1648035049438477 freeze= True\n",
      "[2026-01-19 13:27:14] ## n_step 1744000 score -7.498 best score 1.017 loss 0.00091\n",
      "[2026-01-19 13:28:26] ## n_step 1760000 score -7.750 best score 1.017 loss 0.00098\n",
      "[2026-01-19 13:29:39] ## n_step 1776000 score -11.298 best score 1.017 loss 0.00068\n",
      "[2026-01-19 13:30:53] ## n_step 1792000 score -7.891 best score 1.017 loss 0.00100\n",
      "step= 54000 a= 0.315574586391449 b= 0.9350118637084961 std= 3.168823003768921 freeze= True\n",
      "[2026-01-19 13:32:06] ## n_step 1808000 score -7.992 best score 1.017 loss 0.00101\n",
      "[2026-01-19 13:33:24] ## n_step 1824000 score -6.948 best score 1.017 loss 0.00085\n",
      "[2026-01-19 13:34:37] ## n_step 1840000 score -3.213 best score 1.017 loss 0.00088\n",
      "[2026-01-19 13:35:51] ## n_step 1856000 score -7.322 best score 1.017 loss 0.00093\n",
      "step= 56000 a= 0.31167516112327576 b= 0.9108293652534485 std= 3.2084686756134033 freeze= True\n",
      "[2026-01-19 13:37:05] ## n_step 1872000 score -4.951 best score 1.017 loss 0.00099\n",
      "[2026-01-19 13:38:18] ## n_step 1888000 score -7.027 best score 1.017 loss 0.00106\n",
      "[2026-01-19 13:39:31] ## n_step 1904000 score -6.337 best score 1.017 loss 0.00083\n",
      "[2026-01-19 13:40:47] ## n_step 1920000 score -1.273 best score 1.017 loss 0.00115\n",
      "step= 58000 a= 0.3123905658721924 b= 0.9039555191993713 std= 3.2011208534240723 freeze= True\n",
      "[2026-01-19 13:42:00] ## n_step 1936000 score -6.165 best score 1.316 loss 0.00101\n",
      "[2026-01-19 13:43:13] ## n_step 1952000 score -0.475 best score 1.316 loss 0.00094\n",
      "[2026-01-19 13:44:26] ## n_step 1968000 score -4.587 best score 1.316 loss 0.00073\n",
      "[2026-01-19 13:45:39] ## n_step 1984000 score -3.371 best score 1.316 loss 0.00079\n",
      "step= 60000 a= 0.3106788396835327 b= 0.8682196736335754 std= 3.2187581062316895 freeze= True\n",
      "[2026-01-19 13:46:52] ## n_step 2000000 score -3.817 best score 1.316 loss 0.00072\n",
      "[2026-01-19 13:46:52] ## evaluating\n",
      "EQIX Human:112.5 AI:26.6\n",
      "PFE Human:97.6 AI:41.5\n",
      "ABT Human:83.4 AI:55.7\n",
      "BA Human:95.5 AI:43.6\n",
      "VRTX Human:106.8 AI:32.2\n",
      "BLK Human:117.6 AI:21.5\n",
      "PENN Human:105.9 AI:21.5\n",
      "HUBB Human:116.4 AI:11.1\n",
      "HSY Human:126.2 AI:1.2\n",
      "TRV Human:135.5 AI:-8.1\n",
      "score_eval=0.938 best_score_eval=0.948\n",
      "Tick: T  step: 353 steps: 200 Hold: 102 Sold: 1,865 Bought: 1,967\n",
      "Balance: 8,189.39 Net worth: 9,640.44 Max worth: 11,898.41 total_sales: 28,437.58\n",
      "Avg price bought: 1.00 Avg price_sold: 15.25\n",
      "0.91 vs \u001b[6;30;42m0.96\u001b[0m model performance\n",
      "\n",
      "[2026-01-19 13:49:03] ## n_step 2016000 score -2.321 best score 1.316 loss 0.00084\n",
      "[2026-01-19 13:50:16] ## n_step 2032000 score -3.981 best score 1.316 loss 0.00082\n",
      "[2026-01-19 13:51:30] ## n_step 2048000 score -4.184 best score 1.316 loss 0.00076\n",
      "step= 62000 a= 0.30596286058425903 b= 0.824700653553009 std= 3.2683706283569336 freeze= True\n",
      "[2026-01-19 13:52:43] ## n_step 2064000 score -4.680 best score 1.316 loss 0.00072\n",
      "[2026-01-19 13:53:56] ## n_step 2080000 score -3.791 best score 1.316 loss 0.00076\n",
      "[2026-01-19 13:55:11] ## n_step 2096000 score -1.871 best score 1.316 loss 0.00083\n",
      "[2026-01-19 13:56:23] ## n_step 2112000 score -7.093 best score 1.316 loss 0.00083\n",
      "step= 64000 a= 0.3060806393623352 b= 0.8143189549446106 std= 3.267112970352173 freeze= True\n",
      "[2026-01-19 13:57:36] ## n_step 2128000 score -5.582 best score 1.316 loss 0.00103\n",
      "[2026-01-19 13:58:50] ## n_step 2144000 score -2.611 best score 1.316 loss 0.00079\n",
      "[2026-01-19 14:00:03] ## n_step 2160000 score -3.461 best score 1.316 loss 0.00081\n",
      "[2026-01-19 14:01:16] ## n_step 2176000 score -0.392 best score 1.316 loss 0.00092\n",
      "step= 66000 a= 0.3074043095111847 b= 0.7942850589752197 std= 3.253044843673706 freeze= True\n",
      "[2026-01-19 14:02:29] ## n_step 2192000 score -3.646 best score 1.316 loss 0.00087\n",
      "[2026-01-19 14:03:42] ## n_step 2208000 score -4.120 best score 1.316 loss 0.00102\n",
      "[2026-01-19 14:04:56] ## n_step 2224000 score -1.059 best score 1.316 loss 0.00087\n",
      "[2026-01-19 14:06:09] ## n_step 2240000 score 1.853 best score 2.558 loss 0.00061\n",
      "step= 68000 a= 0.3103087544441223 b= 0.7456032633781433 std= 3.2225968837738037 freeze= True\n",
      "[2026-01-19 14:07:23] ## n_step 2256000 score -2.169 best score 2.558 loss 0.00079\n",
      "[2026-01-19 14:08:36] ## n_step 2272000 score 1.516 best score 2.558 loss 0.00066\n",
      "[2026-01-19 14:09:50] ## n_step 2288000 score -0.052 best score 2.558 loss 0.00076\n",
      "[2026-01-19 14:11:03] ## n_step 2304000 score -1.268 best score 2.558 loss 0.00067\n",
      "step= 70000 a= 0.3204731345176697 b= 0.6725822687149048 std= 3.1203863620758057 freeze= True\n",
      "[2026-01-19 14:12:16] ## n_step 2320000 score 0.080 best score 2.558 loss 0.00067\n",
      "[2026-01-19 14:13:29] ## n_step 2336000 score 0.142 best score 2.995 loss 0.00068\n",
      "[2026-01-19 14:14:43] ## n_step 2352000 score -0.439 best score 2.995 loss 0.00070\n",
      "[2026-01-19 14:15:57] ## n_step 2368000 score -1.075 best score 2.995 loss 0.00073\n",
      "step= 72000 a= 0.32855722308158875 b= 0.6110055446624756 std= 3.043609857559204 freeze= True\n",
      "[2026-01-19 14:17:10] ## n_step 2384000 score 2.103 best score 2.995 loss 0.00061\n",
      "[2026-01-19 14:18:23] ## n_step 2400000 score 3.039 best score 5.349 loss 0.00081\n",
      "[2026-01-19 14:19:37] ## n_step 2416000 score -0.372 best score 5.349 loss 0.00074\n",
      "[2026-01-19 14:20:50] ## n_step 2432000 score -2.155 best score 5.349 loss 0.00088\n",
      "step= 74000 a= 0.33216503262519836 b= 0.5352464914321899 std= 3.010551691055298 freeze= True\n",
      "[2026-01-19 14:22:04] ## n_step 2448000 score 0.831 best score 5.349 loss 0.00080\n",
      "[2026-01-19 14:23:17] ## n_step 2464000 score -2.120 best score 5.349 loss 0.00072\n",
      "[2026-01-19 14:24:30] ## n_step 2480000 score 0.686 best score 5.349 loss 0.00083\n",
      "[2026-01-19 14:25:43] ## n_step 2496000 score -1.650 best score 5.349 loss 0.00084\n",
      "step= 76000 a= 0.3310869038105011 b= 0.4452505111694336 std= 3.020354986190796 freeze= True\n",
      "[2026-01-19 14:26:57] ## n_step 2512000 score -4.247 best score 5.349 loss 0.00087\n",
      "[2026-01-19 14:28:10] ## n_step 2528000 score 3.720 best score 5.349 loss 0.00071\n",
      "[2026-01-19 14:29:24] ## n_step 2544000 score -1.502 best score 5.349 loss 0.00063\n",
      "[2026-01-19 14:30:38] ## n_step 2560000 score 0.283 best score 5.349 loss 0.00057\n",
      "step= 78000 a= 0.3234480023384094 b= 0.3900631368160248 std= 3.091686964035034 freeze= True\n",
      "[2026-01-19 14:31:51] ## n_step 2576000 score -1.968 best score 5.349 loss 0.00065\n",
      "[2026-01-19 14:33:04] ## n_step 2592000 score 1.278 best score 5.349 loss 0.00064\n",
      "[2026-01-19 14:34:12] ## n_step 2608000 score -2.502 best score 5.349 loss 0.00075\n",
      "[2026-01-19 14:35:27] ## n_step 2624000 score -3.271 best score 5.349 loss 0.00068\n",
      "step= 80000 a= 0.3156243860721588 b= 0.38330909609794617 std= 3.168323040008545 freeze= True\n",
      "[2026-01-19 14:36:42] ## n_step 2640000 score -2.730 best score 5.349 loss 0.00067\n",
      "[2026-01-19 14:37:57] ## n_step 2656000 score -2.175 best score 5.349 loss 0.00061\n",
      "[2026-01-19 14:39:11] ## n_step 2672000 score -1.406 best score 5.349 loss 0.00072\n",
      "[2026-01-19 14:40:28] ## n_step 2688000 score -0.466 best score 5.349 loss 0.00060\n",
      "step= 82000 a= 0.30983099341392517 b= 0.3668883144855499 std= 3.2275660037994385 freeze= True\n",
      "[2026-01-19 14:41:45] ## n_step 2704000 score -1.557 best score 5.349 loss 0.00060\n",
      "[2026-01-19 14:42:59] ## n_step 2720000 score -2.018 best score 5.349 loss 0.00052\n",
      "[2026-01-19 14:44:13] ## n_step 2736000 score 1.316 best score 5.349 loss 0.00087\n",
      "[2026-01-19 14:45:27] ## n_step 2752000 score 0.306 best score 5.349 loss 0.00047\n",
      "step= 84000 a= 0.3028697371482849 b= 0.35916057229042053 std= 3.3017494678497314 freeze= True\n",
      "[2026-01-19 14:46:43] ## n_step 2768000 score 3.867 best score 5.349 loss 0.00059\n",
      "[2026-01-19 14:47:56] ## n_step 2784000 score 0.493 best score 5.349 loss 0.00058\n",
      "[2026-01-19 14:49:10] ## n_step 2800000 score -0.538 best score 5.349 loss 0.00065\n",
      "[2026-01-19 14:50:24] ## n_step 2816000 score 2.999 best score 5.349 loss 0.00058\n",
      "step= 86000 a= 0.29327699542045593 b= 0.3420305550098419 std= 3.409745693206787 freeze= True\n",
      "[2026-01-19 14:51:37] ## n_step 2832000 score 0.280 best score 5.349 loss 0.00052\n",
      "[2026-01-19 14:52:50] ## n_step 2848000 score 1.686 best score 5.349 loss 0.00054\n",
      "[2026-01-19 14:54:04] ## n_step 2864000 score 1.849 best score 5.349 loss 0.00068\n",
      "[2026-01-19 14:55:18] ## n_step 2880000 score 1.933 best score 5.349 loss 0.00048\n",
      "step= 88000 a= 0.2889759838581085 b= 0.33862921595573425 std= 3.4604952335357666 freeze= True\n",
      "[2026-01-19 14:56:32] ## n_step 2896000 score -0.576 best score 5.349 loss 0.00042\n",
      "[2026-01-19 14:57:45] ## n_step 2912000 score 1.328 best score 5.349 loss 0.00050\n",
      "[2026-01-19 14:58:58] ## n_step 2928000 score -3.024 best score 5.349 loss 0.00052\n",
      "[2026-01-19 15:00:12] ## n_step 2944000 score -0.401 best score 5.349 loss 0.00032\n",
      "step= 90000 a= 0.28527480363845825 b= 0.33441615104675293 std= 3.505392074584961 freeze= True\n",
      "[2026-01-19 15:01:25] ## n_step 2960000 score 0.824 best score 5.349 loss 0.00052\n",
      "[2026-01-19 15:02:38] ## n_step 2976000 score -0.532 best score 5.349 loss 0.00048\n",
      "[2026-01-19 15:03:51] ## n_step 2992000 score -0.483 best score 5.349 loss 0.00065\n",
      "[2026-01-19 15:04:28] ## evaluating\n",
      "MTB Human:107.9 AI:7.8\n",
      "BIO Human:92.7 AI:23.0\n",
      "AES Human:78.2 AI:37.5\n",
      "BR Human:89.9 AI:25.8\n",
      "KEY Human:79.7 AI:25.8\n",
      "WMB Human:65.5 AI:40.0\n",
      "ZS Human:77.6 AI:27.9\n",
      "HSIC Human:77.6 AI:19.8\n",
      "OI Human:68.4 AI:19.8\n",
      "STE Human:79.8 AI:8.3\n",
      "score_eval=1.028 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 434 Sold: 3,663 Bought: 4,097\n",
      "Balance: 3,814.73 Net worth: 9,988.80 Max worth: 12,384.67 total_sales: 60,538.58\n",
      "Avg price bought: 1.00 Avg price_sold: 16.53\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-19 15:05:59] ## n_step 3008000 score -0.324 best score 5.349 loss 0.00048\n",
      "step= 92000 a= 0.2815793752670288 b= 0.33301088213920593 std= 3.551396608352661 freeze= True\n",
      "[2026-01-19 15:07:13] ## n_step 3024000 score 1.011 best score 5.349 loss 0.00034\n",
      "[2026-01-19 15:08:26] ## n_step 3040000 score 1.995 best score 5.349 loss 0.00047\n",
      "[2026-01-19 15:09:40] ## n_step 3056000 score -0.483 best score 5.349 loss 0.00040\n",
      "[2026-01-19 15:10:54] ## n_step 3072000 score -4.398 best score 5.349 loss 0.00057\n",
      "step= 94000 a= 0.28029826283454895 b= 0.3393891155719757 std= 3.5676281452178955 freeze= True\n",
      "[2026-01-19 15:12:07] ## n_step 3088000 score -2.382 best score 5.349 loss 0.00038\n",
      "[2026-01-19 15:13:20] ## n_step 3104000 score -3.070 best score 5.349 loss 0.00044\n",
      "[2026-01-19 15:14:34] ## n_step 3120000 score -4.331 best score 5.349 loss 0.00041\n",
      "[2026-01-19 15:15:47] ## n_step 3136000 score -0.737 best score 5.349 loss 0.00038\n",
      "step= 96000 a= 0.2773892879486084 b= 0.3431161046028137 std= 3.605041742324829 freeze= True\n",
      "[2026-01-19 15:17:01] ## n_step 3152000 score 0.509 best score 5.349 loss 0.00047\n",
      "[2026-01-19 15:18:15] ## n_step 3168000 score -0.655 best score 5.349 loss 0.00043\n",
      "[2026-01-19 15:19:29] ## n_step 3184000 score -2.777 best score 5.349 loss 0.00036\n",
      "[2026-01-19 15:20:43] ## n_step 3200000 score -6.110 best score 5.349 loss 0.00045\n",
      "step= 98000 a= 0.27709537744522095 b= 0.35474464297294617 std= 3.608865737915039 freeze= True\n",
      "[2026-01-19 15:21:56] ## n_step 3216000 score -0.260 best score 5.349 loss 0.00043\n",
      "[2026-01-19 15:23:10] ## n_step 3232000 score -1.562 best score 5.349 loss 0.00039\n",
      "[2026-01-19 15:24:23] ## n_step 3248000 score -5.485 best score 5.349 loss 0.00046\n",
      "[2026-01-19 15:25:38] ## n_step 3264000 score -4.003 best score 5.349 loss 0.00043\n",
      "step= 100000 a= 0.2757576107978821 b= 0.3794049024581909 std= 3.626373052597046 freeze= True\n",
      "[2026-01-19 15:26:51] ## n_step 3280000 score -2.158 best score 5.349 loss 0.00052\n",
      "[2026-01-19 15:28:02] ## n_step 3296000 score -2.782 best score 5.349 loss 0.00044\n",
      "[2026-01-19 15:29:13] ## n_step 3312000 score 0.439 best score 5.349 loss 0.00045\n",
      "[2026-01-19 15:30:23] ## n_step 3328000 score -5.664 best score 5.349 loss 0.00051\n",
      "step= 102000 a= 0.2736634910106659 b= 0.4078816771507263 std= 3.654122829437256 freeze= True\n",
      "[2026-01-19 15:31:34] ## n_step 3344000 score 2.203 best score 5.349 loss 0.00041\n",
      "[2026-01-19 15:32:45] ## n_step 3360000 score -3.118 best score 5.349 loss 0.00036\n",
      "[2026-01-19 15:33:57] ## n_step 3376000 score -2.303 best score 5.349 loss 0.00041\n",
      "[2026-01-19 15:35:20] ## n_step 3392000 score 0.426 best score 5.349 loss 0.00041\n",
      "step= 104000 a= 0.2730006277561188 b= 0.4331910014152527 std= 3.6629951000213623 freeze= True\n",
      "[2026-01-19 15:36:37] ## n_step 3408000 score 0.194 best score 5.349 loss 0.00041\n",
      "[2026-01-19 15:37:51] ## n_step 3424000 score -2.650 best score 5.349 loss 0.00037\n",
      "[2026-01-19 15:39:05] ## n_step 3440000 score -2.575 best score 5.349 loss 0.00049\n",
      "[2026-01-19 15:40:18] ## n_step 3456000 score 0.151 best score 5.349 loss 0.00048\n",
      "step= 106000 a= 0.27187103033065796 b= 0.4510236978530884 std= 3.6782147884368896 freeze= True\n",
      "[2026-01-19 15:41:33] ## n_step 3472000 score 1.000 best score 5.349 loss 0.00042\n",
      "[2026-01-19 15:42:47] ## n_step 3488000 score 1.745 best score 5.349 loss 0.00041\n",
      "[2026-01-19 15:44:01] ## n_step 3504000 score 1.804 best score 5.349 loss 0.00028\n",
      "[2026-01-19 15:45:14] ## n_step 3520000 score -4.878 best score 5.349 loss 0.00049\n",
      "step= 108000 a= 0.2719153165817261 b= 0.46962013840675354 std= 3.6776156425476074 freeze= True\n",
      "[2026-01-19 15:46:28] ## n_step 3536000 score -3.710 best score 5.349 loss 0.00033\n",
      "[2026-01-19 15:47:42] ## n_step 3552000 score 3.927 best score 5.349 loss 0.00046\n",
      "[2026-01-19 15:48:56] ## n_step 3568000 score -4.368 best score 5.349 loss 0.00039\n",
      "[2026-01-19 15:50:10] ## n_step 3584000 score 1.574 best score 5.349 loss 0.00039\n",
      "step= 110000 a= 0.27351608872413635 b= 0.4794555902481079 std= 3.6560921669006348 freeze= True\n",
      "[2026-01-19 15:51:23] ## n_step 3600000 score -2.595 best score 5.349 loss 0.00035\n",
      "[2026-01-19 15:52:37] ## n_step 3616000 score -1.530 best score 5.349 loss 0.00041\n",
      "[2026-01-19 15:53:50] ## n_step 3632000 score -1.745 best score 5.349 loss 0.00029\n",
      "[2026-01-19 15:55:05] ## n_step 3648000 score -0.739 best score 5.349 loss 0.00037\n",
      "step= 112000 a= 0.274255633354187 b= 0.4745251536369324 std= 3.646233320236206 freeze= True\n",
      "[2026-01-19 15:56:18] ## n_step 3664000 score -1.003 best score 5.349 loss 0.00044\n",
      "[2026-01-19 15:57:31] ## n_step 3680000 score -4.164 best score 5.349 loss 0.00040\n",
      "[2026-01-19 15:58:46] ## n_step 3696000 score -2.744 best score 5.349 loss 0.00037\n",
      "[2026-01-19 16:00:00] ## n_step 3712000 score -6.309 best score 5.349 loss 0.00038\n",
      "step= 114000 a= 0.27510929107666016 b= 0.4902772605419159 std= 3.6349191665649414 freeze= True\n",
      "[2026-01-19 16:01:13] ## n_step 3728000 score -4.757 best score 5.349 loss 0.00040\n",
      "[2026-01-19 16:02:26] ## n_step 3744000 score 3.948 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:03:40] ## n_step 3760000 score 0.259 best score 5.646 loss 0.00034\n",
      "[2026-01-19 16:04:53] ## n_step 3776000 score 0.866 best score 5.646 loss 0.00031\n",
      "step= 116000 a= 0.274161696434021 b= 0.4932260513305664 std= 3.647482395172119 freeze= True\n",
      "[2026-01-19 16:06:06] ## n_step 3792000 score -5.885 best score 5.646 loss 0.00042\n",
      "[2026-01-19 16:07:19] ## n_step 3808000 score -0.293 best score 5.646 loss 0.00043\n",
      "[2026-01-19 16:08:32] ## n_step 3824000 score -4.406 best score 5.646 loss 0.00040\n",
      "[2026-01-19 16:09:47] ## n_step 3840000 score -0.656 best score 5.646 loss 0.00042\n",
      "step= 118000 a= 0.2754240334033966 b= 0.5024304986000061 std= 3.630765199661255 freeze= True\n",
      "[2026-01-19 16:11:00] ## n_step 3856000 score -1.727 best score 5.646 loss 0.00040\n",
      "[2026-01-19 16:12:13] ## n_step 3872000 score -6.931 best score 5.646 loss 0.00037\n",
      "[2026-01-19 16:13:27] ## n_step 3888000 score -5.873 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:14:41] ## n_step 3904000 score -3.111 best score 5.646 loss 0.00035\n",
      "step= 120000 a= 0.2751598358154297 b= 0.5210345983505249 std= 3.634251356124878 freeze= True\n",
      "[2026-01-19 16:15:55] ## n_step 3920000 score 0.445 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:17:08] ## n_step 3936000 score -3.609 best score 5.646 loss 0.00027\n",
      "[2026-01-19 16:18:21] ## n_step 3952000 score -8.694 best score 5.646 loss 0.00032\n",
      "[2026-01-19 16:19:35] ## n_step 3968000 score -2.127 best score 5.646 loss 0.00035\n",
      "step= 122000 a= 0.27892252802848816 b= 0.561335563659668 std= 3.5852248668670654 freeze= True\n",
      "[2026-01-19 16:20:49] ## n_step 3984000 score -7.071 best score 5.646 loss 0.00041\n",
      "[2026-01-19 16:22:02] ## n_step 4000000 score -10.811 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:22:02] ## evaluating\n",
      "JPM Human:81.8 AI:-2.8\n",
      "IPG Human:92.3 AI:-13.2\n",
      "MKTX Human:92.3 AI:-19.6\n",
      "AMG Human:101.9 AI:-29.2\n",
      "AJG Human:111.0 AI:-38.3\n",
      "BSX Human:119.6 AI:-46.9\n",
      "DTE Human:103.2 AI:-30.5\n",
      "PRGO Human:93.9 AI:-30.5\n",
      "AMZN Human:78.2 AI:-14.8\n",
      "LLY Human:88.4 AI:-25.0\n",
      "score_eval=0.913 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 561 Sold: 1,365 Bought: 1,926\n",
      "Balance: 1,006.26 Net worth: 8,987.02 Max worth: 10,533.47 total_sales: 22,014.05\n",
      "Avg price bought: 1.00 Avg price_sold: 16.13\n",
      "0.91 vs \u001b[6;30;41m0.90\u001b[0m model performance\n",
      "\n",
      "[2026-01-19 16:24:12] ## n_step 4016000 score -7.263 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:25:26] ## n_step 4032000 score -4.923 best score 5.646 loss 0.00048\n",
      "step= 124000 a= 0.28241652250289917 b= 0.5957644581794739 std= 3.5408692359924316 freeze= True\n",
      "[2026-01-19 16:26:40] ## n_step 4048000 score -4.585 best score 5.646 loss 0.00031\n",
      "[2026-01-19 16:27:53] ## n_step 4064000 score -2.935 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:29:08] ## n_step 4080000 score -5.049 best score 5.646 loss 0.00032\n",
      "[2026-01-19 16:30:21] ## n_step 4096000 score -2.966 best score 5.646 loss 0.00031\n",
      "step= 126000 a= 0.28438428044319153 b= 0.6199436187744141 std= 3.5163686275482178 freeze= True\n",
      "[2026-01-19 16:31:35] ## n_step 4112000 score -7.648 best score 5.646 loss 0.00035\n",
      "[2026-01-19 16:32:48] ## n_step 4128000 score -5.037 best score 5.646 loss 0.00039\n",
      "[2026-01-19 16:34:01] ## n_step 4144000 score -6.867 best score 5.646 loss 0.00034\n",
      "[2026-01-19 16:35:15] ## n_step 4160000 score -7.899 best score 5.646 loss 0.00037\n",
      "step= 128000 a= 0.2875213027000427 b= 0.6503896713256836 std= 3.4780030250549316 freeze= True\n",
      "[2026-01-19 16:36:29] ## n_step 4176000 score -1.960 best score 5.646 loss 0.00041\n",
      "[2026-01-19 16:37:43] ## n_step 4192000 score -3.781 best score 5.646 loss 0.00048\n",
      "[2026-01-19 16:38:58] ## n_step 4208000 score -3.706 best score 5.646 loss 0.00038\n",
      "[2026-01-19 16:40:12] ## n_step 4224000 score -1.940 best score 5.646 loss 0.00033\n",
      "step= 130000 a= 0.2888183891773224 b= 0.664609968662262 std= 3.462383508682251 freeze= True\n",
      "[2026-01-19 16:41:26] ## n_step 4240000 score -3.105 best score 5.646 loss 0.00037\n",
      "[2026-01-19 16:42:40] ## n_step 4256000 score -2.678 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:43:54] ## n_step 4272000 score 1.860 best score 5.646 loss 0.00039\n",
      "[2026-01-19 16:45:08] ## n_step 4288000 score 2.188 best score 5.646 loss 0.00034\n",
      "step= 132000 a= 0.28955724835395813 b= 0.6813938617706299 std= 3.4535484313964844 freeze= True\n",
      "[2026-01-19 16:46:23] ## n_step 4304000 score -4.888 best score 5.646 loss 0.00034\n",
      "[2026-01-19 16:47:37] ## n_step 4320000 score -0.982 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:48:51] ## n_step 4336000 score -1.322 best score 5.646 loss 0.00037\n",
      "[2026-01-19 16:50:05] ## n_step 4352000 score -0.111 best score 5.646 loss 0.00035\n",
      "step= 134000 a= 0.2893262505531311 b= 0.6649928689002991 std= 3.456305980682373 freeze= True\n",
      "[2026-01-19 16:51:19] ## n_step 4368000 score -2.156 best score 5.646 loss 0.00036\n",
      "[2026-01-19 16:52:34] ## n_step 4384000 score -1.747 best score 5.646 loss 0.00034\n",
      "[2026-01-19 16:53:47] ## n_step 4400000 score -0.742 best score 5.646 loss 0.00038\n",
      "[2026-01-19 16:55:02] ## n_step 4416000 score -7.606 best score 5.646 loss 0.00031\n",
      "step= 136000 a= 0.2889076769351959 b= 0.6623646020889282 std= 3.461313486099243 freeze= True\n",
      "[2026-01-19 16:56:16] ## n_step 4432000 score -5.860 best score 5.646 loss 0.00034\n",
      "[2026-01-19 16:57:30] ## n_step 4448000 score -4.192 best score 5.646 loss 0.00033\n",
      "[2026-01-19 16:58:45] ## n_step 4464000 score -2.924 best score 5.646 loss 0.00041\n",
      "[2026-01-19 16:59:59] ## n_step 4480000 score 1.618 best score 5.646 loss 0.00031\n",
      "step= 138000 a= 0.2894730865955353 b= 0.6490828394889832 std= 3.454552412033081 freeze= True\n",
      "[2026-01-19 17:01:13] ## n_step 4496000 score -2.979 best score 5.646 loss 0.00041\n",
      "[2026-01-19 17:02:27] ## n_step 4512000 score -2.961 best score 5.646 loss 0.00038\n",
      "[2026-01-19 17:03:42] ## n_step 4528000 score -3.410 best score 5.646 loss 0.00033\n",
      "[2026-01-19 17:04:56] ## n_step 4544000 score -2.670 best score 5.646 loss 0.00039\n",
      "step= 140000 a= 0.2895892858505249 b= 0.6267920732498169 std= 3.4531664848327637 freeze= True\n",
      "[2026-01-19 17:06:10] ## n_step 4560000 score -3.712 best score 5.646 loss 0.00036\n",
      "[2026-01-19 17:07:24] ## n_step 4576000 score -2.771 best score 5.646 loss 0.00039\n",
      "[2026-01-19 17:08:38] ## n_step 4592000 score -6.519 best score 5.646 loss 0.00037\n",
      "[2026-01-19 17:09:52] ## n_step 4608000 score -3.241 best score 5.646 loss 0.00029\n",
      "step= 142000 a= 0.2904074788093567 b= 0.6318097710609436 std= 3.4434375762939453 freeze= True\n",
      "[2026-01-19 17:11:07] ## n_step 4624000 score -4.409 best score 5.646 loss 0.00034\n",
      "[2026-01-19 17:12:20] ## n_step 4640000 score -4.897 best score 5.646 loss 0.00029\n",
      "[2026-01-19 17:13:35] ## n_step 4656000 score -5.169 best score 5.646 loss 0.00030\n",
      "[2026-01-19 17:14:49] ## n_step 4672000 score -4.800 best score 5.646 loss 0.00040\n",
      "step= 144000 a= 0.2895177900791168 b= 0.6466938853263855 std= 3.45401930809021 freeze= True\n",
      "[2026-01-19 17:16:05] ## n_step 4688000 score -6.631 best score 5.646 loss 0.00034\n",
      "[2026-01-19 17:17:19] ## n_step 4704000 score -3.986 best score 5.646 loss 0.00029\n",
      "[2026-01-19 17:18:33] ## n_step 4720000 score -2.597 best score 5.646 loss 0.00026\n",
      "[2026-01-19 17:19:49] ## n_step 4736000 score 1.050 best score 5.646 loss 0.00028\n",
      "step= 146000 a= 0.2921476364135742 b= 0.6862635612487793 std= 3.422926902770996 freeze= True\n",
      "[2026-01-19 17:21:05] ## n_step 4752000 score -7.979 best score 5.646 loss 0.00038\n",
      "[2026-01-19 17:22:19] ## n_step 4768000 score -6.140 best score 5.646 loss 0.00036\n",
      "[2026-01-19 17:23:33] ## n_step 4784000 score -1.532 best score 5.646 loss 0.00029\n",
      "[2026-01-19 17:24:48] ## n_step 4800000 score -1.187 best score 5.646 loss 0.00030\n",
      "step= 148000 a= 0.28959858417510986 b= 0.6784723401069641 std= 3.4530556201934814 freeze= True\n",
      "[2026-01-19 17:26:00] ## n_step 4816000 score -1.703 best score 5.646 loss 0.00034\n",
      "[2026-01-19 17:27:15] ## n_step 4832000 score -1.455 best score 5.646 loss 0.00033\n",
      "[2026-01-19 17:28:30] ## n_step 4848000 score 0.523 best score 5.646 loss 0.00029\n",
      "[2026-01-19 17:29:45] ## n_step 4864000 score -3.517 best score 5.646 loss 0.00025\n",
      "step= 150000 a= 0.2882836163043976 b= 0.6706476807594299 std= 3.468806266784668 freeze= True\n",
      "[2026-01-19 17:31:00] ## n_step 4880000 score -1.351 best score 5.646 loss 0.00031\n",
      "[2026-01-19 17:32:15] ## n_step 4896000 score -1.920 best score 5.646 loss 0.00033\n",
      "[2026-01-19 17:33:30] ## n_step 4912000 score -2.074 best score 5.646 loss 0.00037\n",
      "[2026-01-19 17:34:45] ## n_step 4928000 score 0.674 best score 5.646 loss 0.00031\n",
      "step= 152000 a= 0.28901827335357666 b= 0.6674169898033142 std= 3.459988832473755 freeze= True\n",
      "[2026-01-19 17:35:59] ## n_step 4944000 score -3.574 best score 5.646 loss 0.00025\n",
      "[2026-01-19 17:37:15] ## n_step 4960000 score -3.793 best score 5.646 loss 0.00027\n",
      "[2026-01-19 17:38:29] ## n_step 4976000 score 0.742 best score 5.646 loss 0.00033\n",
      "[2026-01-19 17:39:44] ## n_step 4992000 score -1.666 best score 5.646 loss 0.00031\n",
      "[2026-01-19 17:40:22] ## evaluating\n",
      "LH Human:97.8 AI:-40.1\n",
      "SYY Human:106.7 AI:-49.0\n",
      "INTU Human:115.2 AI:-57.4\n",
      "TMO Human:123.1 AI:-65.3\n",
      "NVR Human:106.3 AI:-48.5\n",
      "AON Human:97.3 AI:-48.5\n",
      "COF Human:81.2 AI:-32.4\n",
      "FCX Human:65.8 AI:-17.0\n",
      "LMT Human:76.3 AI:-27.5\n",
      "IRM Human:86.1 AI:-37.4\n",
      "score_eval=0.982 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 693 Sold: 250 Bought: 943\n",
      "Balance: 44.70 Net worth: 9,903.28 Max worth: 12,712.04 total_sales: 3,762.03\n",
      "Avg price bought: 1.00 Avg price_sold: 15.05\n",
      "0.91 vs \u001b[6;30;42m0.99\u001b[0m model performance\n",
      "\n",
      "step= 154000 a= 0.2878677546977997 b= 0.6372824311256409 std= 3.4738173484802246 freeze= True\n",
      "[2026-01-19 17:41:54] ## n_step 5008000 score -2.025 best score 5.646 loss 0.00025\n",
      "[2026-01-19 17:43:08] ## n_step 5024000 score -2.320 best score 5.646 loss 0.00022\n",
      "[2026-01-19 17:44:23] ## n_step 5040000 score -2.241 best score 5.646 loss 0.00025\n",
      "[2026-01-19 17:45:37] ## n_step 5056000 score 2.139 best score 5.646 loss 0.00030\n",
      "step= 156000 a= 0.28566333651542664 b= 0.6058753728866577 std= 3.500624418258667 freeze= True\n",
      "[2026-01-19 17:46:51] ## n_step 5072000 score -4.160 best score 5.646 loss 0.00030\n",
      "[2026-01-19 17:48:04] ## n_step 5088000 score 0.360 best score 5.646 loss 0.00032\n",
      "[2026-01-19 17:49:19] ## n_step 5104000 score 1.740 best score 5.646 loss 0.00024\n",
      "[2026-01-19 17:50:33] ## n_step 5120000 score -1.980 best score 5.646 loss 0.00034\n",
      "step= 158000 a= 0.2847834825515747 b= 0.5862286686897278 std= 3.511439561843872 freeze= True\n",
      "[2026-01-19 17:51:47] ## n_step 5136000 score -1.736 best score 5.646 loss 0.00025\n",
      "[2026-01-19 17:53:02] ## n_step 5152000 score -0.814 best score 5.646 loss 0.00025\n",
      "[2026-01-19 17:54:15] ## n_step 5168000 score -1.826 best score 5.646 loss 0.00027\n",
      "[2026-01-19 17:55:30] ## n_step 5184000 score -7.974 best score 5.646 loss 0.00029\n",
      "step= 160000 a= 0.28805726766586304 b= 0.5839633941650391 std= 3.471531867980957 freeze= True\n",
      "[2026-01-19 17:56:44] ## n_step 5200000 score -1.609 best score 5.646 loss 0.00030\n",
      "[2026-01-19 17:57:57] ## n_step 5216000 score -2.243 best score 5.646 loss 0.00031\n",
      "[2026-01-19 17:59:13] ## n_step 5232000 score -1.167 best score 5.646 loss 0.00028\n",
      "[2026-01-19 18:00:27] ## n_step 5248000 score -2.012 best score 5.646 loss 0.00025\n",
      "step= 162000 a= 0.2903130054473877 b= 0.577451229095459 std= 3.4445581436157227 freeze= True\n",
      "[2026-01-19 18:01:41] ## n_step 5264000 score -3.590 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:02:55] ## n_step 5280000 score -2.832 best score 5.646 loss 0.00029\n",
      "[2026-01-19 18:04:09] ## n_step 5296000 score -1.443 best score 5.646 loss 0.00025\n",
      "[2026-01-19 18:05:24] ## n_step 5312000 score -2.197 best score 5.646 loss 0.00027\n",
      "step= 164000 a= 0.29244300723075867 b= 0.5690380930900574 std= 3.4194698333740234 freeze= True\n",
      "[2026-01-19 18:06:38] ## n_step 5328000 score -2.733 best score 5.646 loss 0.00027\n",
      "[2026-01-19 18:07:52] ## n_step 5344000 score -5.404 best score 5.646 loss 0.00027\n",
      "[2026-01-19 18:09:07] ## n_step 5360000 score -5.616 best score 5.646 loss 0.00027\n",
      "[2026-01-19 18:10:21] ## n_step 5376000 score -4.034 best score 5.646 loss 0.00028\n",
      "step= 166000 a= 0.29426518082618713 b= 0.5670457482337952 std= 3.3982954025268555 freeze= True\n",
      "[2026-01-19 18:11:35] ## n_step 5392000 score -4.118 best score 5.646 loss 0.00037\n",
      "[2026-01-19 18:12:50] ## n_step 5408000 score -6.446 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:14:04] ## n_step 5424000 score -1.140 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:15:20] ## n_step 5440000 score -1.568 best score 5.646 loss 0.00026\n",
      "step= 168000 a= 0.2914702594280243 b= 0.561229407787323 std= 3.4308817386627197 freeze= True\n",
      "[2026-01-19 18:16:35] ## n_step 5456000 score -3.086 best score 5.646 loss 0.00034\n",
      "[2026-01-19 18:17:47] ## n_step 5472000 score -1.155 best score 5.646 loss 0.00024\n",
      "[2026-01-19 18:19:02] ## n_step 5488000 score -6.682 best score 5.646 loss 0.00037\n",
      "[2026-01-19 18:20:16] ## n_step 5504000 score -1.302 best score 5.646 loss 0.00028\n",
      "step= 170000 a= 0.2907823622226715 b= 0.5759748220443726 std= 3.438998222351074 freeze= True\n",
      "[2026-01-19 18:21:30] ## n_step 5520000 score -4.123 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:22:45] ## n_step 5536000 score -4.936 best score 5.646 loss 0.00028\n",
      "[2026-01-19 18:23:59] ## n_step 5552000 score -7.506 best score 5.646 loss 0.00030\n",
      "[2026-01-19 18:25:13] ## n_step 5568000 score -6.697 best score 5.646 loss 0.00026\n",
      "step= 172000 a= 0.2915157675743103 b= 0.6002026796340942 std= 3.4303462505340576 freeze= True\n",
      "[2026-01-19 18:26:28] ## n_step 5584000 score -8.903 best score 5.646 loss 0.00028\n",
      "[2026-01-19 18:27:42] ## n_step 5600000 score -6.205 best score 5.646 loss 0.00022\n",
      "[2026-01-19 18:28:56] ## n_step 5616000 score -2.910 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:30:10] ## n_step 5632000 score -3.184 best score 5.646 loss 0.00028\n",
      "step= 174000 a= 0.2900344729423523 b= 0.6049299836158752 std= 3.4478659629821777 freeze= True\n",
      "[2026-01-19 18:31:24] ## n_step 5648000 score -1.359 best score 5.646 loss 0.00029\n",
      "[2026-01-19 18:32:38] ## n_step 5664000 score -1.748 best score 5.646 loss 0.00025\n",
      "[2026-01-19 18:33:51] ## n_step 5680000 score -4.909 best score 5.646 loss 0.00027\n",
      "[2026-01-19 18:35:06] ## n_step 5696000 score -4.840 best score 5.646 loss 0.00026\n",
      "step= 176000 a= 0.2890130281448364 b= 0.6228339076042175 std= 3.4600515365600586 freeze= True\n",
      "[2026-01-19 18:36:20] ## n_step 5712000 score -5.392 best score 5.646 loss 0.00027\n",
      "[2026-01-19 18:37:34] ## n_step 5728000 score -7.126 best score 5.646 loss 0.00022\n",
      "[2026-01-19 18:38:49] ## n_step 5744000 score -5.822 best score 5.646 loss 0.00024\n",
      "[2026-01-19 18:40:03] ## n_step 5760000 score -5.339 best score 5.646 loss 0.00017\n",
      "step= 178000 a= 0.28827086091041565 b= 0.6413426995277405 std= 3.4689595699310303 freeze= True\n",
      "[2026-01-19 18:41:18] ## n_step 5776000 score -1.660 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:42:32] ## n_step 5792000 score -6.767 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:43:46] ## n_step 5808000 score -5.093 best score 5.646 loss 0.00023\n",
      "[2026-01-19 18:45:00] ## n_step 5824000 score -9.057 best score 5.646 loss 0.00025\n",
      "step= 180000 a= 0.290691614151001 b= 0.6781209111213684 std= 3.4400715827941895 freeze= True\n",
      "[2026-01-19 18:46:13] ## n_step 5840000 score -3.201 best score 5.646 loss 0.00022\n",
      "[2026-01-19 18:47:28] ## n_step 5856000 score -8.453 best score 5.646 loss 0.00023\n",
      "[2026-01-19 18:48:43] ## n_step 5872000 score -5.159 best score 5.646 loss 0.00022\n",
      "[2026-01-19 18:49:57] ## n_step 5888000 score -4.535 best score 5.646 loss 0.00022\n",
      "step= 182000 a= 0.2891870439052582 b= 0.6861301064491272 std= 3.4579696655273438 freeze= True\n",
      "[2026-01-19 18:51:11] ## n_step 5904000 score -4.149 best score 5.646 loss 0.00023\n",
      "[2026-01-19 18:52:25] ## n_step 5920000 score -3.742 best score 5.646 loss 0.00020\n",
      "[2026-01-19 18:53:39] ## n_step 5936000 score -8.258 best score 5.646 loss 0.00022\n",
      "[2026-01-19 18:54:54] ## n_step 5952000 score -1.218 best score 5.646 loss 0.00027\n",
      "step= 184000 a= 0.28700095415115356 b= 0.6889473795890808 std= 3.484308958053589 freeze= True\n",
      "[2026-01-19 18:56:07] ## n_step 5968000 score -6.881 best score 5.646 loss 0.00026\n",
      "[2026-01-19 18:57:22] ## n_step 5984000 score -7.553 best score 5.646 loss 0.00020\n",
      "[2026-01-19 18:58:36] ## n_step 6000000 score -5.652 best score 5.646 loss 0.00022\n",
      "[2026-01-19 18:58:36] ## evaluating\n",
      "TGT Human:70.3 AI:-37.4\n",
      "TRV Human:80.1 AI:-47.1\n",
      "ODFL Human:89.3 AI:-56.4\n",
      "MSI Human:98.0 AI:-65.1\n",
      "LHX Human:106.2 AI:-73.3\n",
      "USB Human:113.9 AI:-81.0\n",
      "GL Human:121.3 AI:-88.3\n",
      "SY1.DE Human:128.2 AI:-95.3\n",
      "AEP Human:110.9 AI:-78.0\n",
      "RMD Human:94.1 AI:-61.2\n",
      "score_eval=0.924 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 177 Bought: 177\n",
      "Balance: 9,988.12 Net worth: 9,988.12 Max worth: 10,008.75 total_sales: 2,964.11\n",
      "Avg price bought: 1.00 Avg price_sold: 16.75\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-19 19:00:47] ## n_step 6016000 score -3.563 best score 5.646 loss 0.00024\n",
      "step= 186000 a= 0.28629758954048157 b= 0.6992469429969788 std= 3.4928691387176514 freeze= True\n",
      "[2026-01-19 19:02:01] ## n_step 6032000 score -5.541 best score 5.646 loss 0.00027\n",
      "[2026-01-19 19:03:15] ## n_step 6048000 score -7.891 best score 5.646 loss 0.00027\n",
      "[2026-01-19 19:04:31] ## n_step 6064000 score -4.810 best score 5.646 loss 0.00017\n",
      "[2026-01-19 19:05:45] ## n_step 6080000 score -4.228 best score 5.646 loss 0.00021\n",
      "step= 188000 a= 0.2836519777774811 b= 0.6981244087219238 std= 3.525447130203247 freeze= True\n",
      "[2026-01-19 19:06:59] ## n_step 6096000 score 0.173 best score 5.646 loss 0.00032\n",
      "[2026-01-19 19:08:13] ## n_step 6112000 score -7.338 best score 5.646 loss 0.00020\n",
      "[2026-01-19 19:09:29] ## n_step 6128000 score -5.331 best score 5.646 loss 0.00021\n",
      "[2026-01-19 19:10:43] ## n_step 6144000 score -4.843 best score 5.646 loss 0.00021\n",
      "step= 190000 a= 0.28482070565223694 b= 0.7217150926589966 std= 3.5109808444976807 freeze= True\n",
      "[2026-01-19 19:11:57] ## n_step 6160000 score -8.386 best score 5.646 loss 0.00023\n",
      "[2026-01-19 19:13:12] ## n_step 6176000 score -7.653 best score 5.646 loss 0.00022\n",
      "[2026-01-19 19:14:26] ## n_step 6192000 score -6.744 best score 5.646 loss 0.00023\n",
      "[2026-01-19 19:15:40] ## n_step 6208000 score -5.946 best score 5.646 loss 0.00023\n",
      "step= 192000 a= 0.2864084839820862 b= 0.7641716599464417 std= 3.4915168285369873 freeze= True\n",
      "[2026-01-19 19:16:55] ## n_step 6224000 score -11.787 best score 5.646 loss 0.00024\n",
      "[2026-01-19 19:18:09] ## n_step 6240000 score -9.530 best score 5.646 loss 0.00025\n",
      "[2026-01-19 19:19:24] ## n_step 6256000 score -13.779 best score 5.646 loss 0.00021\n",
      "[2026-01-19 19:20:38] ## n_step 6272000 score -7.782 best score 5.646 loss 0.00020\n",
      "step= 194000 a= 0.28365927934646606 b= 0.7919846773147583 std= 3.5253562927246094 freeze= True\n",
      "[2026-01-19 19:21:51] ## n_step 6288000 score -4.285 best score 5.646 loss 0.00021\n",
      "[2026-01-19 19:23:05] ## n_step 6304000 score -6.620 best score 5.646 loss 0.00026\n",
      "[2026-01-19 19:24:19] ## n_step 6320000 score -8.699 best score 5.646 loss 0.00020\n",
      "[2026-01-19 19:25:33] ## n_step 6336000 score -2.154 best score 5.646 loss 0.00023\n",
      "step= 196000 a= 0.2825726866722107 b= 0.8027447462081909 std= 3.538912296295166 freeze= True\n",
      "[2026-01-19 19:26:47] ## n_step 6352000 score -9.215 best score 5.646 loss 0.00019\n",
      "[2026-01-19 19:28:00] ## n_step 6368000 score -10.474 best score 5.646 loss 0.00023\n",
      "[2026-01-19 19:29:16] ## n_step 6384000 score -10.171 best score 5.646 loss 0.00020\n",
      "[2026-01-19 19:30:30] ## n_step 6400000 score -10.352 best score 5.646 loss 0.00023\n",
      "step= 198000 a= 0.2816438674926758 b= 0.8374621868133545 std= 3.5505831241607666 freeze= True\n",
      "[2026-01-19 19:31:43] ## n_step 6416000 score -5.406 best score 5.646 loss 0.00016\n",
      "[2026-01-19 19:32:57] ## n_step 6432000 score -7.422 best score 5.646 loss 0.00022\n",
      "[2026-01-19 19:34:12] ## n_step 6448000 score -4.327 best score 5.646 loss 0.00018\n",
      "[2026-01-19 19:35:25] ## n_step 6464000 score -8.972 best score 5.646 loss 0.00022\n",
      "step= 200000 a= 0.2824386656284332 b= 0.8557004928588867 std= 3.5405917167663574 freeze= True\n",
      "[2026-01-19 19:36:40] ## n_step 6480000 score -2.572 best score 5.646 loss 0.00017\n",
      "[2026-01-19 19:37:53] ## n_step 6496000 score -7.744 best score 5.646 loss 0.00027\n",
      "[2026-01-19 19:39:08] ## n_step 6512000 score -9.471 best score 5.646 loss 0.00017\n",
      "[2026-01-19 19:40:23] ## n_step 6528000 score -12.516 best score 5.646 loss 0.00018\n",
      "step= 202000 a= 0.2819833755493164 b= 0.8738952875137329 std= 3.5463085174560547 freeze= True\n",
      "[2026-01-19 19:41:37] ## n_step 6544000 score -7.679 best score 5.646 loss 0.00020\n",
      "[2026-01-19 19:42:52] ## n_step 6560000 score -10.304 best score 5.646 loss 0.00024\n",
      "[2026-01-19 19:44:06] ## n_step 6576000 score -5.355 best score 5.646 loss 0.00019\n",
      "[2026-01-19 19:45:21] ## n_step 6592000 score -7.244 best score 5.646 loss 0.00026\n",
      "step= 204000 a= 0.2843458354473114 b= 0.9064157605171204 std= 3.5168440341949463 freeze= True\n",
      "[2026-01-19 19:46:35] ## n_step 6608000 score -7.498 best score 5.646 loss 0.00018\n",
      "[2026-01-19 19:47:49] ## n_step 6624000 score -4.373 best score 5.646 loss 0.00023\n",
      "[2026-01-19 19:49:03] ## n_step 6640000 score -8.669 best score 5.646 loss 0.00016\n",
      "[2026-01-19 19:50:17] ## n_step 6656000 score -7.708 best score 5.646 loss 0.00020\n",
      "step= 206000 a= 0.28398260474205017 b= 0.9068526029586792 std= 3.5213422775268555 freeze= True\n",
      "[2026-01-19 19:51:32] ## n_step 6672000 score -7.102 best score 5.646 loss 0.00020\n",
      "[2026-01-19 19:52:45] ## n_step 6688000 score -9.633 best score 5.646 loss 0.00022\n",
      "[2026-01-19 19:53:59] ## n_step 6704000 score -10.306 best score 5.646 loss 0.00019\n",
      "[2026-01-19 19:55:13] ## n_step 6720000 score -6.450 best score 5.646 loss 0.00020\n",
      "step= 208000 a= 0.28358641266822815 b= 0.9161996245384216 std= 3.526262044906616 freeze= True\n",
      "[2026-01-19 19:56:27] ## n_step 6736000 score -8.915 best score 5.646 loss 0.00022\n",
      "[2026-01-19 19:57:40] ## n_step 6752000 score -5.202 best score 5.646 loss 0.00017\n",
      "[2026-01-19 19:58:55] ## n_step 6768000 score -9.291 best score 5.646 loss 0.00021\n",
      "[2026-01-19 20:00:08] ## n_step 6784000 score -2.874 best score 5.646 loss 0.00022\n",
      "step= 210000 a= 0.28169599175453186 b= 0.903817892074585 std= 3.549926280975342 freeze= True\n",
      "[2026-01-19 20:01:22] ## n_step 6800000 score -1.835 best score 5.646 loss 0.00019\n",
      "[2026-01-19 20:02:37] ## n_step 6816000 score -5.300 best score 5.646 loss 0.00020\n",
      "[2026-01-19 20:03:51] ## n_step 6832000 score -5.540 best score 5.646 loss 0.00021\n",
      "[2026-01-19 20:05:05] ## n_step 6848000 score -7.517 best score 5.646 loss 0.00021\n",
      "step= 212000 a= 0.2798474133014679 b= 0.8970614075660706 std= 3.573375701904297 freeze= True\n",
      "[2026-01-19 20:06:19] ## n_step 6864000 score -5.971 best score 5.646 loss 0.00020\n",
      "[2026-01-19 20:07:33] ## n_step 6880000 score -11.072 best score 5.646 loss 0.00014\n",
      "[2026-01-19 20:08:48] ## n_step 6896000 score -8.689 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:10:01] ## n_step 6912000 score -7.743 best score 5.646 loss 0.00018\n",
      "step= 214000 a= 0.27997565269470215 b= 0.9012481570243835 std= 3.5717391967773438 freeze= True\n",
      "[2026-01-19 20:11:16] ## n_step 6928000 score -7.726 best score 5.646 loss 0.00023\n",
      "[2026-01-19 20:12:30] ## n_step 6944000 score -7.698 best score 5.646 loss 0.00017\n",
      "[2026-01-19 20:13:43] ## n_step 6960000 score -7.366 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:14:58] ## n_step 6976000 score -6.589 best score 5.646 loss 0.00018\n",
      "step= 216000 a= 0.28106689453125 b= 0.9033788442611694 std= 3.5578718185424805 freeze= True\n",
      "[2026-01-19 20:16:12] ## n_step 6992000 score -6.869 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:16:48] ## evaluating\n",
      "SHW Human:94.8 AI:-69.8\n",
      "BNR.DE Human:94.8 AI:-73.7\n",
      "BKNG Human:102.9 AI:-81.8\n",
      "EA Human:110.5 AI:-89.4\n",
      "CPT Human:93.5 AI:-72.4\n",
      "MGM Human:101.6 AI:-80.5\n",
      "NI Human:93.8 AI:-80.5\n",
      "RVTY Human:86.4 AI:-80.5\n",
      "ADP Human:70.0 AI:-64.1\n",
      "LYB Human:54.1 AI:-48.2\n",
      "score_eval=0.978 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 716 Sold: 278 Bought: 994\n",
      "Balance: 53.32 Net worth: 10,239.10 Max worth: 13,141.07 total_sales: 3,862.70\n",
      "Avg price bought: 1.00 Avg price_sold: 13.89\n",
      "0.91 vs \u001b[6;30;42m1.02\u001b[0m model performance\n",
      "\n",
      "[2026-01-19 20:18:21] ## n_step 7008000 score -5.463 best score 5.646 loss 0.00014\n",
      "[2026-01-19 20:19:36] ## n_step 7024000 score -7.429 best score 5.646 loss 0.00015\n",
      "[2026-01-19 20:20:50] ## n_step 7040000 score -5.660 best score 5.646 loss 0.00018\n",
      "step= 218000 a= 0.28047317266464233 b= 0.9040542244911194 std= 3.5654032230377197 freeze= True\n",
      "[2026-01-19 20:22:04] ## n_step 7056000 score -5.996 best score 5.646 loss 0.00012\n",
      "[2026-01-19 20:23:18] ## n_step 7072000 score -4.314 best score 5.646 loss 0.00023\n",
      "[2026-01-19 20:24:32] ## n_step 7088000 score -3.900 best score 5.646 loss 0.00018\n",
      "[2026-01-19 20:25:46] ## n_step 7104000 score -6.419 best score 5.646 loss 0.00018\n",
      "step= 220000 a= 0.27872419357299805 b= 0.8856556415557861 std= 3.587775945663452 freeze= True\n",
      "[2026-01-19 20:27:00] ## n_step 7120000 score -9.583 best score 5.646 loss 0.00018\n",
      "[2026-01-19 20:28:14] ## n_step 7136000 score -8.961 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:29:29] ## n_step 7152000 score -5.053 best score 5.646 loss 0.00015\n",
      "[2026-01-19 20:30:43] ## n_step 7168000 score -6.378 best score 5.646 loss 0.00021\n",
      "step= 222000 a= 0.2795034646987915 b= 0.8890707492828369 std= 3.577773332595825 freeze= True\n",
      "[2026-01-19 20:31:58] ## n_step 7184000 score -5.353 best score 5.646 loss 0.00013\n",
      "[2026-01-19 20:33:12] ## n_step 7200000 score -4.537 best score 5.646 loss 0.00019\n",
      "[2026-01-19 20:34:26] ## n_step 7216000 score -8.604 best score 5.646 loss 0.00020\n",
      "[2026-01-19 20:35:40] ## n_step 7232000 score -11.063 best score 5.646 loss 0.00021\n",
      "step= 224000 a= 0.28315338492393494 b= 0.8975436091423035 std= 3.5316545963287354 freeze= True\n",
      "[2026-01-19 20:36:55] ## n_step 7248000 score -8.789 best score 5.646 loss 0.00021\n",
      "[2026-01-19 20:38:13] ## n_step 7264000 score -7.548 best score 5.646 loss 0.00014\n",
      "[2026-01-19 20:39:28] ## n_step 7280000 score -7.275 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:40:44] ## n_step 7296000 score -6.212 best score 5.646 loss 0.00016\n",
      "step= 226000 a= 0.2835874855518341 b= 0.8883465528488159 std= 3.5262486934661865 freeze= True\n",
      "[2026-01-19 20:41:57] ## n_step 7312000 score -8.863 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:43:14] ## n_step 7328000 score -10.483 best score 5.646 loss 0.00014\n",
      "[2026-01-19 20:44:30] ## n_step 7344000 score -10.769 best score 5.646 loss 0.00014\n",
      "[2026-01-19 20:45:45] ## n_step 7360000 score -9.042 best score 5.646 loss 0.00015\n",
      "step= 228000 a= 0.2863816022872925 b= 0.9025338888168335 std= 3.491844415664673 freeze= True\n",
      "[2026-01-19 20:47:00] ## n_step 7376000 score -9.210 best score 5.646 loss 0.00015\n",
      "[2026-01-19 20:48:17] ## n_step 7392000 score -3.851 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:49:32] ## n_step 7408000 score -7.425 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:50:47] ## n_step 7424000 score -9.703 best score 5.646 loss 0.00014\n",
      "step= 230000 a= 0.28252124786376953 b= 0.8968020677566528 std= 3.5395567417144775 freeze= True\n",
      "[2026-01-19 20:52:00] ## n_step 7440000 score -7.983 best score 5.646 loss 0.00018\n",
      "[2026-01-19 20:53:20] ## n_step 7456000 score -10.005 best score 5.646 loss 0.00014\n",
      "[2026-01-19 20:54:33] ## n_step 7472000 score -6.630 best score 5.646 loss 0.00016\n",
      "[2026-01-19 20:55:47] ## n_step 7488000 score -7.103 best score 5.646 loss 0.00014\n",
      "step= 232000 a= 0.27923133969306946 b= 0.8962929248809814 std= 3.5812599658966064 freeze= True\n",
      "[2026-01-19 20:57:01] ## n_step 7504000 score -10.034 best score 5.646 loss 0.00015\n",
      "[2026-01-19 20:58:15] ## n_step 7520000 score -11.030 best score 5.646 loss 0.00014\n",
      "[2026-01-19 20:59:30] ## n_step 7536000 score -12.222 best score 5.646 loss 0.00011\n",
      "[2026-01-19 21:00:44] ## n_step 7552000 score -12.704 best score 5.646 loss 0.00015\n",
      "step= 234000 a= 0.2793358564376831 b= 0.9224258065223694 std= 3.5799200534820557 freeze= True\n",
      "[2026-01-19 21:01:57] ## n_step 7568000 score -10.662 best score 5.646 loss 0.00014\n",
      "[2026-01-19 21:03:12] ## n_step 7584000 score -10.973 best score 5.646 loss 0.00015\n",
      "[2026-01-19 21:04:26] ## n_step 7600000 score -9.005 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:05:40] ## n_step 7616000 score -7.295 best score 5.646 loss 0.00020\n",
      "step= 236000 a= 0.2796262800693512 b= 0.9296917915344238 std= 3.5762016773223877 freeze= True\n",
      "[2026-01-19 21:06:54] ## n_step 7632000 score -7.916 best score 5.646 loss 0.00016\n",
      "[2026-01-19 21:08:09] ## n_step 7648000 score -11.090 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:09:23] ## n_step 7664000 score -13.824 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:10:38] ## n_step 7680000 score -11.771 best score 5.646 loss 0.00017\n",
      "step= 238000 a= 0.27997854351997375 b= 0.9562403559684753 std= 3.571702241897583 freeze= True\n",
      "[2026-01-19 21:11:52] ## n_step 7696000 score -6.612 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:13:07] ## n_step 7712000 score -9.248 best score 5.646 loss 0.00017\n",
      "[2026-01-19 21:14:21] ## n_step 7728000 score -9.989 best score 5.646 loss 0.00011\n",
      "[2026-01-19 21:15:36] ## n_step 7744000 score -9.063 best score 5.646 loss 0.00012\n",
      "step= 240000 a= 0.2777527868747711 b= 0.9681944251060486 std= 3.6003239154815674 freeze= True\n",
      "[2026-01-19 21:16:49] ## n_step 7760000 score -9.136 best score 5.646 loss 0.00017\n",
      "[2026-01-19 21:18:06] ## n_step 7776000 score -14.378 best score 5.646 loss 0.00014\n",
      "[2026-01-19 21:19:20] ## n_step 7792000 score -8.361 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:20:34] ## n_step 7808000 score -6.035 best score 5.646 loss 0.00013\n",
      "step= 242000 a= 0.27804169058799744 b= 0.9854183197021484 std= 3.5965828895568848 freeze= True\n",
      "[2026-01-19 21:21:47] ## n_step 7824000 score -7.855 best score 5.646 loss 0.00017\n",
      "[2026-01-19 21:23:03] ## n_step 7840000 score -11.542 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:24:17] ## n_step 7856000 score -7.665 best score 5.646 loss 0.00011\n",
      "[2026-01-19 21:25:31] ## n_step 7872000 score -12.961 best score 5.646 loss 0.00012\n",
      "step= 244000 a= 0.28205984830856323 b= 1.0139228105545044 std= 3.545346736907959 freeze= True\n",
      "[2026-01-19 21:26:46] ## n_step 7888000 score -7.504 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:28:01] ## n_step 7904000 score -8.977 best score 5.646 loss 0.00017\n",
      "[2026-01-19 21:29:15] ## n_step 7920000 score -12.321 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:30:29] ## n_step 7936000 score -9.019 best score 5.646 loss 0.00013\n",
      "step= 246000 a= 0.2821703553199768 b= 1.020869255065918 std= 3.5439584255218506 freeze= True\n",
      "[2026-01-19 21:31:44] ## n_step 7952000 score -7.003 best score 5.646 loss 0.00009\n",
      "[2026-01-19 21:33:01] ## n_step 7968000 score -10.952 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:34:15] ## n_step 7984000 score -8.429 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:35:29] ## n_step 8000000 score -8.272 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:35:29] ## evaluating\n",
      "AAPL Human:49.7 AI:-43.8\n",
      "FOXA Human:59.8 AI:-54.0\n",
      "DBK.DE Human:69.4 AI:-63.6\n",
      "AMAT Human:78.5 AI:-72.6\n",
      "WAB Human:87.0 AI:-81.2\n",
      "LIN Human:95.1 AI:-89.2\n",
      "CE Human:87.9 AI:-89.2\n",
      "SYF Human:95.7 AI:-97.0\n",
      "GAS Human:103.1 AI:-104.4\n",
      "FI Human:110.1 AI:-111.4\n",
      "score_eval=0.823 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 60 Bought: 60\n",
      "Balance: 10,014.77 Net worth: 10,014.77 Max worth: 10,022.92 total_sales: 1,011.19\n",
      "Avg price bought: 1.00 Avg price_sold: 16.85\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "step= 248000 a= 0.2802705466747284 b= 1.0187878608703613 std= 3.567981004714966 freeze= True\n",
      "[2026-01-19 21:37:42] ## n_step 8016000 score -11.740 best score 5.646 loss 0.00014\n",
      "[2026-01-19 21:38:56] ## n_step 8032000 score -7.373 best score 5.646 loss 0.00010\n",
      "[2026-01-19 21:40:11] ## n_step 8048000 score -7.763 best score 5.646 loss 0.00014\n",
      "[2026-01-19 21:41:24] ## n_step 8064000 score -11.304 best score 5.646 loss 0.00010\n",
      "step= 250000 a= 0.2779913544654846 b= 1.019778847694397 std= 3.5972342491149902 freeze= True\n",
      "[2026-01-19 21:42:40] ## n_step 8080000 score -9.068 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:43:54] ## n_step 8096000 score -5.693 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:45:07] ## n_step 8112000 score -8.961 best score 5.646 loss 0.00010\n",
      "[2026-01-19 21:46:21] ## n_step 8128000 score -8.990 best score 5.646 loss 0.00014\n",
      "step= 252000 a= 0.27646195888519287 b= 1.0188829898834229 std= 3.6171343326568604 freeze= True\n",
      "[2026-01-19 21:47:36] ## n_step 8144000 score -6.810 best score 5.646 loss 0.00016\n",
      "[2026-01-19 21:48:50] ## n_step 8160000 score -10.921 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:50:05] ## n_step 8176000 score -9.423 best score 5.646 loss 0.00010\n",
      "[2026-01-19 21:51:20] ## n_step 8192000 score -8.407 best score 5.646 loss 0.00011\n",
      "step= 254000 a= 0.2777065634727478 b= 1.0309656858444214 std= 3.6009232997894287 freeze= True\n",
      "[2026-01-19 21:52:36] ## n_step 8208000 score -8.031 best score 5.646 loss 0.00010\n",
      "[2026-01-19 21:53:50] ## n_step 8224000 score -9.732 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:55:05] ## n_step 8240000 score -12.269 best score 5.646 loss 0.00013\n",
      "[2026-01-19 21:56:19] ## n_step 8256000 score -8.850 best score 5.646 loss 0.00009\n",
      "step= 256000 a= 0.2808815836906433 b= 1.058475136756897 std= 3.5602190494537354 freeze= True\n",
      "[2026-01-19 21:57:34] ## n_step 8272000 score -5.332 best score 5.646 loss 0.00012\n",
      "[2026-01-19 21:58:49] ## n_step 8288000 score -8.283 best score 5.646 loss 0.00009\n",
      "[2026-01-19 22:00:04] ## n_step 8304000 score -6.198 best score 5.646 loss 0.00016\n",
      "[2026-01-19 22:01:17] ## n_step 8320000 score -9.673 best score 5.646 loss 0.00010\n",
      "step= 258000 a= 0.28212597966194153 b= 1.0518358945846558 std= 3.54451584815979 freeze= True\n",
      "[2026-01-19 22:02:35] ## n_step 8336000 score -5.735 best score 5.646 loss 0.00013\n",
      "[2026-01-19 22:03:49] ## n_step 8352000 score -4.458 best score 5.646 loss 0.00012\n",
      "[2026-01-19 22:05:03] ## n_step 8368000 score -6.588 best score 5.646 loss 0.00008\n",
      "[2026-01-19 22:06:16] ## n_step 8384000 score -6.359 best score 5.646 loss 0.00010\n",
      "step= 260000 a= 0.2898603081703186 b= 1.0404300689697266 std= 3.449937582015991 freeze= True\n",
      "[2026-01-19 22:07:34] ## n_step 8400000 score -8.527 best score 5.646 loss 0.00011\n",
      "[2026-01-19 22:08:48] ## n_step 8416000 score -7.987 best score 5.646 loss 0.00012\n",
      "[2026-01-19 22:10:01] ## n_step 8432000 score -8.045 best score 5.646 loss 0.00009\n",
      "[2026-01-19 22:11:16] ## n_step 8448000 score -7.192 best score 5.646 loss 0.00013\n",
      "step= 262000 a= 0.29635438323020935 b= 1.0087790489196777 std= 3.374338388442993 freeze= True\n",
      "[2026-01-19 22:12:30] ## n_step 8464000 score -9.194 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:13:44] ## n_step 8480000 score -6.220 best score 5.646 loss 0.00011\n",
      "[2026-01-19 22:14:59] ## n_step 8496000 score -4.908 best score 5.646 loss 0.00013\n",
      "[2026-01-19 22:16:14] ## n_step 8512000 score -8.017 best score 5.646 loss 0.00011\n",
      "step= 264000 a= 0.3006361722946167 b= 0.9890450239181519 std= 3.326279640197754 freeze= True\n",
      "[2026-01-19 22:17:30] ## n_step 8528000 score -9.988 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:18:49] ## n_step 8544000 score -5.662 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:20:03] ## n_step 8560000 score -5.005 best score 5.646 loss 0.00011\n",
      "[2026-01-19 22:21:17] ## n_step 8576000 score -10.127 best score 5.646 loss 0.00012\n",
      "step= 266000 a= 0.30525144934654236 b= 0.9869896173477173 std= 3.2759876251220703 freeze= True\n",
      "[2026-01-19 22:22:32] ## n_step 8592000 score -4.057 best score 5.646 loss 0.00013\n",
      "[2026-01-19 22:23:47] ## n_step 8608000 score -10.033 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:25:01] ## n_step 8624000 score -7.695 best score 5.646 loss 0.00008\n",
      "[2026-01-19 22:26:15] ## n_step 8640000 score -1.298 best score 5.646 loss 0.00011\n",
      "step= 268000 a= 0.3017371594905853 b= 0.9627590179443359 std= 3.3141427040100098 freeze= True\n",
      "[2026-01-19 22:27:30] ## n_step 8656000 score -6.084 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:28:45] ## n_step 8672000 score -5.369 best score 5.646 loss 0.00009\n",
      "[2026-01-19 22:29:58] ## n_step 8688000 score -9.823 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:31:13] ## n_step 8704000 score -7.175 best score 5.646 loss 0.00011\n",
      "step= 270000 a= 0.2969340682029724 b= 0.9430077075958252 std= 3.367751121520996 freeze= True\n",
      "[2026-01-19 22:32:28] ## n_step 8720000 score -10.405 best score 5.646 loss 0.00012\n",
      "[2026-01-19 22:33:44] ## n_step 8736000 score -4.223 best score 5.646 loss 0.00012\n",
      "[2026-01-19 22:34:58] ## n_step 8752000 score -5.536 best score 5.646 loss 0.00009\n",
      "[2026-01-19 22:36:12] ## n_step 8768000 score -4.136 best score 5.646 loss 0.00009\n",
      "step= 272000 a= 0.29628506302833557 b= 0.9356069564819336 std= 3.3751277923583984 freeze= True\n",
      "[2026-01-19 22:37:28] ## n_step 8784000 score -10.319 best score 5.646 loss 0.00012\n",
      "[2026-01-19 22:38:47] ## n_step 8800000 score -4.358 best score 5.646 loss 0.00011\n",
      "[2026-01-19 22:40:01] ## n_step 8816000 score -2.948 best score 5.646 loss 0.00011\n",
      "[2026-01-19 22:41:15] ## n_step 8832000 score -5.233 best score 5.646 loss 0.00009\n",
      "step= 274000 a= 0.29686835408210754 b= 0.9204082489013672 std= 3.3684964179992676 freeze= True\n",
      "[2026-01-19 22:42:29] ## n_step 8848000 score -10.326 best score 5.646 loss 0.00013\n",
      "[2026-01-19 22:43:44] ## n_step 8864000 score -6.076 best score 5.646 loss 0.00011\n",
      "[2026-01-19 22:44:58] ## n_step 8880000 score -7.590 best score 5.646 loss 0.00013\n",
      "[2026-01-19 22:46:12] ## n_step 8896000 score -11.997 best score 5.646 loss 0.00008\n",
      "step= 276000 a= 0.29508453607559204 b= 0.9172874689102173 std= 3.388859510421753 freeze= True\n",
      "[2026-01-19 22:47:26] ## n_step 8912000 score -6.652 best score 5.646 loss 0.00013\n",
      "[2026-01-19 22:48:40] ## n_step 8928000 score -6.476 best score 5.646 loss 0.00008\n",
      "[2026-01-19 22:49:54] ## n_step 8944000 score -3.684 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:51:09] ## n_step 8960000 score -8.372 best score 5.646 loss 0.00012\n",
      "step= 278000 a= 0.29159972071647644 b= 0.9153639078140259 std= 3.42935848236084 freeze= True\n",
      "[2026-01-19 22:52:22] ## n_step 8976000 score -5.444 best score 5.646 loss 0.00010\n",
      "[2026-01-19 22:53:36] ## n_step 8992000 score -8.571 best score 5.646 loss 0.00008\n",
      "[2026-01-19 22:54:13] ## evaluating\n",
      "MDT Human:100.4 AI:-101.7\n",
      "JNPR Human:83.3 AI:-84.7\n",
      "VICI Human:76.6 AI:-84.7\n",
      "FANG Human:84.9 AI:-92.9\n",
      "CRL Human:68.2 AI:-76.3\n",
      "PPG Human:62.0 AI:-76.3\n",
      "ETR Human:46.1 AI:-60.3\n",
      "ODFL Human:40.6 AI:-60.3\n",
      "CMS Human:50.6 AI:-70.3\n",
      "AEE Human:60.0 AI:-79.7\n",
      "score_eval=0.959 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 0 Bought: 0\n",
      "Balance: 10,000.00 Net worth: 10,000.00 Max worth: 10,000.00 total_sales: 0.00\n",
      "Avg price bought: 0.00 Avg price_sold: 0.00\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-19 22:55:45] ## n_step 9008000 score -8.291 best score 5.646 loss 0.00014\n",
      "[2026-01-19 22:56:59] ## n_step 9024000 score -6.516 best score 5.646 loss 0.00012\n",
      "step= 280000 a= 0.29186949133872986 b= 0.9288370609283447 std= 3.4261889457702637 freeze= True\n",
      "[2026-01-19 22:58:14] ## n_step 9040000 score -8.217 best score 5.646 loss 0.00011\n",
      "[2026-01-19 22:59:29] ## n_step 9056000 score -6.258 best score 5.646 loss 0.00015\n",
      "[2026-01-19 23:00:43] ## n_step 9072000 score -6.227 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:01:56] ## n_step 9088000 score -5.007 best score 5.646 loss 0.00010\n",
      "step= 282000 a= 0.2923907935619354 b= 0.9313632249832153 std= 3.4200804233551025 freeze= True\n",
      "[2026-01-19 23:03:10] ## n_step 9104000 score -5.606 best score 5.646 loss 0.00010\n",
      "[2026-01-19 23:04:25] ## n_step 9120000 score -8.636 best score 5.646 loss 0.00010\n",
      "[2026-01-19 23:05:39] ## n_step 9136000 score -3.849 best score 5.646 loss 0.00008\n",
      "[2026-01-19 23:06:54] ## n_step 9152000 score -8.103 best score 5.646 loss 0.00016\n",
      "step= 284000 a= 0.29293859004974365 b= 0.9329407215118408 std= 3.413684844970703 freeze= True\n",
      "[2026-01-19 23:08:08] ## n_step 9168000 score -8.052 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:09:23] ## n_step 9184000 score -2.200 best score 5.646 loss 0.00010\n",
      "[2026-01-19 23:10:37] ## n_step 9200000 score -5.473 best score 5.646 loss 0.00011\n",
      "[2026-01-19 23:11:51] ## n_step 9216000 score -8.381 best score 5.646 loss 0.00012\n",
      "step= 286000 a= 0.2960926592350006 b= 0.9418702721595764 std= 3.3773210048675537 freeze= True\n",
      "[2026-01-19 23:13:05] ## n_step 9232000 score -8.940 best score 5.646 loss 0.00012\n",
      "[2026-01-19 23:14:19] ## n_step 9248000 score -6.223 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:15:34] ## n_step 9264000 score -5.644 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:16:49] ## n_step 9280000 score -2.369 best score 5.646 loss 0.00012\n",
      "step= 288000 a= 0.2951856553554535 b= 0.9383478164672852 std= 3.3876984119415283 freeze= True\n",
      "[2026-01-19 23:18:03] ## n_step 9296000 score -13.142 best score 5.646 loss 0.00013\n",
      "[2026-01-19 23:19:18] ## n_step 9312000 score -4.288 best score 5.646 loss 0.00008\n",
      "[2026-01-19 23:20:32] ## n_step 9328000 score -7.234 best score 5.646 loss 0.00008\n",
      "[2026-01-19 23:21:46] ## n_step 9344000 score -10.189 best score 5.646 loss 0.00010\n",
      "step= 290000 a= 0.29703623056411743 b= 0.9513106346130371 std= 3.3665926456451416 freeze= True\n",
      "[2026-01-19 23:23:01] ## n_step 9360000 score -11.249 best score 5.646 loss 0.00011\n",
      "[2026-01-19 23:24:15] ## n_step 9376000 score -8.746 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:25:30] ## n_step 9392000 score -4.505 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:26:44] ## n_step 9408000 score -11.735 best score 5.646 loss 0.00007\n",
      "step= 292000 a= 0.2984325885772705 b= 0.9527857303619385 std= 3.3508403301239014 freeze= True\n",
      "[2026-01-19 23:27:58] ## n_step 9424000 score -7.847 best score 5.646 loss 0.00011\n",
      "[2026-01-19 23:29:12] ## n_step 9440000 score -11.618 best score 5.646 loss 0.00011\n",
      "[2026-01-19 23:30:25] ## n_step 9456000 score -7.292 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:31:40] ## n_step 9472000 score -6.100 best score 5.646 loss 0.00012\n",
      "step= 294000 a= 0.29857337474823 b= 0.9593408107757568 std= 3.3492603302001953 freeze= True\n",
      "[2026-01-19 23:32:54] ## n_step 9488000 score -8.900 best score 5.646 loss 0.00008\n",
      "[2026-01-19 23:34:09] ## n_step 9504000 score -5.511 best score 5.646 loss 0.00013\n",
      "[2026-01-19 23:35:24] ## n_step 9520000 score -7.567 best score 5.646 loss 0.00006\n",
      "[2026-01-19 23:36:39] ## n_step 9536000 score -6.707 best score 5.646 loss 0.00011\n",
      "step= 296000 a= 0.2979440689086914 b= 0.9526860117912292 std= 3.356334686279297 freeze= True\n",
      "[2026-01-19 23:37:53] ## n_step 9552000 score -5.540 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:39:09] ## n_step 9568000 score -4.391 best score 5.646 loss 0.00012\n",
      "[2026-01-19 23:40:25] ## n_step 9584000 score -7.867 best score 5.646 loss 0.00010\n",
      "[2026-01-19 23:41:38] ## n_step 9600000 score -9.737 best score 5.646 loss 0.00008\n",
      "step= 298000 a= 0.3010565936565399 b= 0.9661861658096313 std= 3.3216347694396973 freeze= True\n",
      "[2026-01-19 23:42:53] ## n_step 9616000 score -9.390 best score 5.646 loss 0.00008\n",
      "[2026-01-19 23:44:07] ## n_step 9632000 score -4.126 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:45:21] ## n_step 9648000 score -5.267 best score 5.646 loss 0.00010\n",
      "[2026-01-19 23:46:38] ## n_step 9664000 score -8.822 best score 5.646 loss 0.00008\n",
      "step= 300000 a= 0.29909762740135193 b= 0.9566548466682434 std= 3.3433899879455566 freeze= True\n",
      "[2026-01-19 23:47:53] ## n_step 9680000 score -8.812 best score 5.646 loss 0.00009\n",
      "[2026-01-19 23:49:09] ## n_step 9696000 score -9.238 best score 5.646 loss 0.00011\n",
      "[2026-01-19 23:50:24] ## n_step 9712000 score -7.733 best score 5.646 loss 0.00007\n",
      "[2026-01-19 23:51:38] ## n_step 9728000 score -2.776 best score 5.646 loss 0.00010\n",
      "step= 302000 a= 0.29921382665634155 b= 0.9558454751968384 std= 3.3420915603637695 freeze= True\n",
      "[2026-01-19 23:52:52] ## n_step 9744000 score -5.945 best score 5.646 loss 0.00010\n",
      "[2026-01-19 23:54:07] ## n_step 9760000 score -7.794 best score 5.646 loss 0.00011\n",
      "[2026-01-19 23:55:21] ## n_step 9776000 score -4.211 best score 5.646 loss 0.00008\n",
      "[2026-01-19 23:56:36] ## n_step 9792000 score -6.525 best score 5.646 loss 0.00008\n",
      "step= 304000 a= 0.2965654134750366 b= 0.9444696307182312 std= 3.3719372749328613 freeze= True\n",
      "[2026-01-19 23:57:50] ## n_step 9808000 score -9.863 best score 5.646 loss 0.00008\n",
      "[2026-01-19 23:59:06] ## n_step 9824000 score -7.861 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:00:20] ## n_step 9840000 score -11.708 best score 5.646 loss 0.00010\n",
      "[2026-01-20 00:01:38] ## n_step 9856000 score -8.009 best score 5.646 loss 0.00011\n",
      "step= 306000 a= 0.29904285073280334 b= 0.970587968826294 std= 3.3440024852752686 freeze= True\n",
      "[2026-01-20 00:02:55] ## n_step 9872000 score -8.509 best score 5.646 loss 0.00008\n",
      "[2026-01-20 00:04:11] ## n_step 9888000 score -8.514 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:05:25] ## n_step 9904000 score -1.916 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:06:39] ## n_step 9920000 score -5.106 best score 5.646 loss 0.00013\n",
      "step= 308000 a= 0.3022841215133667 b= 0.9935292601585388 std= 3.3081459999084473 freeze= True\n",
      "[2026-01-20 00:07:53] ## n_step 9936000 score -6.737 best score 5.646 loss 0.00011\n",
      "[2026-01-20 00:09:08] ## n_step 9952000 score -6.241 best score 5.646 loss 0.00008\n",
      "[2026-01-20 00:10:23] ## n_step 9968000 score -5.359 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:11:37] ## n_step 9984000 score -6.173 best score 5.646 loss 0.00010\n",
      "step= 310000 a= 0.30454376339912415 b= 0.991356611251831 std= 3.283600330352783 freeze= True\n",
      "[2026-01-20 00:12:51] ## n_step 10000000 score -5.765 best score 5.646 loss 0.00008\n",
      "[2026-01-20 00:12:51] ## evaluating\n",
      "DFS Human:38.4 AI:-63.8\n",
      "STLD Human:48.3 AI:-73.8\n",
      "ADP Human:57.7 AI:-83.1\n",
      "ROP Human:66.5 AI:-92.0\n",
      "KEYS Human:74.9 AI:-100.3\n",
      "GEN Human:68.9 AI:-100.3\n",
      "DLR Human:63.3 AI:-100.3\n",
      "HEI.DE Human:71.5 AI:-108.5\n",
      "LRCX Human:79.2 AI:-116.2\n",
      "ACGL Human:86.5 AI:-123.6\n",
      "score_eval=0.891 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 146 Bought: 146\n",
      "Balance: 9,969.42 Net worth: 9,969.42 Max worth: 10,000.00 total_sales: 2,456.49\n",
      "Avg price bought: 1.00 Avg price_sold: 16.83\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-20 00:15:01] ## n_step 10016000 score -5.588 best score 5.646 loss 0.00009\n",
      "[2026-01-20 00:16:16] ## n_step 10032000 score -13.002 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:17:30] ## n_step 10048000 score -9.442 best score 5.646 loss 0.00008\n",
      "step= 312000 a= 0.3049706816673279 b= 1.0043063163757324 std= 3.279003620147705 freeze= True\n",
      "[2026-01-20 00:18:45] ## n_step 10064000 score -8.333 best score 5.646 loss 0.00009\n",
      "[2026-01-20 00:19:59] ## n_step 10080000 score -8.694 best score 5.646 loss 0.00009\n",
      "[2026-01-20 00:21:13] ## n_step 10096000 score -3.823 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:22:28] ## n_step 10112000 score -6.331 best score 5.646 loss 0.00008\n",
      "step= 314000 a= 0.30458924174308777 b= 0.9902291893959045 std= 3.2831101417541504 freeze= True\n",
      "[2026-01-20 00:23:42] ## n_step 10128000 score -9.184 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:24:57] ## n_step 10144000 score -6.238 best score 5.646 loss 0.00010\n",
      "[2026-01-20 00:26:11] ## n_step 10160000 score -12.599 best score 5.646 loss 0.00008\n",
      "[2026-01-20 00:27:26] ## n_step 10176000 score -9.031 best score 5.646 loss 0.00006\n",
      "step= 316000 a= 0.30524855852127075 b= 1.0118277072906494 std= 3.2760186195373535 freeze= True\n",
      "[2026-01-20 00:28:41] ## n_step 10192000 score -8.068 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:29:55] ## n_step 10208000 score -10.056 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:31:10] ## n_step 10224000 score -8.358 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:32:24] ## n_step 10240000 score -8.421 best score 5.646 loss 0.00007\n",
      "step= 318000 a= 0.3028114140033722 b= 1.0109357833862305 std= 3.3023853302001953 freeze= True\n",
      "[2026-01-20 00:33:38] ## n_step 10256000 score -9.684 best score 5.646 loss 0.00005\n",
      "[2026-01-20 00:34:53] ## n_step 10272000 score -6.739 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:36:08] ## n_step 10288000 score -12.249 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:37:23] ## n_step 10304000 score -5.744 best score 5.646 loss 0.00009\n",
      "step= 320000 a= 0.3011723756790161 b= 1.0125720500946045 std= 3.3203577995300293 freeze= True\n",
      "[2026-01-20 00:38:37] ## n_step 10320000 score -5.861 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:39:52] ## n_step 10336000 score -8.279 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:41:07] ## n_step 10352000 score -9.638 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:42:22] ## n_step 10368000 score -4.904 best score 5.646 loss 0.00006\n",
      "step= 322000 a= 0.29801249504089355 b= 1.005881667137146 std= 3.3555638790130615 freeze= True\n",
      "[2026-01-20 00:43:37] ## n_step 10384000 score -9.709 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:44:51] ## n_step 10400000 score -8.564 best score 5.646 loss 0.00008\n",
      "[2026-01-20 00:46:05] ## n_step 10416000 score -6.640 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:47:20] ## n_step 10432000 score -6.510 best score 5.646 loss 0.00008\n",
      "step= 324000 a= 0.29561102390289307 b= 0.9984430074691772 std= 3.3828237056732178 freeze= True\n",
      "[2026-01-20 00:48:34] ## n_step 10448000 score -5.212 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:49:48] ## n_step 10464000 score -5.498 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:51:02] ## n_step 10480000 score -7.786 best score 5.646 loss 0.00008\n",
      "[2026-01-20 00:52:16] ## n_step 10496000 score -6.097 best score 5.646 loss 0.00006\n",
      "step= 326000 a= 0.29432404041290283 b= 0.9875238537788391 std= 3.397615671157837 freeze= True\n",
      "[2026-01-20 00:53:29] ## n_step 10512000 score -7.402 best score 5.646 loss 0.00005\n",
      "[2026-01-20 00:54:45] ## n_step 10528000 score -7.797 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:56:00] ## n_step 10544000 score -4.848 best score 5.646 loss 0.00006\n",
      "[2026-01-20 00:57:15] ## n_step 10560000 score -4.753 best score 5.646 loss 0.00005\n",
      "step= 328000 a= 0.2952101230621338 b= 0.9911030530929565 std= 3.3874175548553467 freeze= True\n",
      "[2026-01-20 00:58:29] ## n_step 10576000 score -11.151 best score 5.646 loss 0.00007\n",
      "[2026-01-20 00:59:46] ## n_step 10592000 score -2.033 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:01:00] ## n_step 10608000 score -7.028 best score 5.646 loss 0.00007\n",
      "[2026-01-20 01:02:15] ## n_step 10624000 score -6.233 best score 5.646 loss 0.00006\n",
      "step= 330000 a= 0.29472678899765015 b= 0.9701970219612122 std= 3.392972946166992 freeze= True\n",
      "[2026-01-20 01:03:29] ## n_step 10640000 score -5.678 best score 5.646 loss 0.00007\n",
      "[2026-01-20 01:04:47] ## n_step 10656000 score -8.913 best score 5.646 loss 0.00007\n",
      "[2026-01-20 01:06:01] ## n_step 10672000 score -9.557 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:07:16] ## n_step 10688000 score -6.904 best score 5.646 loss 0.00006\n",
      "step= 332000 a= 0.2957156300544739 b= 0.9720650315284729 std= 3.381627082824707 freeze= True\n",
      "[2026-01-20 01:08:30] ## n_step 10704000 score -5.936 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:09:44] ## n_step 10720000 score -7.843 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:10:59] ## n_step 10736000 score -3.468 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:12:13] ## n_step 10752000 score -5.412 best score 5.646 loss 0.00005\n",
      "step= 334000 a= 0.2939591705799103 b= 0.9493774771690369 std= 3.4018328189849854 freeze= True\n",
      "[2026-01-20 01:13:27] ## n_step 10768000 score -6.225 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:14:42] ## n_step 10784000 score -8.434 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:15:57] ## n_step 10800000 score -7.359 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:17:12] ## n_step 10816000 score -5.771 best score 5.646 loss 0.00007\n",
      "step= 336000 a= 0.29618656635284424 b= 0.9580689668655396 std= 3.3762505054473877 freeze= True\n",
      "[2026-01-20 01:18:26] ## n_step 10832000 score -7.577 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:19:42] ## n_step 10848000 score -9.411 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:20:55] ## n_step 10864000 score -9.370 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:22:10] ## n_step 10880000 score -9.071 best score 5.646 loss 0.00005\n",
      "step= 338000 a= 0.3021502196788788 b= 0.9942895770072937 std= 3.3096120357513428 freeze= True\n",
      "[2026-01-20 01:23:25] ## n_step 10896000 score -7.144 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:24:40] ## n_step 10912000 score -11.758 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:25:54] ## n_step 10928000 score -8.292 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:27:08] ## n_step 10944000 score -8.517 best score 5.646 loss 0.00006\n",
      "step= 340000 a= 0.3008143901824951 b= 0.986276388168335 std= 3.3243091106414795 freeze= True\n",
      "[2026-01-20 01:28:28] ## n_step 10960000 score -4.785 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:29:43] ## n_step 10976000 score -6.892 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:30:57] ## n_step 10992000 score -7.936 best score 5.646 loss 0.00007\n",
      "[2026-01-20 01:31:34] ## evaluating\n",
      "GME Human:63.6 AI:-106.5\n",
      "UBER Human:71.6 AI:-114.5\n",
      "IT Human:79.2 AI:-122.1\n",
      "ROST Human:86.3 AI:-129.3\n",
      "CCL Human:80.6 AI:-129.3\n",
      "NDSN Human:75.0 AI:-129.3\n",
      "APD Human:58.0 AI:-112.2\n",
      "VST Human:66.0 AI:-120.2\n",
      "LYB Human:61.0 AI:-120.2\n",
      "QCOM Human:68.7 AI:-127.9\n",
      "score_eval=1.008 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 0 Bought: 0\n",
      "Balance: 10,000.00 Net worth: 10,000.00 Max worth: 10,000.00 total_sales: 0.00\n",
      "Avg price bought: 0.00 Avg price_sold: 0.00\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-20 01:33:06] ## n_step 11008000 score -3.894 best score 5.646 loss 0.00006\n",
      "step= 342000 a= 0.3021652102470398 b= 0.9858447313308716 std= 3.309447765350342 freeze= True\n",
      "[2026-01-20 01:34:21] ## n_step 11024000 score -9.615 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:35:35] ## n_step 11040000 score -7.061 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:36:50] ## n_step 11056000 score -3.816 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:38:04] ## n_step 11072000 score -4.503 best score 5.646 loss 0.00006\n",
      "step= 344000 a= 0.3019459843635559 b= 0.9778346419334412 std= 3.3118507862091064 freeze= True\n",
      "[2026-01-20 01:39:19] ## n_step 11088000 score -3.050 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:40:33] ## n_step 11104000 score -7.447 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:41:47] ## n_step 11120000 score -8.478 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:43:01] ## n_step 11136000 score -4.958 best score 5.646 loss 0.00005\n",
      "step= 346000 a= 0.30415594577789307 b= 0.9987987279891968 std= 3.2877869606018066 freeze= True\n",
      "[2026-01-20 01:44:16] ## n_step 11152000 score -11.017 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:45:29] ## n_step 11168000 score -4.877 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:46:44] ## n_step 11184000 score -7.977 best score 5.646 loss 0.00004\n",
      "[2026-01-20 01:47:58] ## n_step 11200000 score -7.976 best score 5.646 loss 0.00005\n",
      "step= 348000 a= 0.30480390787124634 b= 1.0054349899291992 std= 3.2807979583740234 freeze= True\n",
      "[2026-01-20 01:49:13] ## n_step 11216000 score -5.462 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:50:28] ## n_step 11232000 score -9.865 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:51:42] ## n_step 11248000 score -7.903 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:52:56] ## n_step 11264000 score -7.121 best score 5.646 loss 0.00008\n",
      "step= 350000 a= 0.30447253584861755 b= 0.9957314729690552 std= 3.2843685150146484 freeze= True\n",
      "[2026-01-20 01:54:11] ## n_step 11280000 score -3.952 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:55:25] ## n_step 11296000 score -9.379 best score 5.646 loss 0.00005\n",
      "[2026-01-20 01:56:39] ## n_step 11312000 score -6.160 best score 5.646 loss 0.00006\n",
      "[2026-01-20 01:57:54] ## n_step 11328000 score -6.800 best score 5.646 loss 0.00007\n",
      "step= 352000 a= 0.30693867802619934 b= 1.005791187286377 std= 3.2579798698425293 freeze= True\n",
      "[2026-01-20 01:59:09] ## n_step 11344000 score -7.394 best score 5.646 loss 0.00006\n",
      "[2026-01-20 02:00:24] ## n_step 11360000 score -3.613 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:01:39] ## n_step 11376000 score -5.767 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:02:52] ## n_step 11392000 score -4.502 best score 5.646 loss 0.00005\n",
      "step= 354000 a= 0.3079688251018524 b= 0.9894181489944458 std= 3.247081995010376 freeze= True\n",
      "[2026-01-20 02:04:07] ## n_step 11408000 score -5.753 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:05:22] ## n_step 11424000 score -10.195 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:06:36] ## n_step 11440000 score -7.762 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:07:51] ## n_step 11456000 score -11.002 best score 5.646 loss 0.00006\n",
      "step= 356000 a= 0.3114585876464844 b= 1.0048187971115112 std= 3.2106997966766357 freeze= True\n",
      "[2026-01-20 02:09:06] ## n_step 11472000 score -5.153 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:10:20] ## n_step 11488000 score -4.269 best score 5.646 loss 0.00006\n",
      "[2026-01-20 02:11:35] ## n_step 11504000 score -9.062 best score 5.646 loss 0.00006\n",
      "[2026-01-20 02:12:49] ## n_step 11520000 score -8.560 best score 5.646 loss 0.00005\n",
      "step= 358000 a= 0.30996280908584595 b= 0.9886230826377869 std= 3.226193428039551 freeze= True\n",
      "[2026-01-20 02:14:03] ## n_step 11536000 score -9.196 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:15:18] ## n_step 11552000 score -7.716 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:16:32] ## n_step 11568000 score -1.720 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:17:46] ## n_step 11584000 score -4.599 best score 5.646 loss 0.00005\n",
      "step= 360000 a= 0.3101562261581421 b= 0.9864243268966675 std= 3.224181652069092 freeze= True\n",
      "[2026-01-20 02:19:01] ## n_step 11600000 score -9.621 best score 5.646 loss 0.00006\n",
      "[2026-01-20 02:20:15] ## n_step 11616000 score -2.566 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:21:29] ## n_step 11632000 score -5.644 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:22:44] ## n_step 11648000 score -6.742 best score 5.646 loss 0.00004\n",
      "step= 362000 a= 0.3134136199951172 b= 0.9889633655548096 std= 3.190671682357788 freeze= True\n",
      "[2026-01-20 02:23:58] ## n_step 11664000 score -6.709 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:25:12] ## n_step 11680000 score -8.297 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:26:27] ## n_step 11696000 score -5.747 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:27:42] ## n_step 11712000 score -4.885 best score 5.646 loss 0.00004\n",
      "step= 364000 a= 0.3170676827430725 b= 0.9992198348045349 std= 3.1539008617401123 freeze= True\n",
      "[2026-01-20 02:28:56] ## n_step 11728000 score -5.887 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:30:10] ## n_step 11744000 score -8.343 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:31:24] ## n_step 11760000 score -8.620 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:32:39] ## n_step 11776000 score -7.469 best score 5.646 loss 0.00005\n",
      "step= 366000 a= 0.3203660845756531 b= 1.0064425468444824 std= 3.121428966522217 freeze= True\n",
      "[2026-01-20 02:33:53] ## n_step 11792000 score -7.888 best score 5.646 loss 0.00006\n",
      "[2026-01-20 02:35:08] ## n_step 11808000 score -9.405 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:36:23] ## n_step 11824000 score -5.330 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:37:37] ## n_step 11840000 score -8.319 best score 5.646 loss 0.00005\n",
      "step= 368000 a= 0.3208516836166382 b= 1.0063823461532593 std= 3.1167049407958984 freeze= True\n",
      "[2026-01-20 02:38:53] ## n_step 11856000 score -6.772 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:40:08] ## n_step 11872000 score -5.073 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:41:23] ## n_step 11888000 score -4.559 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:42:37] ## n_step 11904000 score -5.849 best score 5.646 loss 0.00005\n",
      "step= 370000 a= 0.3181559145450592 b= 0.9886152148246765 std= 3.143113136291504 freeze= True\n",
      "[2026-01-20 02:43:52] ## n_step 11920000 score -8.048 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:45:06] ## n_step 11936000 score -5.153 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:46:20] ## n_step 11952000 score -7.334 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:47:35] ## n_step 11968000 score -6.427 best score 5.646 loss 0.00003\n",
      "step= 372000 a= 0.3151630461215973 b= 0.970267117023468 std= 3.1729607582092285 freeze= True\n",
      "[2026-01-20 02:48:50] ## n_step 11984000 score -4.499 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:50:04] ## n_step 12000000 score -6.741 best score 5.646 loss 0.00004\n",
      "[2026-01-20 02:50:04] ## evaluating\n",
      "COTY Human:71.1 AI:-135.4\n",
      "JNJ Human:66.1 AI:-135.4\n",
      "GIS Human:49.1 AI:-118.4\n",
      "LOW Human:57.2 AI:-126.4\n",
      "MCK Human:64.8 AI:-134.1\n",
      "CSCO Human:72.1 AI:-141.3\n",
      "AYI Human:78.9 AI:-148.1\n",
      "BLDR Human:85.4 AI:-154.6\n",
      "NXPI Human:91.6 AI:-160.8\n",
      "DBK.DE Human:97.5 AI:-166.7\n",
      "score_eval=0.906 best_score_eval=1.028\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 0 Bought: 0\n",
      "Balance: 10,000.00 Net worth: 10,000.00 Max worth: 10,000.00 total_sales: 0.00\n",
      "Avg price bought: 0.00 Avg price_sold: 0.00\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-20 02:52:16] ## n_step 12016000 score -5.561 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:53:30] ## n_step 12032000 score -6.489 best score 5.646 loss 0.00004\n",
      "step= 374000 a= 0.3163565993309021 b= 0.9631496667861938 std= 3.160989999771118 freeze= True\n",
      "[2026-01-20 02:54:45] ## n_step 12048000 score -8.688 best score 5.646 loss 0.00007\n",
      "[2026-01-20 02:55:59] ## n_step 12064000 score -2.706 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:57:13] ## n_step 12080000 score -5.829 best score 5.646 loss 0.00005\n",
      "[2026-01-20 02:58:27] ## n_step 12096000 score -9.024 best score 5.646 loss 0.00005\n",
      "step= 376000 a= 0.3164356052875519 b= 0.9553444385528564 std= 3.160200595855713 freeze= True\n",
      "[2026-01-20 02:59:43] ## n_step 12112000 score -9.920 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:00:57] ## n_step 12128000 score -7.337 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:02:11] ## n_step 12144000 score -9.126 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:03:26] ## n_step 12160000 score -5.745 best score 5.646 loss 0.00005\n",
      "step= 378000 a= 0.3145503103733063 b= 0.954913318157196 std= 3.1791417598724365 freeze= True\n",
      "[2026-01-20 03:04:41] ## n_step 12176000 score -7.399 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:05:55] ## n_step 12192000 score -7.669 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:07:10] ## n_step 12208000 score -8.541 best score 5.646 loss 0.00005\n",
      "[2026-01-20 03:08:24] ## n_step 12224000 score -6.863 best score 5.646 loss 0.00003\n",
      "step= 380000 a= 0.3132186532020569 b= 0.9587517976760864 std= 3.192657947540283 freeze= True\n",
      "[2026-01-20 03:09:39] ## n_step 12240000 score -5.972 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:10:54] ## n_step 12256000 score -7.777 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:12:08] ## n_step 12272000 score -3.767 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:13:22] ## n_step 12288000 score -7.189 best score 5.646 loss 0.00003\n",
      "step= 382000 a= 0.3130946755409241 b= 0.9547194242477417 std= 3.1939220428466797 freeze= True\n",
      "[2026-01-20 03:14:37] ## n_step 12304000 score -6.651 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:15:52] ## n_step 12320000 score -4.597 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:17:07] ## n_step 12336000 score -3.547 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:18:21] ## n_step 12352000 score -7.143 best score 5.646 loss 0.00004\n",
      "step= 384000 a= 0.31195372343063354 b= 0.9438968300819397 std= 3.20560359954834 freeze= True\n",
      "[2026-01-20 03:19:37] ## n_step 12368000 score -6.073 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:20:51] ## n_step 12384000 score -2.689 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:22:06] ## n_step 12400000 score -6.105 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:23:21] ## n_step 12416000 score -4.284 best score 5.646 loss 0.00003\n",
      "step= 386000 a= 0.3116537928581238 b= 0.9352366924285889 std= 3.208688735961914 freeze= True\n",
      "[2026-01-20 03:24:34] ## n_step 12432000 score -7.486 best score 5.646 loss 0.00005\n",
      "[2026-01-20 03:25:49] ## n_step 12448000 score -6.262 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:27:04] ## n_step 12464000 score -8.014 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:28:18] ## n_step 12480000 score -6.684 best score 5.646 loss 0.00003\n",
      "step= 388000 a= 0.31018292903900146 b= 0.9216529130935669 std= 3.2239041328430176 freeze= True\n",
      "[2026-01-20 03:29:33] ## n_step 12496000 score -7.910 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:30:48] ## n_step 12512000 score -7.543 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:32:02] ## n_step 12528000 score -5.022 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:33:17] ## n_step 12544000 score -8.407 best score 5.646 loss 0.00003\n",
      "step= 390000 a= 0.3098723888397217 b= 0.9269343614578247 std= 3.227134943008423 freeze= True\n",
      "[2026-01-20 03:34:31] ## n_step 12560000 score -6.776 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:35:46] ## n_step 12576000 score -11.296 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:37:01] ## n_step 12592000 score -7.777 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:38:15] ## n_step 12608000 score -3.820 best score 5.646 loss 0.00003\n",
      "step= 392000 a= 0.3076401948928833 b= 0.9202502369880676 std= 3.2505505084991455 freeze= True\n",
      "[2026-01-20 03:39:30] ## n_step 12624000 score -5.714 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:40:45] ## n_step 12640000 score -4.275 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:41:59] ## n_step 12656000 score -12.017 best score 5.646 loss 0.00005\n",
      "[2026-01-20 03:43:14] ## n_step 12672000 score -6.695 best score 5.646 loss 0.00003\n",
      "step= 394000 a= 0.30684688687324524 b= 0.9257316589355469 std= 3.2589542865753174 freeze= True\n",
      "[2026-01-20 03:44:29] ## n_step 12688000 score -5.857 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:45:43] ## n_step 12704000 score -5.352 best score 5.646 loss 0.00002\n",
      "[2026-01-20 03:46:58] ## n_step 12720000 score -6.789 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:48:12] ## n_step 12736000 score -7.625 best score 5.646 loss 0.00003\n",
      "step= 396000 a= 0.30568525195121765 b= 0.9240518808364868 std= 3.271338701248169 freeze= True\n",
      "[2026-01-20 03:49:27] ## n_step 12752000 score -6.727 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:50:44] ## n_step 12768000 score -8.568 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:52:11] ## n_step 12784000 score -7.158 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:53:26] ## n_step 12800000 score -6.670 best score 5.646 loss 0.00003\n",
      "step= 398000 a= 0.30766230821609497 b= 0.9345455169677734 std= 3.250316858291626 freeze= True\n",
      "[2026-01-20 03:54:41] ## n_step 12816000 score -6.659 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:55:56] ## n_step 12832000 score -7.585 best score 5.646 loss 0.00004\n",
      "[2026-01-20 03:57:10] ## n_step 12848000 score -11.963 best score 5.646 loss 0.00003\n",
      "[2026-01-20 03:58:25] ## n_step 12864000 score -6.136 best score 5.646 loss 0.00003\n",
      "step= 400000 a= 0.3070576786994934 b= 0.9445047378540039 std= 3.2567169666290283 freeze= True\n",
      "[2026-01-20 03:59:41] ## n_step 12880000 score -13.551 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:00:55] ## n_step 12896000 score -5.507 best score 5.646 loss 0.00002\n",
      "[2026-01-20 04:02:09] ## n_step 12912000 score -10.142 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:03:24] ## n_step 12928000 score -8.253 best score 5.646 loss 0.00003\n",
      "step= 402000 a= 0.3057323396205902 b= 0.9480159878730774 std= 3.2708349227905273 freeze= True\n",
      "[2026-01-20 04:04:39] ## n_step 12944000 score -7.342 best score 5.646 loss 0.00004\n",
      "[2026-01-20 04:05:54] ## n_step 12960000 score -5.895 best score 5.646 loss 0.00004\n",
      "[2026-01-20 04:07:08] ## n_step 12976000 score -8.340 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:08:22] ## n_step 12992000 score -12.220 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:09:00] ## evaluating\n",
      "TSN Human:74.3 AI:-148.9\n",
      "WDC Human:80.9 AI:-155.5\n",
      "ESS Human:76.0 AI:-155.5\n",
      "1COV.DE Human:82.3 AI:-161.9\n",
      "AFL Human:88.4 AI:-168.0\n",
      "FOX Human:94.2 AI:-173.8\n",
      "EOG Human:76.3 AI:-155.9\n",
      "SYY Human:82.7 AI:-162.3\n",
      "HAS Human:65.1 AI:-144.7\n",
      "HP Human:60.6 AI:-144.7\n",
      "score_eval=1.053 best_score_eval=1.053\n",
      "Tick: T  step: 353 steps: 200 Hold: 591 Sold: 121 Bought: 712\n",
      "Balance: 44.65 Net worth: 8,452.18 Max worth: 10,750.62 total_sales: 2,137.92\n",
      "Avg price bought: 1.00 Avg price_sold: 17.67\n",
      "0.91 vs \u001b[6;30;41m0.85\u001b[0m model performance\n",
      "\n",
      "step= 404000 a= 0.30746495723724365 b= 0.968794584274292 std= 3.2524030208587646 freeze= True\n",
      "[2026-01-20 04:10:31] ## n_step 13008000 score -6.600 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:11:46] ## n_step 13024000 score -9.402 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:13:01] ## n_step 13040000 score -8.895 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:14:15] ## n_step 13056000 score -8.105 best score 5.646 loss 0.00003\n",
      "step= 406000 a= 0.3098320960998535 b= 0.9941742420196533 std= 3.2275545597076416 freeze= True\n",
      "[2026-01-20 04:15:30] ## n_step 13072000 score -9.024 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:16:45] ## n_step 13088000 score -6.018 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:17:59] ## n_step 13104000 score -8.644 best score 5.646 loss 0.00002\n",
      "[2026-01-20 04:19:15] ## n_step 13120000 score -10.566 best score 5.646 loss 0.00003\n",
      "step= 408000 a= 0.30985867977142334 b= 1.0080432891845703 std= 3.2272777557373047 freeze= True\n",
      "[2026-01-20 04:20:30] ## n_step 13136000 score -7.002 best score 5.646 loss 0.00004\n",
      "[2026-01-20 04:21:44] ## n_step 13152000 score -7.428 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:22:58] ## n_step 13168000 score -10.894 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:24:13] ## n_step 13184000 score -10.226 best score 5.646 loss 0.00004\n",
      "step= 410000 a= 0.31064555048942566 b= 1.0210052728652954 std= 3.2191028594970703 freeze= True\n",
      "[2026-01-20 04:25:27] ## n_step 13200000 score -6.980 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:26:42] ## n_step 13216000 score -6.951 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:27:56] ## n_step 13232000 score -4.100 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:29:11] ## n_step 13248000 score -7.931 best score 5.646 loss 0.00002\n",
      "step= 412000 a= 0.30914306640625 b= 1.0124746561050415 std= 3.234748125076294 freeze= True\n",
      "[2026-01-20 04:30:26] ## n_step 13264000 score -9.534 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:31:40] ## n_step 13280000 score -5.758 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:32:55] ## n_step 13296000 score -6.280 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:34:10] ## n_step 13312000 score -7.212 best score 5.646 loss 0.00002\n",
      "step= 414000 a= 0.3086824417114258 b= 1.0170737504959106 std= 3.2395753860473633 freeze= True\n",
      "[2026-01-20 04:35:25] ## n_step 13328000 score -10.713 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:36:40] ## n_step 13344000 score -5.853 best score 5.646 loss 0.00002\n",
      "[2026-01-20 04:37:55] ## n_step 13360000 score -9.706 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:39:09] ## n_step 13376000 score -10.938 best score 5.646 loss 0.00003\n",
      "step= 416000 a= 0.3054361343383789 b= 1.012292742729187 std= 3.2740068435668945 freeze= True\n",
      "[2026-01-20 04:40:24] ## n_step 13392000 score -5.776 best score 5.646 loss 0.00002\n",
      "[2026-01-20 04:41:38] ## n_step 13408000 score -9.817 best score 5.646 loss 0.00002\n",
      "[2026-01-20 04:42:51] ## n_step 13424000 score -7.430 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:44:06] ## n_step 13440000 score -8.604 best score 5.646 loss 0.00003\n",
      "step= 418000 a= 0.3087618052959442 b= 1.0390985012054443 std= 3.2387425899505615 freeze= True\n",
      "[2026-01-20 04:45:21] ## n_step 13456000 score -5.714 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:46:35] ## n_step 13472000 score -7.399 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:47:50] ## n_step 13488000 score -7.745 best score 5.646 loss 0.00002\n",
      "[2026-01-20 04:49:05] ## n_step 13504000 score -11.854 best score 5.646 loss 0.00003\n",
      "step= 420000 a= 0.30998605489730835 b= 1.0578619241714478 std= 3.2259514331817627 freeze= True\n",
      "[2026-01-20 04:50:19] ## n_step 13520000 score -5.495 best score 5.646 loss 0.00004\n",
      "[2026-01-20 04:51:34] ## n_step 13536000 score -9.546 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:52:49] ## n_step 13552000 score -9.007 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:54:03] ## n_step 13568000 score -10.815 best score 5.646 loss 0.00002\n",
      "step= 422000 a= 0.3127598464488983 b= 1.079561710357666 std= 3.1973414421081543 freeze= True\n",
      "[2026-01-20 04:55:18] ## n_step 13584000 score -4.657 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:56:32] ## n_step 13600000 score -9.491 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:57:46] ## n_step 13616000 score -6.242 best score 5.646 loss 0.00003\n",
      "[2026-01-20 04:59:01] ## n_step 13632000 score -11.585 best score 5.646 loss 0.00003\n",
      "step= 424000 a= 0.3158501386642456 b= 1.1024242639541626 std= 3.166058301925659 freeze= True\n",
      "[2026-01-20 05:00:16] ## n_step 13648000 score -6.903 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:01:31] ## n_step 13664000 score -6.540 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:02:46] ## n_step 13680000 score -3.942 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:04:01] ## n_step 13696000 score -8.796 best score 5.646 loss 0.00003\n",
      "step= 426000 a= 0.31431445479393005 b= 1.089280366897583 std= 3.1815273761749268 freeze= True\n",
      "[2026-01-20 05:05:15] ## n_step 13712000 score -4.429 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:06:30] ## n_step 13728000 score -8.185 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:07:44] ## n_step 13744000 score -6.233 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:08:59] ## n_step 13760000 score -12.337 best score 5.646 loss 0.00003\n",
      "step= 428000 a= 0.31491678953170776 b= 1.0995948314666748 std= 3.1754419803619385 freeze= True\n",
      "[2026-01-20 05:10:13] ## n_step 13776000 score -9.530 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:11:28] ## n_step 13792000 score -7.089 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:12:43] ## n_step 13808000 score -8.374 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:13:58] ## n_step 13824000 score -7.532 best score 5.646 loss 0.00003\n",
      "step= 430000 a= 0.3167894184589386 b= 1.1207730770111084 std= 3.1566710472106934 freeze= True\n",
      "[2026-01-20 05:15:12] ## n_step 13840000 score -9.515 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:16:27] ## n_step 13856000 score -7.589 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:17:42] ## n_step 13872000 score -5.822 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:18:57] ## n_step 13888000 score -6.174 best score 5.646 loss 0.00002\n",
      "step= 432000 a= 0.3155696988105774 b= 1.0988625288009644 std= 3.168872117996216 freeze= True\n",
      "[2026-01-20 05:20:12] ## n_step 13904000 score -10.405 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:21:26] ## n_step 13920000 score -6.216 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:22:40] ## n_step 13936000 score -5.258 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:23:55] ## n_step 13952000 score -8.396 best score 5.646 loss 0.00002\n",
      "step= 434000 a= 0.3149907886981964 b= 1.0983220338821411 std= 3.1746959686279297 freeze= True\n",
      "[2026-01-20 05:25:10] ## n_step 13968000 score -10.332 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:26:25] ## n_step 13984000 score -7.269 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:27:40] ## n_step 14000000 score -5.750 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:27:40] ## evaluating\n",
      "IT Human:67.6 AI:-153.3\n",
      "DAY Human:63.2 AI:-153.3\n",
      "MGM Human:70.0 AI:-160.0\n",
      "PCAR Human:76.4 AI:-166.5\n",
      "LEN Human:82.5 AI:-172.6\n",
      "GEN Human:77.8 AI:-172.6\n",
      "MAR Human:83.8 AI:-178.5\n",
      "DBK.DE Human:89.4 AI:-184.1\n",
      "CPRT Human:84.7 AI:-184.1\n",
      "COR Human:90.2 AI:-189.6\n",
      "score_eval=0.907 best_score_eval=1.053\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 0 Bought: 0\n",
      "Balance: 10,000.00 Net worth: 10,000.00 Max worth: 10,000.00 total_sales: 0.00\n",
      "Avg price bought: 0.00 Avg price_sold: 0.00\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-20 05:29:50] ## n_step 14016000 score -8.358 best score 5.646 loss 0.00002\n",
      "step= 436000 a= 0.3164091408252716 b= 1.1005221605300903 std= 3.1604650020599365 freeze= True\n",
      "[2026-01-20 05:31:05] ## n_step 14032000 score -6.045 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:32:19] ## n_step 14048000 score -9.643 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:33:33] ## n_step 14064000 score -7.002 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:34:48] ## n_step 14080000 score -8.096 best score 5.646 loss 0.00002\n",
      "step= 438000 a= 0.3170389235019684 b= 1.1023343801498413 std= 3.154186725616455 freeze= True\n",
      "[2026-01-20 05:36:02] ## n_step 14096000 score -14.128 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:37:17] ## n_step 14112000 score -9.208 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:38:32] ## n_step 14128000 score -9.938 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:39:47] ## n_step 14144000 score -7.198 best score 5.646 loss 0.00002\n",
      "step= 440000 a= 0.3174418807029724 b= 1.105377197265625 std= 3.1501829624176025 freeze= True\n",
      "[2026-01-20 05:41:03] ## n_step 14160000 score -8.909 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:42:18] ## n_step 14176000 score -10.049 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:43:33] ## n_step 14192000 score -6.073 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:44:48] ## n_step 14208000 score -9.691 best score 5.646 loss 0.00002\n",
      "step= 442000 a= 0.31689420342445374 b= 1.094972848892212 std= 3.1556272506713867 freeze= True\n",
      "[2026-01-20 05:46:03] ## n_step 14224000 score -9.446 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:47:18] ## n_step 14240000 score -10.413 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:48:32] ## n_step 14256000 score -6.953 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:49:47] ## n_step 14272000 score -6.505 best score 5.646 loss 0.00002\n",
      "step= 444000 a= 0.31833988428115845 b= 1.099021553993225 std= 3.141296625137329 freeze= True\n",
      "[2026-01-20 05:51:02] ## n_step 14288000 score -6.412 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:52:17] ## n_step 14304000 score -5.640 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:53:31] ## n_step 14320000 score -7.350 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:54:46] ## n_step 14336000 score -8.273 best score 5.646 loss 0.00002\n",
      "step= 446000 a= 0.3161805272102356 b= 1.0747692584991455 std= 3.162750244140625 freeze= True\n",
      "[2026-01-20 05:56:01] ## n_step 14352000 score -7.226 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:57:16] ## n_step 14368000 score -9.444 best score 5.646 loss 0.00003\n",
      "[2026-01-20 05:58:30] ## n_step 14384000 score -9.444 best score 5.646 loss 0.00002\n",
      "[2026-01-20 05:59:47] ## n_step 14400000 score -4.942 best score 5.646 loss 0.00003\n",
      "step= 448000 a= 0.31615519523620605 b= 1.070070743560791 std= 3.16300368309021 freeze= True\n",
      "[2026-01-20 06:01:02] ## n_step 14416000 score -9.217 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:02:18] ## n_step 14432000 score -11.088 best score 5.646 loss 0.00003\n",
      "[2026-01-20 06:03:34] ## n_step 14448000 score -9.688 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:04:49] ## n_step 14464000 score -8.567 best score 5.646 loss 0.00003\n",
      "step= 450000 a= 0.3188014328479767 b= 1.0908931493759155 std= 3.136748790740967 freeze= True\n",
      "[2026-01-20 06:06:05] ## n_step 14480000 score -8.859 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:07:20] ## n_step 14496000 score -12.765 best score 5.646 loss 0.00003\n",
      "[2026-01-20 06:08:35] ## n_step 14512000 score -9.572 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:09:53] ## n_step 14528000 score -10.893 best score 5.646 loss 0.00002\n",
      "step= 452000 a= 0.3232092559337616 b= 1.1169593334197998 std= 3.093970775604248 freeze= True\n",
      "[2026-01-20 06:11:07] ## n_step 14544000 score -5.248 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:12:22] ## n_step 14560000 score -9.891 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:13:37] ## n_step 14576000 score -5.068 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:14:52] ## n_step 14592000 score -7.587 best score 5.646 loss 0.00002\n",
      "step= 454000 a= 0.3209356963634491 b= 1.0979084968566895 std= 3.115889072418213 freeze= True\n",
      "[2026-01-20 06:16:09] ## n_step 14608000 score -8.815 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:17:24] ## n_step 14624000 score -3.730 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:18:41] ## n_step 14640000 score -8.835 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:19:56] ## n_step 14656000 score -10.509 best score 5.646 loss 0.00002\n",
      "step= 456000 a= 0.3211422562599182 b= 1.0924327373504639 std= 3.113884687423706 freeze= True\n",
      "[2026-01-20 06:21:13] ## n_step 14672000 score -10.012 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:22:28] ## n_step 14688000 score -12.486 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:23:44] ## n_step 14704000 score -15.538 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:24:59] ## n_step 14720000 score -7.664 best score 5.646 loss 0.00002\n",
      "step= 458000 a= 0.32210955023765564 b= 1.1143786907196045 std= 3.1045339107513428 freeze= True\n",
      "[2026-01-20 06:26:15] ## n_step 14736000 score -8.239 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:27:30] ## n_step 14752000 score -9.705 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:28:46] ## n_step 14768000 score -8.216 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:30:03] ## n_step 14784000 score -9.521 best score 5.646 loss 0.00002\n",
      "step= 460000 a= 0.32063186168670654 b= 1.12015700340271 std= 3.1188416481018066 freeze= True\n",
      "[2026-01-20 06:31:18] ## n_step 14800000 score -11.213 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:32:33] ## n_step 14816000 score -6.894 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:33:48] ## n_step 14832000 score -10.364 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:35:04] ## n_step 14848000 score -6.862 best score 5.646 loss 0.00002\n",
      "step= 462000 a= 0.3207417130470276 b= 1.1270418167114258 std= 3.1177735328674316 freeze= True\n",
      "[2026-01-20 06:36:20] ## n_step 14864000 score -10.823 best score 5.646 loss 0.00001\n",
      "[2026-01-20 06:37:35] ## n_step 14880000 score -10.110 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:38:50] ## n_step 14896000 score -8.364 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:40:06] ## n_step 14912000 score -7.357 best score 5.646 loss 0.00002\n",
      "step= 464000 a= 0.31896907091140747 b= 1.1181960105895996 std= 3.1351001262664795 freeze= True\n",
      "[2026-01-20 06:41:21] ## n_step 14928000 score -4.683 best score 5.646 loss 0.00001\n",
      "[2026-01-20 06:42:36] ## n_step 14944000 score -2.597 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:43:50] ## n_step 14960000 score -8.324 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:45:05] ## n_step 14976000 score -7.976 best score 5.646 loss 0.00002\n",
      "step= 466000 a= 0.3203875422477722 b= 1.1228175163269043 std= 3.121220111846924 freeze= True\n",
      "[2026-01-20 06:46:20] ## n_step 14992000 score -9.179 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:46:57] ## evaluating\n",
      "WTW Human:90.9 AI:-195.0\n",
      "INTC Human:86.4 AI:-195.0\n",
      "RL Human:91.6 AI:-200.2\n",
      "ENPH Human:96.6 AI:-205.2\n",
      "BG Human:101.4 AI:-209.9\n",
      "ABT Human:105.9 AI:-214.5\n",
      "JKHY Human:101.2 AI:-214.5\n",
      "RRC Human:82.8 AI:-196.2\n",
      "USB Human:78.7 AI:-196.2\n",
      "DELL Human:84.0 AI:-201.5\n",
      "score_eval=0.911 best_score_eval=1.053\n",
      "Tick: T  step: 353 steps: 200 Hold: 0 Sold: 0 Bought: 0\n",
      "Balance: 10,000.00 Net worth: 10,000.00 Max worth: 10,000.00 total_sales: 0.00\n",
      "Avg price bought: 0.00 Avg price_sold: 0.00\n",
      "0.91 vs \u001b[6;30;42m1.00\u001b[0m model performance\n",
      "\n",
      "[2026-01-20 06:48:30] ## n_step 15008000 score -9.717 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:49:46] ## n_step 15024000 score -7.965 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:51:01] ## n_step 15040000 score -9.059 best score 5.646 loss 0.00002\n",
      "step= 468000 a= 0.3225753903388977 b= 1.128792643547058 std= 3.100050449371338 freeze= True\n",
      "[2026-01-20 06:52:15] ## n_step 15056000 score -6.984 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:53:30] ## n_step 15072000 score -4.885 best score 5.646 loss 0.00001\n",
      "[2026-01-20 06:54:45] ## n_step 15088000 score -11.369 best score 5.646 loss 0.00001\n",
      "[2026-01-20 06:55:59] ## n_step 15104000 score -11.343 best score 5.646 loss 0.00002\n",
      "step= 470000 a= 0.326727956533432 b= 1.1507819890975952 std= 3.06065034866333 freeze= True\n",
      "[2026-01-20 06:57:12] ## n_step 15120000 score -9.271 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:58:30] ## n_step 15136000 score -9.554 best score 5.646 loss 0.00002\n",
      "[2026-01-20 06:59:45] ## n_step 15152000 score -6.475 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:01:00] ## n_step 15168000 score -9.340 best score 5.646 loss 0.00002\n",
      "step= 472000 a= 0.329243540763855 b= 1.1561613082885742 std= 3.0372653007507324 freeze= True\n",
      "[2026-01-20 07:02:16] ## n_step 15184000 score -10.533 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:03:30] ## n_step 15200000 score -11.679 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:04:44] ## n_step 15216000 score -8.438 best score 5.646 loss 0.00003\n",
      "[2026-01-20 07:05:59] ## n_step 15232000 score -8.292 best score 5.646 loss 0.00002\n",
      "step= 474000 a= 0.3274831473827362 b= 1.1569429636001587 std= 3.0535922050476074 freeze= True\n",
      "[2026-01-20 07:07:16] ## n_step 15248000 score -7.708 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:08:31] ## n_step 15264000 score -9.708 best score 5.646 loss 0.00001\n",
      "[2026-01-20 07:09:47] ## n_step 15280000 score -6.644 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:11:02] ## n_step 15296000 score -6.870 best score 5.646 loss 0.00002\n",
      "step= 476000 a= 0.3263932466506958 b= 1.147611141204834 std= 3.063788890838623 freeze= True\n",
      "[2026-01-20 07:12:19] ## n_step 15312000 score -6.363 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:13:32] ## n_step 15328000 score -5.518 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:14:47] ## n_step 15344000 score -3.056 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:16:02] ## n_step 15360000 score -6.227 best score 5.646 loss 0.00001\n",
      "step= 478000 a= 0.32642802596092224 b= 1.1353988647460938 std= 3.063462495803833 freeze= True\n",
      "[2026-01-20 07:17:18] ## n_step 15376000 score -7.191 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:18:33] ## n_step 15392000 score -7.851 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:19:48] ## n_step 15408000 score -7.839 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:21:00] ## n_step 15424000 score -9.777 best score 5.646 loss 0.00002\n",
      "step= 480000 a= 0.32930341362953186 b= 1.1538974046707153 std= 3.036713123321533 freeze= True\n",
      "[2026-01-20 07:22:14] ## n_step 15440000 score -8.843 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:23:28] ## n_step 15456000 score -7.870 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:24:43] ## n_step 15472000 score -8.088 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:25:59] ## n_step 15488000 score -7.178 best score 5.646 loss 0.00002\n",
      "step= 482000 a= 0.3318261206150055 b= 1.1603237390518188 std= 3.0136265754699707 freeze= True\n",
      "[2026-01-20 07:27:15] ## n_step 15504000 score -6.942 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:28:31] ## n_step 15520000 score -7.597 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:29:45] ## n_step 15536000 score -10.525 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:31:00] ## n_step 15552000 score -4.298 best score 5.646 loss 0.00002\n",
      "step= 484000 a= 0.3297061622142792 b= 1.1400177478790283 std= 3.033003568649292 freeze= True\n",
      "[2026-01-20 07:32:16] ## n_step 15568000 score -6.165 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:33:32] ## n_step 15584000 score -5.210 best score 5.646 loss 0.00003\n",
      "[2026-01-20 07:34:49] ## n_step 15600000 score -7.510 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:36:04] ## n_step 15616000 score -8.552 best score 5.646 loss 0.00002\n",
      "step= 486000 a= 0.32716482877731323 b= 1.1264530420303345 std= 3.056563138961792 freeze= True\n",
      "[2026-01-20 07:37:21] ## n_step 15632000 score -4.605 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:38:36] ## n_step 15648000 score -9.569 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:39:55] ## n_step 15664000 score -5.794 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:41:11] ## n_step 15680000 score -11.448 best score 5.646 loss 0.00002\n",
      "step= 488000 a= 0.32329773902893066 b= 1.117872714996338 std= 3.0931239128112793 freeze= True\n",
      "[2026-01-20 07:42:28] ## n_step 15696000 score -9.293 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:43:44] ## n_step 15712000 score -8.457 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:45:00] ## n_step 15728000 score -4.914 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:46:15] ## n_step 15744000 score -9.720 best score 5.646 loss 0.00002\n",
      "step= 490000 a= 0.32239073514938354 b= 1.106748104095459 std= 3.1018261909484863 freeze= True\n",
      "[2026-01-20 07:47:31] ## n_step 15760000 score -8.925 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:48:48] ## n_step 15776000 score -4.507 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:50:03] ## n_step 15792000 score -6.445 best score 5.646 loss 0.00002\n",
      "[2026-01-20 07:51:18] ## n_step 15808000 score -3.287 best score 5.646 loss 0.00002\n",
      "step= 492000 a= 0.3215889036655426 b= 1.0753135681152344 std= 3.109560012817383 freeze= True\n",
      "[2026-01-20 07:52:35] ## n_step 15824000 score -3.294 best score 5.646 loss 0.00001\n"
     ]
    }
   ],
   "source": [
    "#### Reset the environment\n",
    "envs.train()\n",
    "observations = envs.reset()\n",
    "agent.q_next.eval()\n",
    "print(observations[0])\n",
    "\n",
    "# Initialize per-environment episode reward trackers\n",
    "episode_rewards = [0.0] * n_envs  \n",
    "scores = []  # To store completed episode scores\n",
    "obs_list = [None] * n_envs\n",
    "\n",
    "while n_steps <= 225000000:\n",
    "    agent.q_eval.eval()\n",
    "\n",
    "    obs_array = np.stack(observations)\n",
    "    actions = agent.choose_actions(obs_array, n_envs=n_envs, show_action=False, training=True).tolist()\n",
    "    \n",
    "    # for DummyVecEnvNoFlatten, you can pass tuple arrays\n",
    "    envs.step_async(actions)\n",
    "\n",
    "    if n_steps >= max_steps:\n",
    "        agent.q_eval.train()\n",
    "        for train_cnt in range(2):\n",
    "            if train_cnt > 0:\n",
    "                agent.q_eval.reset_noise()\n",
    "            agent.learn(n_steps)\n",
    "\n",
    "    observations_, rewards, dones, infos = envs.step_wait()\n",
    "    \n",
    "    for j, (observation, action, reward, observation_, done, info) in enumerate(\n",
    "            zip(observations, actions, rewards, observations_, dones, infos)):\n",
    "        \n",
    "        # Store transition as before\n",
    "        agent.store_transition_news(observation, action, reward, observation_, done, info, j)\n",
    "        \n",
    "        # Accumulate reward for each environment\n",
    "        episode_rewards[j] += reward\n",
    "        \n",
    "        # If an episode is done, record its score and reset the reward accumulator\n",
    "        if done:\n",
    "            scores.append(episode_rewards[j])\n",
    "            episode_rewards[j] = 0.0\n",
    "            observation_ = envs.reset_at(j)\n",
    "        \n",
    "        # Update the observation list for the next step\n",
    "        obs_list[j] = observation_\n",
    "    \n",
    "    observations = obs_list\n",
    "\n",
    "    # Calculate the current score as the mean of the last n_envs completed episodes\n",
    "    if len(scores) >= n_envs:\n",
    "        current_score = np.array(scores)[-n_envs:].mean()\n",
    "    else:\n",
    "        current_score = np.array(scores).mean() if scores else 0.0\n",
    "\n",
    "    if current_score >= best_score and n_steps > 1000:\n",
    "        best_score = current_score\n",
    "\n",
    "    if n_steps % 16000 == 0:\n",
    "        if len(agent.loss_c) > 1:\n",
    "            log('## n_step %0d score %.3f best score %.3f loss %.5f' % \n",
    "                (n_steps, current_score, best_score, agent.loss_c[-1]))\n",
    "        else:\n",
    "            log('## n_step %0d score %.3f best score %.3f' % \n",
    "                (n_steps, current_score, best_score))\n",
    "                \n",
    "    if n_steps > 1000 and n_steps % 1000000 == 0:\n",
    "        log('## evaluating')\n",
    "        nscore_eval = []\n",
    "        for tick in range(10) :\n",
    "            tick = np.random.choice(list(env.ticks))\n",
    "            xrange = env.date_ranges[tick][1] - 202\n",
    "            if xrange > 1:\n",
    "                step = random.randint(ndays+1, xrange)\n",
    "                nw = test(tick, step, nstep=200)\n",
    "                nscore_eval.append(nw)\n",
    "                \n",
    "        nw = test('T', 153, nstep=200, metrics=False)\n",
    "\n",
    "        score_eval = np.mean(nscore_eval)\n",
    "        if score_eval > best_score_eval:\n",
    "            best_score_eval = score_eval\n",
    "\n",
    "        print('score_eval=%.3f best_score_eval=%.3f'% (score_eval,best_score_eval))\n",
    "        env.render()\n",
    "        envs.train()\n",
    "        \n",
    "    n_steps += n_envs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = env.tbuf_train.get('T', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(curcls, nxtcls, curbma, curbul, curbll, \n",
    " zbma, zbul, zbll, zkma, zkul, zkll, \n",
    " zcls, zrsi, zadi, zpdi, zndi, \n",
    " zhgh, zlow, zopn, zem12, zem26) = data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.TRADE_PENALTY = 0.012\n",
    "env.PROFIT_CONVEXITY_K = 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n",
      "0.012\n"
     ]
    }
   ],
   "source": [
    "for e in envs.envs:\n",
    "    e.TRADE_PENALTY = 0.012\n",
    "    e.PROFIT_CONVEXITY_K = 0.07\n",
    "    print(e.TRADE_PENALTY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"modz.. {agent.groupr.running_mean} {agent.groupr.running_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6936470556015963"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(2 + 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.q_eval.linext[0].weight.device, agent.q_eval.group1.running_mean_gr.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards\n",
    "# mod1.. 0.5021314024925232 0.04668758809566498\n",
    "# mod2.. 0.2344733476638794 0.08063570410013199\n",
    "# mod3.. 0.24490664899349213 0.09989308565855026\n",
    "# mod4.. 0.5229998826980591 0.12699458003044128\n",
    "# mem .. 0.05433722957968712 0.10341408103704453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.lr\n",
    "#print(self.obs_buf.device, self.obs_buf.index_select(0, idx_t).device)\n",
    "#agent.memory.mean_rews, agent.memory.var_rews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = test('GOOG', 153, nstep=200, bal=10000, metrics=False) \n",
    "nw = test('AAPL', 153, nstep=200, bal=10000, metrics=False) \n",
    "nw = test('T', 153, nstep=200, bal=10000, metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T Human:80.0 AI:-133.1\n"
     ]
    }
   ],
   "source": [
    "nw = test('T', 153, nstep=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMM 346 25 537\n",
      "TSCO 188 25 537\n",
      "KHC 79 25 497\n",
      "COF 61 25 537\n",
      "GEN 408 25 537\n",
      "MBG.DE 92 25 545\n",
      "FOX 148 25 219\n",
      "TDY 40 25 537\n",
      "REG 478 25 537\n",
      "VLO 252 25 537\n"
     ]
    }
   ],
   "source": [
    "for tick in range(10) :\n",
    "    tick = np.random.choice(list(env.ticks))\n",
    "    xrange = env.date_ranges[tick][1] - 202\n",
    "    if xrange > 1:\n",
    "        step = random.randint(ndays+1, xrange)\n",
    "        print(tick, step, ndays, xrange)\n",
    "#        nw = test(tick, step, nstep=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################### Concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- setup & state ---\n",
    "n_steps = 0\n",
    "ascores, scores, s_scores, eps_history, steps_array = deque(maxlen=10000), deque(maxlen=10), deque(maxlen=10000), deque(maxlen=10000), deque(maxlen=10000)\n",
    "\n",
    "n_games = 10 * 30 * 3300\n",
    "since_last, rewardc = [], []\n",
    "best_since_last = 0.\n",
    "\n",
    "max_steps = 80001\n",
    "bootstrap = False\n",
    "\n",
    "if bootstrap:\n",
    "    agent.memory   = pickle.load(open('./pickle/buf_160.pkl', 'rb'))\n",
    "    agent.memory_n = pickle.load(open('./pickle/buf_n_160.pkl', 'rb'))\n",
    "    n_steps = max_steps\n",
    "    agent.epsilon = 1 - (n_steps / 250000)\n",
    "\n",
    "interrupted = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# >>> CHANGED: use official import path for SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "# (keep your DummyVecEnv import if you still use it elsewhere)\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# VecEnv factory (picklable thunk)\n",
    "# -------------------------------\n",
    "def make_env(dataenv, rank):\n",
    "    def _init():\n",
    "        # NOTE: pass ndays from your notebook scope\n",
    "        env = StockTradingEnvBB(dataenv, rank, ndays=ndays)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Create SubprocVecEnv\n",
    "# -------------------------------\n",
    "# n_envs = <set this earlier in your notebook>\n",
    "envs = SubprocVecEnv([make_env(dataenv, i) for i in range(n_envs)])\n",
    "\n",
    "# >>> CHANGED: toggle training flag inside each subprocess\n",
    "envs.set_attr(\"btraining\", True)\n",
    "\n",
    "# Reset â†’ ndarray of shape (n_envs, C, T, 1)\n",
    "observations = envs.reset()\n",
    "agent.q_next.eval()\n",
    "print(observations[0].shape)  # sanity check (C, T, 1)\n",
    "\n",
    "# Per-env trackers\n",
    "episode_rewards = [0.0] * n_envs\n",
    "scores = []\n",
    "obs_batch_next = None\n",
    "\n",
    "best_score = -10.\n",
    "\n",
    "# (Optional) a single local env for ad-hoc evaluation blocks later\n",
    "# Ensure `env` exists if you reference it below in your eval code.\n",
    "try:\n",
    "    env\n",
    "except NameError:\n",
    "    env = StockTradingEnvBB(dataenv, sd=999, ndays=ndays)\n",
    "\n",
    "# -------------------------------\n",
    "# Main training loop\n",
    "# -------------------------------\n",
    "while n_steps <= 225_000_000:\n",
    "    agent.q_eval.eval()\n",
    "\n",
    "    # >>> CHANGED: observations already batched; no np.stack needed\n",
    "    actions = agent.choose_actions(\n",
    "        observations, n_envs=n_envs, show_action=False, training=True\n",
    "    )\n",
    "    actions = np.asarray(actions, dtype=np.int64)  # (n_envs,)\n",
    "\n",
    "    # Non-blocking step then wait\n",
    "    envs.step_async(actions)\n",
    "    observations_, rewards, dones, infos = envs.step_wait()\n",
    "\n",
    "    # Store transitions & accumulate rewards\n",
    "    for j in range(n_envs):\n",
    "        agent.store_transition_news(observations[j], int(actions[j]), float(rewards[j]),\n",
    "                                    observations_[j], bool(dones[j]), infos[j], j)\n",
    "        episode_rewards[j] += float(rewards[j])\n",
    "\n",
    "    # Handle finished episodes: move scores & reset those envs\n",
    "    # Try SB3 2.x fast-path\n",
    "    reset_done_supported = False\n",
    "    try:\n",
    "        new_obs = envs.reset_done(dones)   # SB3 >= 2.0\n",
    "        reset_done_supported = True\n",
    "        if new_obs is not None:\n",
    "            observations_[dones] = new_obs[dones]\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    if not reset_done_supported:\n",
    "        # SB3 1.x fallback: reset individual sub-envs\n",
    "        done_idxs = np.where(dones)[0]\n",
    "        if len(done_idxs):\n",
    "            # record episode scores\n",
    "            for idx in done_idxs:\n",
    "                scores.append(episode_rewards[idx])\n",
    "                episode_rewards[idx] = 0.0\n",
    "            # reset and place new observations\n",
    "            reset_obs_list = envs.env_method(\"reset\", indices=done_idxs)\n",
    "            for idx, ob in zip(done_idxs, reset_obs_list):\n",
    "                observations_[idx] = ob\n",
    "\n",
    "    # Advance obs\n",
    "    observations = observations_\n",
    "\n",
    "    # Score tracking (same logic)\n",
    "    if len(scores) >= n_envs:\n",
    "        current_score = np.array(scores)[-n_envs:].mean()\n",
    "    else:\n",
    "        current_score = (np.array(scores).mean() if scores else 0.0)\n",
    "\n",
    "    if current_score >= best_score and n_steps > 1000:\n",
    "        best_score = current_score\n",
    "\n",
    "    if n_steps % 16000 == 0:\n",
    "        if len(agent.loss_c) > 1:\n",
    "            log('## n_step %0d score %.3f best score %.3f loss %.5f' %\n",
    "                (n_steps, current_score, best_score, agent.loss_c[-1]))\n",
    "        else:\n",
    "            log('## n_step %0d score %.3f best score %.3f' %\n",
    "                (n_steps, current_score, best_score))\n",
    "\n",
    "    # -------- Periodic evaluation (unchanged) --------\n",
    "    if n_steps > 1000 and n_steps % 1_000_000 == 0:\n",
    "        log('## evaluating')\n",
    "        nscore_eval = []\n",
    "        # ensure `env` exists; using single-process env for eval\n",
    "        for tick in range(10):\n",
    "            tick = np.random.choice(list(env.ticks))\n",
    "            xrange = env.date_ranges[tick][1] - 202\n",
    "            if xrange > 1:\n",
    "                step = random.randint(ndays+1, xrange)\n",
    "                nw = test(tick, step, nstep=200)\n",
    "                nscore_eval.append(nw)\n",
    "\n",
    "        nw = test('T', 153, nstep=200, metrics=False)\n",
    "\n",
    "        score_eval = np.mean(nscore_eval) if nscore_eval else 0.0\n",
    "        if score_eval > best_score:\n",
    "            best_score = score_eval\n",
    "\n",
    "        print('score_eval=%.3f best_score_eval=%.3f' % (score_eval, best_score))\n",
    "        try:\n",
    "            env.render()\n",
    "        except Exception:\n",
    "            pass\n",
    "        envs.set_attr(\"btraining\", True)  # resume training flag in workers\n",
    "\n",
    "    # Step counter (still adds n_envs per vectorized step)\n",
    "    n_steps += n_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
